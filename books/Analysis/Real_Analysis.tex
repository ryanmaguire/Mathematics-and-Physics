\documentclass[crop=false,class=book,oneside]{standalone}
%----------------------------Preamble-------------------------------%
\input{../../preamble.tex}
%----------------------------GLOSSARY-------------------------------%
\makeglossaries
\loadglsentries{../../glossary}
\loadglsentries{../../acronym}
%--------------------------Main Document----------------------------%
\begin{document}
    \ifx\ifmathcourses\undefined
        \pagenumbering{roman}
        \title{Real Analysis}
        \author{Ryan Maguire}
        \date{\vspace{-5ex}}
        \maketitle
        \tableofcontents
        \clearpage
        \chapter*{Real Analysis}
        \addcontentsline{toc}{chapter}{Real Analysis}
        \markboth{}{REAL ANALYSIS}
        \vspace{10ex}
        \setcounter{chapter}{1}
        \pagenumbering{arabic}
    \else
        \chapter{Real Analysis}
    \fi
    \section{Notes from Rosenlicht}
        \subsection{Sets}
            Give a function $f:X\rightarrow{Y}$, the dinstinction
            between the image of a subset $S\subseteq{X}$ and a
            point $x\in{X}$ is:
            \begin{equation}
                f(\{x\})=\{f(x)\}
            \end{equation}
            Similarly for the pre-image:
            \begin{equation}
                \{f^{\minus{1}}(y)\}=f^{\minus{1}}(\{y\})
            \end{equation}
            One definition of an infinite set is that it contains
            a bijection between itself and a proper subset. Such
            sets are called Dedekind infinite, and countable choice is
            needed here. The following are true:
            \begin{align}
                (A^{C})^{C}&=A\\
                A\cup{A}&=A\cap{A}=A\cup\emptyset=A\\
                A\cap\emptyset&=\emptyset\\
                A\times\emptyset&=\emptyset
            \end{align}
            In addition, there are De Morgan's laws and the distributive
            laws. Some more identities:
            \begin{align}
                (A\setminus{B})\cap{C}&=(A\cap{C})\setminus{B}\\
                (A\cup{B})\setminus(A\cap{B})
                    &=(A\setminus{B})\cup(B\setminus{A})\\
                (A\setminus(B\setminus{C}))
                    &=(A\setminus{B})\cup(A\cap{B}\cap{C})\\
                (A\setminus{B})\times{C}
                    &=(A\times{C})\setminus(B\times{C})
            \end{align}
            Given any collection of sets $X_{i}$, $i\in{I}$, and a
            set $B$, we have:
            \begin{align}
                B\cap\Big(\bigcup_{i\in{I}}A_{i}\Big)
                    &=\bigcup_{i\in{I}}\Big(B\cap{A_{i}}\Big)
            \end{align}
            Composition is a commutative operation. That is, given
            $f:X\rightarrow{Y}$, $g:Y\rightarrow{Z}$, and
            $h:Z\rightarrow{W}$, we have:
            \begin{equation}
                h\circ(g\circ{f})=(h\circ{h})\circ{f}
            \end{equation}
            The following is also true of functions:
            \begin{subequations}
                \begin{align}
                    f(A\cup{B})&=f(A)\cup{f}(B)\\
                    f(A\cap{B})&\subseteq{f}(A)\cap{f}(B)\\
                    f^{\minus{1}}(A\cup{B})
                        &=f^{\minus{1}}(A)\cup{f}^{\minus{1}}(B)\\
                    f^{\minus{1}}(A\cap{B})
                        &=f^{\minus{1}}(A)\cap{f}^{\minus{1}}(B)\\
                    A\subseteq{f}^{\minus{1}}(f(A))\\
                    f(f^{\minus{1}}(A)\subseteq{A}
                \end{align}
            \end{subequations}
            \begin{theorem}
                If $f:X\rightarrow{Y}$ is injective, then:
                \begin{subequations}
                    \begin{align}
                        f^{\minus{1}}(f(A))&=A\\
                        f(A\cap{B})&=f(A)\cap{f}(B)
                    \end{align}
                \end{subequations}
            \end{theorem}
            \begin{theorem}
                If $f:X\rightarrow{Y}$ is surjective, then:
                \begin{equation}
                    f(f^{\minus{1}}(A))=A
                \end{equation}
            \end{theorem}
        \subsection{The Real Number System}
            The real numbers are a set $\mathbb{R}$ with several
            properties. These properties make $\mathbb{R}$ a
            complete ordered field, and indeed the only complete
            ordered field. That is, the real numbers are unique
            up to \textit{isomorphism}. There are two functions
            $+,\cdot:\mathbb{R}^{2}\rightarrow\mathbb{R}$, called
            addition and multiplication, respectively, that satisfy
            the following \textit{field axioms}:
            \begin{align}
                a+b&=b+a&
                a\cdot{b}&=b\cdot{a}
                \tag{Commutativity}\\
                a+(b+c)&=(a+b)+c&
                a\cdot(b\cdot{c})&=(a\cdot{b})\cdot{c}
                \tag{Associativity}\\
                a\cdot(b+c)&=a\cdot{b}+a\cdot{c}
                \tag{Distributive Law}\\
                \exists_{0\in\mathbb{R}}:0+a&=a&
                \exists_{1\in\mathbb{R}}:a\cdot{1}&=a
                \tag{Neutral Elements}\\
                \forall_{a\in\mathbb{R}}\exists_{b\in\mathbb{R}}:
                a+b&=0&
                \forall_{a\in\mathbb{R},a\ne{0}}
                \exists_{a^{\minus{1}}}:
                a\cdot{a}^{\minus{1}}&=1
                \tag{Inverse Elements}
            \end{align}
            By inductively using the associative laws and the
            commutative laws, we see that adding $n$ elements
            does not depend on the order in which they are
            added. Similarly for multiplication. For a general
            field, we write $(F,+,\cdot)$.
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, and if $a\in{F}$, then
                the additive inverse of $a$ is unique.
            \end{theorem}
            \begin{proof}
                For suppose $b$ and $b'$ are additive inverses. Then:
                \begin{equation}
                    b=b+0=b+(a+b')=(b+a)+b'=0+b'=b'
                \end{equation}
                And therefore $b$ is unique.
            \end{proof}
            We denote the additive inverse of an element $a$ by
            writing $\minus{a}$.
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, if $a,b\in{F}$, then
                there is a unique $x\in{F}$ such that
                $x+a=b$.
            \end{theorem}
            \begin{proof}
                For let $x=a-b$. Then:
                \begin{equation}
                    x+a=(b-a)+a
                    =b+(-a+a)
                    =b+0
                    =b
                \end{equation}
                Moreover, of $x'$ is a solution, then:
                \begin{equation}
                    x'=x'+0=x'+(a+(\minus{a}))=
                    (x'+a)+(\minus{a})=b+(\minus{a})=x
                \end{equation}
                Thus, $x'=x$.
            \end{proof}
            Instead of writing $b+(\minus{a})$, we
            denote this by $b-a$. This new operation is called
            subtraction. Note that it is not commutative, nor
            is it associative. Indeed, for any $a,b\in\mathbb{R}$,
            suppose $a-b=b-a$, and let $y=a-b$. Then we have that
            $y=\minus{y}$, and thus $y+y=2y=0$. This is only possible
            in $\mathbb{R}$ if $y=0$, and thus we'd require that
            $a=b$. So subtraction is not commutative in $\mathbb{R}$.
            There are fields such that $y+y=0$ and such that
            $y\ne{0}$, but such fields can't have a notion of
            \textit{order} on them. We'll discuss these later.
            Note that the notion is not associative either. Again,
            let $a=2$ and $b=c=1$. Then $a-(b-c)=2$, but
            $(a-b)-c=0$. Again we come to the conclusion that either
            $2=0$, or subtraction is not associative. In an ordered
            field, which is what $\mathbb{R}$ is, we cannot have
            $2=0$. In finite fields, this is possible.
            \begin{theorem}
                If $(F,+,\cdot)$ is a field and if $a\in{F}$
                is non-zero, then the multiplicative inverse
                of $a$ is unique.
            \end{theorem}
            \begin{proof}
                For suppose $b$ and $b'$ are multiplicative inverses
                of $a$. Then:
                \begin{equation}
                    b=b\cdot{1}=b\cdot(a\cdot{b}')=
                    (b\cdot{a})\cdot{b}'=1\cdot{b}'=b'
                \end{equation}
                And therefore $b$ is unique.
            \end{proof}
            We write the multiplicative inverse of a non-zero element
            by $a^{\minus{1}}$.
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, if $a,b\in{F}$, and if
                $a\ne{0}$, then there is a unique $x\in{F}$ such that
                $x\cdot{a}=b$.
            \end{theorem}
            \begin{proof}
                For let $x=b\cdot{a}^{\minus{1}}$. Then:
                \begin{equation}
                    x\cdot{a}=(b\cdot{a}^{\minus{1}})=
                    b\cdot(a^{\minus{1}}\cdot{a})=
                    b\cdot{1}=b
                \end{equation}
                Moreoever, if $x'$ is a solution, then:
                \begin{equation}
                    x'=x'\cdot{1}=x'\cdot(a\cdot{a^{\minus{1}}})
                    =(x'\cdot{a})\cdot{a^{\minus{1}}}=
                    b\cdot{a}^{\minus{1}}=x
                \end{equation}
                Thus, $x'=x$.
            \end{proof}
            We define division by non-zero numbers by writing
            $\frac{a}{b}=a\cdot{b}^{\minus{1}}$. Other symbols are
            used for this, like $a\div{b}$, or simply $a/b$. Similar
            to subtraction, division is neither commutative nor
            associative.
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, if $a,b,c\in{F}$, and if
                $a+c=b+c$, then $a=b$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    a=a+0=a+(c-c)=(a+c)-c=(b+c)-c=b+(c-c)=0
                \end{equation}
                Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, $a,b,c\in{F}$, if
                $c\ne{0}$, and if $a\cdot{c}=b\cdot{c}$, then
                $a=b$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    a=a\cdot{1}=a\cdot(c\cdot{c}^{\minus{1}})=
                    (a\cdot{c})\cdot{c}^{\minus{1}}=
                    (b\cdot{c})\cdot{c}^{\minus{1}}=
                    b\cdot(c\cdot{c}^{\minus{1}})=
                    b\cdot{1}=b
                \end{equation}
                Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $(F,\cdot,+)$ is a field, and if $a\in{F}$, then
                $a\cdot{0}=0$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    a\cdot{0}+a\cdot{0}=a\cdot(0+0)=
                    a\cdot{0}=a\cdot{0}+0
                \end{equation}
                And therefore from the cancellation laws,
                $a\cdot{0}=0$.
            \end{proof}
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, and $a\in{F}$, then
                $\minus{a}=(\minus{1})\cdot{a}$
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    (\minus{1})\cdot{a}+a=
                    (\minus{1}+1)\cdot{a}=
                    0\cdot{a}=0
                \end{equation}
                From the uniqueness of inverses,
                $\minus{a}=(\minus{1})\cdot{a}$.
            \end{proof}
            \begin{theorem}
                If $(F,+,\cdot)$ is a field and $a\in{F}$, then
                $\minus(\minus{a})=a$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    \minus(\minus{a})+(\minus{a})=
                    (\minus{1})\cdot(\minus{a})+(\minus{a})
                    =(\minus{1}+1)\cdot(\minus{a})
                    =0\cdot(\minus{a})=0
                \end{equation}
                From the uniqueness of inverses, etc.
            \end{proof}
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, and if $a,b\in{F}$ are
                non-zero, then $(a\cdot{b})^{\minus{1}}=%
                                b^{\minus{1}}\cdot{a}^{\minus{1}}$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    (a\cdot{b})
                    \cdot(b^{\minus{1}}\cdot{a}^{\minus{1}})
                    =a\cdot
                    (b\cdot{b}^{\minus{1}})\cdot{a}^{\minus{1}}
                    =a\cdot{1}\cdot{a}^{\minus{1}}=
                    a\cdot{a}^{\minus{1}}=1
                \end{equation}
                From the uniqueness of inverses, etc.
            \end{proof}
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, $a\in{F}$ is non-zero,
                then $(a^{\minus{1}})^{\minus{1}}=a$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    (a^{\minus{1}})^{\minus{1}}\cdot{a}^{\minus{1}}=
                    (a\cdot{a}^{\minus{1}})^{\minus{1}}=
                    1^{\minus{1}}=1
                \end{equation}
                From uniquness, etc.
            \end{proof}
            \begin{theorem}
                If $(F,+,\cdot)$ is a field, and $a,b,c,d\in{F}$, and
                if $b,d\ne{0}$, then:
                \begin{equation}
                    (a\cdot{b}^{\minus{1}})+(c\cdot{d}^{\minus{1}})=
                    (a\cdot{d}+b\cdot{c})\cdot(b\cdot{d})^{\minus{1}}
                    =\frac{ad+bc}{bd}
                \end{equation}
            \end{theorem}
            As stated before, the axioms of a field are not enough
            to uniquely define the real numbers. Indeed, the rational
            numbers $\mathbb{Q}$ define a field, as do the complex
            numbers $\mathbb{C}$. To see a finite field, consider the
            set $\mathbb{F}_{2}=\{0,1\}$, and consider the following
            arithmetic:
            \par
            \begin{minipage}[b]{0.49\textwidth}
                \centering
                \begin{table}[H]
                    \centering
                    \captionsetup{type=table}
                    \begin{tabular}{c|cc}
                        $+$&0&1\\
                        \hline
                        0&0&1\\
                        1&1&0
                    \end{tabular}
                    \caption{Addition in $\mathbb{F}_{2}$}
                    \label{tab:Real_Analysis_Add_in_F_2_Field}
                \end{table}
            \end{minipage}
            \hfill
            \begin{minipage}[b]{0.49\textwidth}
                \begin{table}[H]
                    \centering
                    \captionsetup{type=table}
                    \begin{tabular}{c|cc}
                        $\cdot$&0&1\\
                        \hline
                        0&0&0\\
                        1&0&1
                    \end{tabular}
                    \caption{Multiplication in $\mathbb{F}_{2}$}
                    \label{tab:Real_Analysis_Mult_in_F_2_Field}
                \end{table}
            \end{minipage}
            Then $(F,+,\cdot)$ is a field. It's a very strange field,
            since we have $1+1=0$, but alas it satisfies all of the
            properties of a field, and all of the theorem's we have
            proved still apply. Interesting, it is the only field
            with two elements. We have no choice in deciding what
            $a\cdot{b}$ means in the field, since multiplication by
            zero must give zero, and multiplication by one must give
            back the original number. Similarly for addition.
            Adding zero must not change anything, and so all
            we are left with is deciding what $1+1$ equals. But
            to be a field, there must be an additive inverse
            element. Thus we are forced to set $1+1=0$. There is
            also a field with three elements. For let
            $\mathbb{F}_{3}=\{0,1,2\}$ and define:
            \par\hfill\par
            \begin{minipage}[b]{0.49\textwidth}
                \centering
                \begin{table}[H]
                    \centering
                    \captionsetup{type=table}
                    \begin{tabular}{c|ccc}
                        $+$&0&1&2\\
                        \hline
                        0&0&1&2\\
                        1&1&2&0\\
                        2&2&0&1
                    \end{tabular}
                    \caption{Addition in $\mathbb{F}_{3}$}
                    \label{tab:Real_Analysis_Add_in_F_3_Field}
                \end{table}
            \end{minipage}
            \hfill
            \begin{minipage}[b]{0.49\textwidth}
                \begin{table}[H]
                    \centering
                    \captionsetup{type=table}
                    \begin{tabular}{c|ccc}
                        $\cdot$&0&1&2\\
                        \hline
                        0&0&0&0\\
                        1&0&1&2\\
                        2&0&2&1
                    \end{tabular}
                    \caption{Multiplication in $\mathbb{F}_{3}$}
                    \label{tab:Real_Analysis_Mult_in_F_3_Field}
                \end{table}
            \end{minipage}
            Intuition tells us that $1+1>1>0$, and thus $1+1$ cannot
            be equal to zero. Thus, to exclude finite fields we
            need to introduce the notion of order.
            \begin{enumerate}
                \item There is a subset $\mathbb{R}^{+}$
                      of $\mathbb{R}$ such that, for all
                      $a,b\in\mathbb{R}^{+}$, we
                      have $a\cdot{b}\in\mathbb{R}^{+}$ and
                      $a+b\in\mathbb{R}^{+}$.
                \item For all $a\in\mathbb{R}$, one and only one of
                      the following statements is true:
                      \begin{itemize}
                          \item $a\in\mathbb{R}^{+}$
                          \item $a=0$
                          \item $\minus{a}\in\mathbb{R}^{+}$
                      \end{itemize}
            \end{enumerate}
            $\mathbb{R}^{+}$ is called the set of positive numbers,
            and the elements such that $\minus{a}\in\mathbb{R}^{+}$
            are called negative. We define less than by writing
            $a<b$ if $b-a\in\mathbb{R}^{+}$. Similarly, we define
            greater than by writing $a>b$ is $a-b\in\mathbb{R}^{+}$.
            The less than or equal to and greater than or equal to
            symbols, denoted $\leq$ and $\geq$, respectively,
            are such that $a\leq{b}$ if $a<b$ or $a=b$, and
            similarly $a\geq{b}$ if $a>b$ or $a=b$. This defines
            $\mathbb{R}$ to be on ordered field.
            \begin{theorem}
                If $a,b\in\mathbb{R}$, then either $a=b$, $a<b$, or
                $a>b$.
            \end{theorem}
            \begin{proof}
                For either $a-b\in\mathbb{R}^{+}$, $a-b=0$, or
                $\minus(a-b)\in\mathbb{R}^{+}$. If
                $a-b\in\mathbb{R}^{+}$, then $a>b$. If $a-b=0$, then
                $a=b$. Finally, if $\minus(a-b)\in\mathbb{R}^{+}$,
                then $b-a\in\mathbb{R}^{+}$, and thus $b>a$.
            \end{proof}
            \begin{theorem}
                If $a,b,c\in\mathbb{R}$, if $a<b$, and if $b<c$, then
                $a<c$.
            \end{theorem}
            \begin{proof}
                For if $a<b$, then $b-a\in\mathbb{R}^{+}$. But if
                $b<c$, then $c-b\in\mathbb{R}^{+}$. But then:
                \begin{equation}
                    c-a=(c-b)+(b-a)\in\mathbb{R}^{+}
                \end{equation}
                Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $a,b,c,d\in\mathbb{R}$, if $a<b$, and if
                $c\leq{d}$, then $a+c<b+d$.
            \end{theorem}
            \begin{proof}
                If $a<b$, then $b-a\in\mathbb{R}^{+}$. If $c\leq{d}$,
                then either $d-c\in\mathbb{R}^{+}$, or $d-c=0$. Thus:
                \begin{equation}
                    (b+d)-(a+c)=(b-a)+(d-c)\in\mathbb{R}^{+}
                \end{equation}
                Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $a,b,c,d\in\mathbb{R}^{+}$, if $a<b$, and if
                $c\leq{d}$, then $a\cdot{c}<b\cdot{d}$.
            \end{theorem}
            \begin{proof}
                For if $a<b$, then $b-a\in\mathbb{R}^{+}$. But if
                $c\leq{d}$, then $d-c\in\mathbb{R}^{+}$, or
                $d-c=0$. But then
                $b\cdot{c}-a\cdot{c}=c\cdot(b-a)\in\mathbb{R}^{+}$.
                Similarly,
                $a\cdot{d}-a\cdot{c}=a\cdot(d-c)$, and thus this is
                either positive of zero. Therefore:
                \begin{equation}
                    bd-ac=(bd-ad)+(ad-ac)=
                    d(b-d)+a(d-c)\in\mathbb{R}^{+}
                \end{equation}
            \end{proof}
            \begin{theorem}
                If $a,b\in\mathbb{R}$ are negative, then $a+b$ is
                negative.
            \end{theorem}
            \begin{proof}
                For if $a$ and $b$ are negative, then
                $\minus{a}$ and $\minus{b}$ are positive. But then
                $(\minus{a})+(\minus{b})\in\mathbb{R}^{+}$. But:
                \begin{equation}
                    (\minus{a})+(\minus{b})=
                    (\minus{1})\cdot{a}+(\minus{1})\cdot{b}
                    =(\minus{1})\cdot(a+b)
                    =\minus(a+b)\in\mathbb{R}^{+}
                \end{equation}
                Thus, $a+b$ is negative.
            \end{proof}
            \begin{theorem}
                If $a,b\in\mathbb{R}$, if $a$ is positive, and if
                $b$ is negative, than $a\cdot{b}$ is negative.
            \end{theorem}
            \begin{proof}
                For if $b$ is negative, then $\minus{b}$ is
                positive, and thus:
                \begin{equation}
                    \minus(a\cdot{b})
                    =a\cdot(\minus{b})\in\mathbb{R}^{+}
                \end{equation}
                Thus, $a\cdot{b}$ is negative.
            \end{proof}
            \begin{theorem}
                If $a,b\in\mathbb{R}$ are negative, then $a\cdot{b}$
                is positive.
            \end{theorem}
            \begin{proof}
                For if $a$ and $b$ are negative, then
                $\minus{a},\minus{b}\in\mathbb{R}^{+}$. But then:
                \begin{equation}
                    a\cdot{b}=1\cdot(a\cdot{b})
                    =\big((\minus{1})\cdot(\minus{1})\big)
                    \cdot(a\cdot{b})
                    =(\minus{a})\cdot(\minus{b})\in\mathbb{R}^{+}
                \end{equation}
                And thus $a\cdot{b}$ is positive.
            \end{proof}
            \begin{theorem}
                If $a\in\mathbb{R}$, then $a^{2}\geq{0}$.
            \end{theorem}
            \begin{proof}
                For if $a$ is positive, then $a\cdot{a}$ is positive.
                If $a$ is zero, then $a\cdot{a}=0$. Finally, from the
                previous theorem, the product of two negative numbers
                is positive, and therefore if $a$ is negative, then
                $a\cdot{a}$ is positive.
            \end{proof}
            From this we have that $1=1^{1}>0$. This generalized to
            the sum of any number of squares.
            \begin{theorem}
                If $a>0$, then $a^{\minus{1}}>0$.
            \end{theorem}
            \begin{proof}
                Suppose not. Then either $a^{\minus{1}}$ is negative
                or it is zero. But it is not zero, for zero has no
                multiplicative inverse, and $a$ is an inverse of
                $a^{\minus{1}}$. Thus $a^{\minus{1}}$ is negative.
                But $a\cdot{a}^{\minus{1}}=1>0$, a contradiction.
                Therefore, $a^{\minus{1}}$ is positive.
            \end{proof}
            \begin{theorem}
                If $0<a<b$, then $0<b^{\minus{1}}<a^{\minus{1}}$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    0<a<b\Longrightarrow
                    0<a\cdot(a^{\minus{1}}b^{\minus{1}})<
                    b\cdot(a^{\minus{1}}b^{\minus{1}})
                    \Longrightarrow
                    0<b^{\minus{1}}<a^{\minus{1}}
                \end{equation}
            \end{proof}
            \begin{theorem}
                If $a<b<0$, then $b^{\minus{1}}<a^{minus{1}}$.
            \end{theorem}
            \begin{proof}
                For if $a<b<0$, then $0<b-a$ and
                $0<a\cdot{b}$. But then
                $0<a^{\minus{1}}\cdot{b}^{\minus{1}}$.
                Thus:
                \begin{equation}
                    0<(b-a)\cdot{a}^{\minus{1}}b^{\minus{1}}=
                    a^{\minus{1}}-b^{\minus{1}}
                \end{equation}
                And thus $b^{\minus{1}}<a^{\minus{1}}$.
            \end{proof}
            \begin{theorem}
                If $a,b,c\in\mathbb{R}$, then
                $\minus(a-b)=b-a$.
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    (b-a)+(a-b)=b+(\minus{a}+a)-b=
                    b+0-b=b-b=0
                \end{equation}
                From the uniqueness of inverses, etc.
            \end{proof}
            \begin{theorem}
                If $a,b,c,d\in\mathbb{R}$, then:
                \begin{equation}
                    (a-b)\cdot(c-d)
                    =(a\cdot{c}+b\cdot{d})-(a\cdot{d}+b\cdot{c})
                \end{equation}
            \end{theorem}
            \begin{proof}
                For:
                \begin{subequations}
                    \begin{align}
                        (a-b)\cdot(c-d)&=
                        a\cdot(c-d)-b\cdot(c-d)\\
                        &=(a\cdot{c}-a\cdot{d})-
                            (b\cdot{c}-b\cdot{d})\\
                        &=(a\cdot{c}-a\cdot{d})+
                            (b\cdot{d}-b\cdot{c})\\
                        &=(a\cdot{c}+b\cdot{d})-
                            (a\cdot{d}+b\cdot{c})
                    \end{align}
                \end{subequations}
                Therefore, etc.
            \end{proof}
            We thus have a way to distinguish $\mathbb{R}$
            from finite fields. We define the natural numbers to by
            $2=1+1$, $3=2+1$, $4=3+1$, and so on. Order also excludes
            the complex numbers, $\mathbb{C}$, since the complex
            numbers are not ordered. However, the rational numbers,
            $\mathbb{Q}$, still satisfy all of these properties and
            are too an ordered field. We need another property to
            distinguish $\mathbb{Q}$ from $\mathbb{R}$. First, a
            discussion of exponentiation and the absolute value
            function. Given a positive integer $n$, we define the
            exponentiation of a real number $r$ by
            $r^{n}=r\cdots{r}$, where multiplication is
            carried out $n$ times. From this, we get:
            \begin{subequations}
                \begin{align}
                    a^{n}\cdot{a}^{m}&=a^{n+m}\\
                    (a^{m})^{n}&=a^{mn}\\
                    (ab)^{n}&=a^{n}b^{n}
                \end{align}
            \end{subequations}
            The absolute value of a real number is defined as:
            \begin{equation}
                |a|=
                \begin{cases}
                    a,&a\geq{0}\\
                    \minus{a},&a<-
                \end{cases}
            \end{equation}
            \begin{theorem}
                If $a\in\mathbb{R}$, then $|a|\geq{0}$.
            \end{theorem}
            \begin{theorem}
                If $a,b\in\mathbb{R}$, then
                $|a\cdot{b}|=|a|\cdot|b|$.
            \end{theorem}
            \begin{theorem}
                If $a\in\mathbb{R}$, then $a^{2}=|a|^{2}$.
            \end{theorem}
            \begin{ltheorem}{Triangle Inequality}
                If $a,b\in\mathbb{R}$, then
                $|a+b|\leq|a|+|b|$.
            \end{ltheorem}
            \begin{ltheorem}{Reverse Triangle Inequality}
                If $a,b\in\mathbb{R}$, then
                $|a-b|\geq\big||a|-|b|\big|$
            \end{ltheorem}
            \begin{theorem}
                If $a,b\in\mathbb{R}$, then:
                \begin{equation}
                    \max\{a,b\}=\frac{a+b+|a-b|}{2}
                \end{equation}
            \end{theorem}
            \begin{proof}
                If $a=b$, then we are done. If $a<b$, then
                $|a-b|=b-a$, and thus:
                \begin{equation}
                    \frac{a+b+|a-b|}{2}=\frac{a+b+b-a}{2}=b
                \end{equation}
                And this is the max of $a$ and $b$. similarly
                if $b<a$.
            \end{proof}
            \begin{theorem}
                If $a,b\in\mathbb{R}$, then:
                \begin{equation}
                    \min\{a,b\}=\frac{a+b-|a-b|}{2}
                \end{equation}
            \end{theorem}
            \begin{proof}
                For if $a=b$, then we are done. If
                $a<b$, then $|a-b|=b-a$, and thus:
                \begin{equation}
                    \frac{a+b-|a-b|}{2}=
                    \frac{a+b-(b-a)}{2}=a
                \end{equation}
                And this is the minimum of $a$ and $b$. Similarly
                for $b<a$.
            \end{proof}
            \begin{theorem}
                If $a,b,x,y\in\mathbb{R}$, if $a<x<b$< and if
                $a<y<b$< then:
                \begin{equation}
                    |x-y|<b-a
                \end{equation}
            \end{theorem}
            \begin{proof}
                For:
                \begin{equation}
                    a-b=\minus(b-a)<
                    x-b<x-y<b-y<ba
                \end{equation}
                And therefore:
                \begin{equation}
                    \minus(b-a)<x-y<b-a
                \end{equation}
                Therefore, etc.
            \end{proof}
            Note that $|x-a|<\varepsilon$ implies that
            $\varepsilon-a<x<\varepsilon+a$. Thus, the solution set
            to this inequality is all of the points that lie in the
            interval $(a-\varepsilon,a+\varepsilon)$. Now, to
            separate $\mathbb{R}$ from $\mathbb{Q}$ we need
            to introduce the idea of \textit{completeness}.
            We will do this in the form of the Least Upper
            Bound axiom.
            \begin{definition}
                An upper bound for a subset $S\subseteq\mathbb{R}$
                is a real number $r$ such that, for all $x\in{S}$,
                we have $x\leq{r}$.
            \end{definition}
            A bounded above subset is a subset with an upper bound.
            \begin{definition}
                A least upper bound for a subset
                $S\subseteq\mathbb{R}$ is a real number $r$ such
                that $r$ is an upper bound
                for $S$, and for all upper bounds $s$, we have
                $r\leq{s}$.
            \end{definition}
            From this definition we have that least upper bounds are
            unique for a given bounded above set.
            \begin{theorem}
                If $S$ is a subset of $\mathbb{R}$, if $s$ is a
                least upper bound of $S$, and if $x\in\mathbb{R}$
                is such that $x<s$, then there is a $y\in{S}$
                such that $x<y$.
            \end{theorem}
            \begin{proof}
                For suppose not. Then $x$ is an upper bound of $S$,
                a contradiction as $s$ is the least upper bound.
            \end{proof}
            Any non-empty finite subset will have a least
            upper bound. Infinite subsets need not have a least
            upper bound, and indeed $\mathbb{R}$ does not have
            one. If the least upper bound of $S$ exists, it may
            not belong to $S$. For example, the set of all
            negative numbers has zero as its least upper bound,
            but zero is not a negative number. The real
            numbers satisfy the following property:
            \begin{enumerate}
                \item For any non-empty set of real numbers that
                      is bounded from above, there is a least
                      upper bound.
            \end{enumerate}
            This axiom distringuishes the rational numbers from the
            real numbers. That is, there are bounded above subsets
            of $\mathbb{Q}$ with no least upper bound.
            We can justify the least upper bound axiom by
            considering the decimal expansion of real numbers. That
            is, we write out
            $x=n+0.x_{1}x_{2}x_{3}\dots$ where $n$ is an integer,
            and $x_{i}$ is an integer between zero and nine. If
            $S$ is bounded above, then there is a least integer
            $n$ such that, for all $x\in{S}$, $x\leq{n}$. This
            simply comes from the Archimedean principle and the
            well-ordering principle of the real numbers.
            But then there is a least $x_{1}$ such that $x_{1}$ is
            and integer between zero and nine and such that, for
            all $x\in{S}$, $x\leq{n}.x_{1}$ where this indicates
            the usual representation of
            $n+x_{1}\times{10}^{\minus{1}}$. We can continue on
            for $x_{2}$ and so on, and this decimal expansion
            will represent the least upper bound of $S$. The
            least upper bound of a set $S$ is often denoted
            $\sup{S}$, where $\sup$ denotes the latin word
            \textit{supremum}. Similarly, the greatest lower bound
            of a set is denoted $\inf{S}$, where $\inf$ stands
            for \textit{infinum}.
            \begin{theorem}
                If $S\subseteq\mathbb{R}$ is bounded from below,
                then there exists a greatest lower bound of $S$.
            \end{theorem}
            \begin{proof}
                For is $S$ is bounded below, then
                $\minus{S}=\{\minus{x}:x\in{S}\}$ is bounded
                from above. But sets that are bounded above have
                a least upper bound. Let $s$ be the least upper
                bound of $\minus{S}$. Then $\minus{s}$ is the
                greatest lower bound of $S$. Therefore, etc.
            \end{proof}
            The real numbers have the property that any real
            number can be approximated arbitrarily well by a
            rational number. The rational numbers, however, have
            certain gaps that are filled in by the real numbers.
            In a sense, the real numbers are \textit{complete}
            whereas the rational numbers are not.
            \begin{ltheorem}{The Archimedean Property}
                If $x$ is a real number, then there is an integer
                $n$ such that $x<n$.
            \end{ltheorem}
            \begin{proof}
                For suppose not. Then there is an $x\in\mathbb{R}$
                such that, for all $n\in\mathbb{N}$, $n\leq{x}$.
                But then $\mathbb{N}$ is bounded above, and then
                there exists a least upper bound. Let $s$ be such
                a bound. But if $s$ is a bound, then for all
                $n\in\mathbb{N}$, $n\leq{s}$. But if
                $n\in\mathbb{N}$, then $n+1\in\mathbb{N}$ and thus
                $n+1\leq{s}$. But then, for all $n\in\mathbb{N}$,
                $n\leq{s-1}$, a contradiction as $s$ is a least
                upper bounded, and $s-1<s$. Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $\varepsilon>0$, then there is an
                $n\in\mathbb{N}$ such that
                $n^{\minus{1}}<\varepsilon$.
            \end{theorem}
            \begin{proof}
                Since $\varepsilon>0$ $\varepsilon^{\minus{1}}$ is
                well defined and positive. But then there is an
                $n\in\mathbb{N}$ such that
                $n>\varepsilon^{\minus{1}}$. But then
                $n^{\minus{1}}<\varepsilon$. Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $x\in\mathbb{R}$, then there is an integer
                $n\in\mathbb{Z}$ such that
                $n\leq{x}<n+1$.
            \end{theorem}
            \begin{proof}
                For if $x\in\mathbb{R}^{+}$, there is an
                $N\in\mathbb{N}$ such that $x<N$. But then, from
                the well-ordering of $\mathbb{N}$, there is a
                least $k\in\mathbb{N}$ such that
                $x<k$. Let $n=k-1$. But then $n\in\mathbb{Z}$ and
                $n\leq{x}<n+1$. If $\minus{x}\in\mathbb{R}^{+}$,
                negate this and repeat the process. If $x=0$, let
                $n=0$.
            \end{proof}
            \begin{theorem}
                If $x\in\mathbb{R}$ and $N\in\mathbb{N}$, and there
                is an $n\in\mathbb{Z}$ such that:
                \begin{equation}
                    \frac{n}{N}\leq{x}<\frac{n+1}{N}
                \end{equation}
            \end{theorem}
            \begin{proof}
                For let $y=N\cdot{x}$. Then there is an
                $n\in\mathbb{Z}$ such that
                $n\leq{N}\cdot{x}<n+1$. Dividing by $N$ proves
                the result.
            \end{proof}
            \begin{theorem}
                If $\varepsilon>0$ and $r\in\mathbb{R}$, then
                there is a $q\in\mathbb{Q}$ such that
                $|r-q|<\varepsilon$.
            \end{theorem}
            \begin{proof}
                For let $\varepsilon>0$. Then there is an
                $N\in\mathbb{N}$ such that
                $N^{\minus{1}}<\varepsilon$. But then there is
                an $n\in\mathbb{Z}$ such that
                $n\leq{N}\cdot{r}<n+1$. Let
                $q=n\cdot{N}^{\minus{1}}$. Then
                $|q-r|<\varepsilon$.
            \end{proof}
            This final theorem shows that any real number can
            be approximated arbitrarily well by any rational number,
            as was claimed. Let's return to the discussion of
            the decimal expansion of real numbers. First, we
            consider finite decimals. Let $n\in\mathbb{N}$ and
            let $a{1},\dots,a_{n}$ be a sequence of integers between
            zero and nine. Let $a_{0}$ be any integer. If
            $m<n$, then:
            \begin{equation}
                \begin{split}
                    a_{0}.a_{1}a_{2}\dots{a}_{m}&\leq
                    a_{0}.a_{1}a_{2}\dots{a}_{m}a_{m+1}
                    \dots{a}_{n}\\
                    &\leq
                    a_{0}.a_{1}a_{2}\dots{a}_{m}
                    +9\times{10}^{\minus(m+1)}+\cdots
                    +9\times{10}^{\minus{n}}
                \end{split}
            \end{equation}
            If we add $10^{\minus{n}}$, this reduces to the
            following:
            \begin{equation}
                a_{0}.a_{1}a_{2}\dots{a}_{m}\leq
                a_{0}.a_{1}a_{2}\dots{a}_{n}\leq
                a_{0}.a_{1}a_{2}\dots{a}_{m}+10^{\minus{m}}
            \end{equation}
            We can thus view an \textit{infinite decimal} as a
            sequence $a:\mathbb{N}\rightarrow\mathbb{Z}$ such that
            $a_{1}\in\mathbb{Z}$, and for all $k>1$,
            $a_{k}$ is an integer between zero and nine. Using the
            decimal expansion we can find real numbers that are
            not rational. For let
            $x=0.101001000100001000001\dots$ This can't be
            rational since $Nx$ is not an integer for any
            positive integer $N$. Another classic example of
            a real number that is not rational is $\sqrt{2}$.
            \begin{theorem}
                If $r>0$, then there is a unique number $a>0$,
                called the square root of $r$, such that
                $a^{2}=r$.
            \end{theorem}
            \begin{proof}
                For uniqueness, first note that if
                $0<a<b$, then $0<a^{2}<b^{2}$, and thus
                any positive real number can have, at most, one
                positive square root. Define the following:
                \begin{equation}
                    S=\{x\in\mathbb{R}^{+}:x^{2}\leq{r}\}
                \end{equation}
                Then $S$ is bounded above, since $\max\{1,r\}$
                is such a bound. Let $a$ be the least upper bound
                of $S$. First, note that $s>0$ since:
                \begin{equation}
                    (\min\{1,r\})^{2}\leq\min\{1,r\}\cdot{1}
                    =\min\{1,r\}\leq{r}
                \end{equation}
                And therefore, $\min\{1,r\}\leq{s}$. Given
                $\varepsilon>0$, we have:
                \begin{equation}
                    (s-\varepsilon)^{2}<r<
                    (s+\varepsilon)^{2}
                \end{equation}
                And therefore:
                \begin{equation}
                    |s^{2}-r|<4s\varepsilon
                \end{equation}
                But $\varepsilon$ is arbitrary, and thus this
                difference is zero. Therefore $r=s^{2}$.
            \end{proof}
            The value $s$ is called the square root of $r$, and
            we denote it by $s=\sqrt{r}$. Note that, for any
            positive real number, there are two square roots:
            $\pm\sqrt{r}$. When we write $\sqrt{r}$, we mean the
            positive value. This theorem shows that positive real
            numbers are the squares of non-zero real numbers.
            Thus, the set $\mathbb{R}^{+}$ described earlier is
            unique, further justifying the use of this set to
            order the real numbers. The real numbers are the only
            arithmetic system, up to isomorphism, that is a
            complete ordered field. Here, complete means that the
            least upper bound axiom holds. If
            $(\mathbb{R},+,\cdot)$ and $(\mathbb{R}',+',\cdot')$
            are complete ordered fields, we may as well consider
            them to be the exact same object. They are essentially
            a relabelling of each other.
            \begin{lexample}
                Find the greatest lower bound and least upper bound
                of the set:
                \begin{equation}
                    A=\{\frac{1}{n}:n\in\mathbb{N}\}
                \end{equation}
                The least upper bound is 1, since for all
                $n\geq{1}$, we have $1\leq{n}^{\minus{1}}$. There
                is no bound less, since $1\in{A}$. The greatest
                lower bound is zero. It is indeed a bound, since
                for all $n>0$, $n^{\minus{1}}>0$. Moreover, if
                $s>0$, there is an $N\in\mathbb{N}$ such that
                $N^{\minus{1}}<s$, and thus $s$ cannot be a lower
                bound. Consider the set:
                \begin{equation}
                    B=\{\frac{1}{3},\frac{4}{9},
                        \frac{13}{27},\frac{40}{81},\dots\}
                \end{equation}
                The denominator's of this set are powers of
                three, and the numerators are sums of powers of
                three. That is, we can write:
                \begin{equation}
                    B=\Big\{\frac{1}{3^{n}}\sum_{k=0}^{n-1}3^{k}:
                        n\in\mathbb{N}\Big\}
                \end{equation}
                We can use the geometric series to simplify the
                sum, noting that:
                \begin{equation}
                    \frac{1}{3^{n}}\sum_{k=0}^{n-1}3^{k}=
                    \frac{1}{3^{n}}\frac{1-3^{n}}{1-3}=
                    \frac{3^{n}-1}{2\cdot{3}^{n}}
                \end{equation}
                Splitting this into two parts, we get:
                \begin{equation}
                    \frac{1}{3^{n}}\sum_{k=0}^{n-1}3^{k}=
                    \frac{1}{2}-\frac{1}{2\cdot{3}^{n}}
                \end{equation}
                And this decays to zero. Thus, we see that the
                least upper bound is $\frac{1}{2}$, since for all
                $\varepsilon>0$ there is an $N\in\mathbb{N}$ such
                that $(2\cdot{3^{N}})^{\minus{1}}<\varepsilon$,
                and thus there are elements of the set that are
                arbitrarily close to $\frac{1}{2}$. Moreover,
                $\frac{1}{2}$ is an upper bound, since every
                element of the set is strictly less than it.
                Using the final equation, we see that the elements
                are strictly increasing as $n$ increasing, and
                thus the greatest lower bound is simply the
                first element, $\frac{1}{3}$. Lastly, find the
                greatest lower bound and least upper bound for:
                \begin{equation}
                    C=\{\sqrt{2},\sqrt{2+\sqrt{2}},
                        \sqrt{2+\sqrt{2+\sqrt{2}}},\dots\}
                \end{equation}
                We see that the pattern is:
                \begin{equation}
                    x_{n+1}=\sqrt{2+\sqrt{x_{n}}}
                \end{equation}
                Thus, this sequence is strictly increasing as
                $n$ increases. From this we know that
                $\sqrt{2}$ is the greatest lower bound. Now we
                must show that the set has a least upper bound.
                Let $x$ be the solution to the equation
                $x=\sqrt{2+\sqrt{x}}$. We know such a solution
                exists since this equation simplifies to a
                quartic polynomial with roots. Then:
                \begin{align}
                    |x-x_{n+1}|&=
                    |\sqrt{2+\sqrt{x}}-\sqrt{2+\sqrt{x_{n}}}|\\
                    &=\Big|\frac{\sqrt{x}-\sqrt{x_{n}}}
                        {\sqrt{2+\sqrt{x}}+\sqrt{2+\sqrt{x_{n}}}}
                    \Big|\\
                    &<\Big|\frac{\sqrt{x}-\sqrt{x_{n}}}{2\sqrt{2}}
                        \Big|\\
                    &=\Big|\frac{x-x_{n}}
                        {2\sqrt{2}(\sqrt{x}+\sqrt{x_{n}})}\Big|\\
                \end{align}
                But we not that
                $\sqrt{x}+\sqrt{x_{n}}>2\sqrt{x_{n}}>2\sqrt{2}$,
                and obtain:
                \begin{equation}
                    |x-x_{n+1}|<\frac{1}{8}|x-x_{n}|
                \end{equation}
                Similarly:
                \begin{equation}
                    |x-x_{n+2}|<\frac{1}{8}|x-x_{n+1}|<
                    \frac{1}{8^{2}}|x-x_{n}|
                \end{equation}
                By induction:
                \begin{equation}
                    |x-x_{n+k}|<\frac{1}{8^{k}}|x-x_{n}|
                \end{equation}
                And this tends to zero, and therefore
                $x_{n}\rightarrow{x}$. Thus, $x$ is the least
                upper bound.
            \end{lexample}
    \section{Old Notes}
        The real line, or real number system, is a complete ordered
        field. That is, it is complete in the sense that all
        Cauchy sequences converge, has a total order structure
        on it, and has a field structure (That of addition,
        multiplication, subtraction, and division).
        An open subset of the real line is a set $S$ such that
        for all $x\in{S}$ there is an $\varepsilon>0$ such that
        $(x-\varepsilon,x+\varepsilon)\subset{S}$. The entire
        space $\mathbb{R}$ is open, as is the empty set
        $\emptyset$. The union of
        an arbitrary collection of open sets is open, and the
        intersection of finitely many open sets is open. The
        intersection of infinitely many open sets may not be
        open, however. A set is closed if its complement is
        open. The Euclidean plane is the set of all ordered
        pairs $(a,b)$. That is,
        $\mathbb{R}^{2}=\mathbb{R}\times\mathbb{R}$. Euclidean
        space, or 3-space, is
        $\mathbb{R}^{3}=\mathbb{R}\times\mathbb{R}\times\mathbb{R}$.
        This is the set of all ordered triplets $(x,y,z)$. Similarly,
        $n$ dimensional Euclidean space is the set of all
        $n$ tuples. This is denoted $\mathbb{R}^{n}$. The distance
        between two points $\mathbf{x}$ and $\mathbf{y}$ is defined
        by the generalized Pythagorean Theorem:
        \begin{equation*}
            d(\mathbf{x},\mathbf{y})=
            \sqrt{\sum_{k=1}^{n}(x_{k}-y_{k})^{2}}
        \end{equation*}
        \begin{definition}
            A metric on a set $X$ is a function
            $d:X\times{X}\rightarrow\mathbb{R}$ such that:
            \begin{enumerate}
                \item $d(x,y)\geq{0}$ for all $x,y\in{X}$.
                \item $d(x,y)=0$ if and only if $x=y$.
                \item $d(x,y)=d(y,x)$ for all $x,y\in{X}$.
                \item $d(x,z)\leq{d(x,y)+d(y,z)}$
                      for all $x,y,z\in{X}$.
            \end{enumerate}
        \end{definition}
        There are two types of integrals defined for functions
        of a real variable: Riemann Integration and Lebesgue Integration.
        Lebesgue integration requires the notion of \textit{measure}.
    \subsection{Definitions}
        \begin{definition*}
                The tangent line of a differentiable function
                $y:\mathbb{R}\rightarrow\mathbb{R}$ at a point
                $x_{0}\in\mathbb{R}$ is the function
                $y_{T}:\mathbb{R}\rightarrow\mathbb{R}$ defined by
                $y_{T}(x)=y'(x_0)(x-x_0)+y(x_0)$ 
            \end{definition*}
        \begin{definition*}
            If $\Gamma(t)=\big(x(t),y(t)\big)$, for $a\leq t\leq b$,
            and $\Gamma'(t)=\big(x'(t),y'(t)\big)$ exists for
            $a<t<b$, then the length of $\Gamma$ from $a$ to $b$ is:
            \begin{equation}
                L=\int_{a}^{b}\sqrt{
                    \bigg(\frac{dx}{dt}\bigg)^{2}+
                    \bigg(\frac{dy}{dt}\bigg)^{2}
                }dt
            \end{equation}
        \end{definition*}
        \begin{definition*}
            The dimension of a vector space is the cardinality of
            any basis of the space. 
        \end{definition*}
        \begin{remark*}
            By the Dimension Theorem, all bases of a vector space
            have the same cardinality.
        \end{remark*}
    \subsection{Theorems}
    \begin{theorem*}[Mean Value Theorem]
        If $f:(a,b)\rightarrow\mathbb{R}$ is continuous and
        bounded, and if $x\in(a,b)$, then there is a $c\in(a,x)$
        such that $\int_{a}^{x}f=(x-a)f(c)$.
    \end{theorem*}
    \begin{theorem*}
        [Generalized Fundamental Theorem of Calculus]
        If $\mathcal{U}$ is an open non-empty subset of
        $\mathbb{R}$, $a\in\mathcal{U}$, and if
        $f:\mathcal{U}\rightarrow\mathbb{R}$
        is bounded and continuous, then
        $F:\mathcal{U}\rightarrow\mathbb{R}$
        defined by $F(x)=\int_{\mathcal{U}\cap (a,x)}f$ is
        differentiable and $F'(x)=f(x)$
    \end{theorem*}
    \begin{proof}
        For let $x\in\mathcal{U}$. Let
        $\{x_n\}_{n=1}^{\infty}\subset\mathcal{U}$
        be a sequence such that $x_{n}\rightarrow x$,
        $x\notin\{x_{n}\}_{n=1}^{\infty}$.
        As $\mathcal{U}$ is open and $x\in\mathcal{U}$,
        there is an $\varepsilon>0$ such that
        $B_{\varepsilon}(x)\subset\mathcal{U}$. But, as
        $x_{n}\rightarrow x$, there is an $N\in \mathbb{N}$ such
        that for all $n>N$, $x_{n}\in B_{\varepsilon}(x)$.
        But then for all $n>N$:
        \begin{equation*}
            \int_{\mathcal{U}\cap(a,x)}f-%
            \int_{\mathcal{U}\cap(a,x_{n})}f=%
            \int_{x_{n}}^{x}f
        \end{equation*}
        But, as $f$ is continuous, by the mean value theorem for
        all $n>N$ there is a $c_{n}\in(x_n,x)$ such that
        $\int_{x_{n}}^{x}f=(x-x_{n})f(c_{n})$. But then 
        \begin{equation*}
            \Big|\frac{\int_{x_{n}}^{x}f}{x-x_{n}}-f(x)\Big|
            =|f(c_{n})-f(x)|
        \end{equation*}
        But $c_{n}\in(x_{n},x)$, and $x_{n}\rightarrow x$, and
        therefore $c_{n} \rightarrow x$. But $f$ is continuous,
        and therefore $f(c_{n})\rightarrow f(x)$. Therefore, by
        the definition of the derivative of $F$ at $x$,
        $F'(x)=f(x)$. 
    \end{proof}
    \begin{theorem*}
        If $V$ is a vector space and $A,B\subset V$ are
        subspaces, then $A\cap B$ is a subspace and
        $\dim(A\cap B)\leq\min\{\dim(A),\dim(B)\}$
    \end{theorem*}
    \begin{theorem*}
        If $f:\mathbb{R}\rightarrow \mathbb{R}$
        is differentiable
        and $f'(x)>0$ for all $x$,
        then $f$ is strictly increasing.
    \end{theorem*}
    \begin{theorem*}
        If $f:(a,b)\rightarrow\mathbb{R}$ is continuous and
        $f(a)<0<f(b)$, then there is a $c\in (a,b)$ such that
        $f(c)=0$.
    \end{theorem*}
    \begin{theorem*}
        If $f$ is integrable on $(a,b)$, and if $c\in(a,b)$, then
        $\int_{a}^{b}f=\int_{a}^{c}f+\int_{c}^{b}f$
    \end{theorem*}
    \section{Definitions and Theorems}
        \subsection{Definitions}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Sets}
                A set is a collection of elements, none of which
                are the set itself.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:EmptySet}
                The empty set is the set $\emptyset$
                such that $\forall_{x}$, $x\notin A$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Subsets}
                A subset of a set $A$ is a set $B$, denoted
                $B\subset A$, such that $\forall_{x\in B}$,
                $x\in A$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Equality}
                Equal sets are sets $A$ and $B$, denoted $A=B$,
                such that $A\subset B$ and $B\subset A$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:OrderedPair}
                An ordered pair of an element $a$ with respect
                to an element $b$, denoted $(a,b)$,
                is the set $(a,b)=\{\{a\},\{a,b\}\}$
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:CartesianProduct%
                }
                The Cartesian Product of a set $A$ with respect
                to a set $B$, denoted $A\times B$, is the set
                $A\times B=\{(a,b):a\in A,b\in B\}$
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:BinaryRelation%
                }
                A binary relation on a set $X$ is
                a subset $R$ of $X\times X$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:ComparableElements%
                }
                Comparable elements in a set $X$ with respect
                to a binary relation $R$
                are elements $x,y\in X$ such that either
                $(x,y)\in R$, denoted $xRy$,
                or $(y,x)\in R$, denoted $yRx$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:ConnexRelation%
                }
                A connex relation on a set $X$ is a
                binary relation $R$ on $X$ such that
                $\forall_{x,y\in X}$, either $xRy$ or $yRx$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:TransitiveRelation%
                }
                A transitive relation on a set $X$
                is a binary relation $R$ on $X$ such
                that $\forall_{x,y,z\in X}$,
                $xRy\land yRz\Rightarrow xRz$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:AntisymmetricRelation%
                }
                An antisymmetric relation is a binary relation
                $R$ on a set $X$ such that
                $\forall_{x,y\in X}$, $xRy\land yRx\Rightarrow x=y$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:TotalOrder}
                A total order on a set $X$ is a binary relation $R$
                on $X$ that is a transitive relation, an
                antisymmetric relation, and a connex relation.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:TrichotomousRelation%
                }
                A trichotomous relation on a set $X$ is a
                binary relation $R$ on $X$ such that
                $\forall_{x,y\in X}$ precisely one of the
                following are true: $xRy$, $yRx$, or $x=y$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Function}
                A function $f$ from a set $A$ to a set $B$,
                denoted $f:A\rightarrow B$,
                is a subset $f\subset A\times B$ such that
                $\forall_{a\in A}$ there is
                a unique $b\in B$ such that $(a,b)\in f$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Image}
                The image of an element $x\in A$ with respect to a
                function $f:A\rightarrow B$, denoted $f(x)$, is the
                unique element $b\in B$ such that $(a,b)\in f$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:Sum:BinaryOperation%
                }
                A binary operation on a set $A$ is a function
                $*:A\times A\rightarrow A$
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Product}
                The product of elements $a,b\in A$ with respect
                to a binary operation
                $*$ on $A$, denoted $a*b$, is the image of $(a,b)$
                with respect to $*$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:CommunativeOperation%
                }
                A commutative operation on a set $A$
                is a binary operation $*$ on $A$
                such that $\forall_{x,y\in A}$, $a*b=b*a$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                        Sum:AssociativeOperation%
                }
                An associative operation on a set $A$ is a
                binary operation $*$ on $A$
                such that $\forall_{a,b,c\in A}$, $a*(b*c)=(a*b)*c$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:RightDistribute%
                }
                A binary operation that right distributes
                over a binary operation $+$ on
                a set $A$ is a binary operation $\cdot$ on $A$
                such that $\forall_{a,b,c\in A}$,
                $a\cdot (b+c)=(a\cdot b)+(a\cdot c)$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:LeftDistribute%
                }
                A binary operation that left distributes
                over a binary operation $+$ on
                a set $A$ is a binary operation $\cdot$ on $A$
                such that $\forall_{a,b,c\in A}$,
                $(b+c)\cdot a=(b\cdot a)+(c\cdot a)$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Distribute}
                A binary operation that distributes over a binary
                operation $+$ on a set $A$ is a binary operation
                $\cdot$ on $A$ such that $\cdot$ both left and right
                distributes over $+$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:LeftIdentity}
                A left identity in a set $A$ with respect
                to a binary operation $*$ is
                an element $e\in A$ such that $\forall_{a\in A}$,
                $e*a=a$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:RightIdentity}
                A right identity in a set $A$ with respect to a
                binary operation $*$ is an element $e\in A$
                such that $\forall_{a\in A}$, $a*e=a$.
            \end{definition}
            \begin{definition}
                \label{%
                    Definition:MathEnc:Analysis:%
                    Sum:IdentityElement%
                }
                An identity element in a set $A$ with
                respect to a binary operation $*$
                on $A$ is an element $e\in A$ that is
                both a right and a left identity.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:LeftInverse}
                A left inverse of an element $a\in A$ with
                respect to a binary operation $*$
                on $A$ and an identity $e\in A$ is an element
                $b\in A$ such that $b*a=e$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:RightInverse}
                A right inverse of an element $a\in A$ with
                respect to a binary operation $*$
                on $A$ and an identity $e\in A$ is an element
                $b\in A$ such that $a*b=e$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Inverse}
                An inverse of an element $a\in A$ with respect to a
                binary operation $*$ on $A$ and an identity
                $e\in A$ is an element $b\in A$ that is both a
                right and a left inverse of $a$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Semigroup}
                A semigroup is an ordered pair $(A,*)$ such that
                $A$ is a set and $*$ is an associative binary
                operation on $A$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Monoid}
                A monoid is a semigroup $(A,*)$ such that
                $\exists e\in A$ such that $e$ is
                and identity element with respect to $*$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Group}
                A group is a monoid $(G,*)$, denoted
                $\langle G,*\rangle$, with an identity
                element $e$ such that
                $\forall_{a\in A}\exists_{b\in A}:a*b=e$ 
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:AbelianGroup}
                An Abelian Group is a group $\langle G,*\rangle$
                such that $*$ is a
                commutative binary operation on $G$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:3Tuple}
                A 3-tuple of an element $a$ with respect
                to an ordered pair $(b,c)$ is the
                set $(a,b,c)=\{\{a\},\{a,\{b,c\}\}\}$
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Ring}
                A ring is a 3-tuple $(A,\cdot,+)$ such that
                $\langle A,+\rangle$ is an
                \hyperref[%
                    Definition:MathEnc:Analysis:%
                    Sum:AbelianGroup%
                ]{Abelian Group},
                $(A,\cdot)$ is a
                \hyperref[%
                    Definition:MathEnc:Analysis:%
                    Sum:Semigroup%
                ]{semigroup},
                and $*$
                \hyperref[%
                    Definition:MathEnc:Analysis:%
                    Sum:Distribute%
                ]{distributes}
                over $+$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:RingUnit}
                A ring with unity is a
                \hyperref[Definition:MathEnc:Analysis:Sum:Ring]{ring}
                $(A,\cdot,+)$ such that $(A,\cdot)$ is a
                \hyperref[%
                    Definition:MathEnc:%
                    Analysis:Sum:Monoid%
                ]{monoid}.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:ComRing}
                A commutative ring is a
                \hyperref[Definition:MathEnc:Analysis:Sum:Ring]{ring}
                $(A,\cdot,+)$ such that $\cdot$ is a
                \hyperref[%
                    Definition:MathEnc:%
                    Analysis:Sum:CommunativeOperation%
                ]{commutative}
                binary operation over $A$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:ComRingUnit}
                A commutative ring with unity is a 
                \hyperref[%
                    Definition:MathEnc:%
                    Analysis:Sum:RingUnit%
                ]{ring with unity}
                such that $\cdot$ is a
                \hyperref[%
                    Definition:MathEnc:%
                    Analysis:Sum:CommunativeOperation%
                ]{commutative}
                binary operation over $A$.
            \end{definition}
            \begin{definition}
                \label{Definition:MathEnc:Analysis:Sum:Field}
                A field is a 
                \hyperref[%
                    Definition:MathEnc:%
                    Analysis:Sum:ComRingUnit%
                ]{commutative ring with unity}
                $(A,\cdot,+)$ such that $\forall_{a\in A}$
                such that $a$ is not an identity with respect
                to $\cdot$, $\exists_{b\in A}$ such that $b$ is an
                \hyperref[%
                    Definition:MathEnc:Analysis:%
                    Sum:Inverse%
                ]{inverse} of $a$ with respect to $\cdot$.
            \end{definition}
        \subsection{Theorems}
            \begin{theorem}
                \label{%
                    Theorem:MathEnc:Analysis:Sum:SqurPresIneqPosNum%
                }
                If $a,b\in\mathbb{R}^{+}$ and $a<b$,
                then $a^{2}<b^{2}$
            \end{theorem}
            \begin{proof}
                If $a<b$, and $0<a$, then $a\cdot a<a\cdot b$
                \hfill
                (Multiplicative Property of Ordered Fields)\par
                But $a\cdot a = a^{2}$, and thus $a^{2}<a\cdot b$
                \hfill
                (Definition of Exponents)\par
                But if $a<b$ and $0<b$, then $a\cdot b<b\cdot b$
                \hfill
                (Multiplicative Property of Ordered Fields)\par
                Therefore $a\cdot b<b^{2}$
                \hfill
                (Definiiton of Exponents)\par
                But if $a^{2}<a\cdot b$ and $a\cdot b<b^{2}$,
                then $a^{2}<b^{2}$
                \hfill
                (Transitive Property of Inequalities)\par
                Therefore, $a^{2}<b^{2}$
            \end{proof}
            \begin{theorem}
                If $a,b\in\mathbb{R}^{+}$ and $a^{2}=b^{2}$,
                then $a=b$.
            \end{theorem}
            \begin{proof}
                If $a^{2}=b^{2}$, then $b^{2}-a^{2}=0$\hfill
                (Additive Property of Ordered Fields)\par
                If $a<b$, then $0<b-a$\hfill
                (Additive Property of Ordered Fields)\par
                If $a,b\in\mathbb{R}^{+}$, then $0<b+a$
                \hfill
                (Closure of Addition in $\mathbb{R}^{+}$)\par
                If $0<b-a$ and $0<b+a$, then $0<(b-a)\cdot (b+a)$
                \hfill
                (Closure of Multiplication in $\mathbb{R}^{+}$)\par
                But $(b-a)\cdot(b+a)=b^{2}-a^{2}$
                \hfill
                (Elementary Algebra)\par
                But $b^{2}-a^{2}=0$, and thus $0\not<b^{2}-a^{2}$
                \hfill
                (Trichotomous Property of Inequalities)\par
                Therefore, $a\not<b$. Similarly, $b\not<a$
                \hfill
                (Proof by Contradiction)\par
                But if $a\not<b$ and $b\not<a$, then $a=b$
                \hfill
                (Trichotomous Property of Inequalities)\par
                Therefore, $a=b$
            \end{proof}
            \begin{theorem}
                If $y\in(0,1)$, then there is an $x\in(0,1)$
                such that $y=x^{2}$.
            \end{theorem}
            \begin{proof}
                Let $A=\{\xi\in\mathbb{R}^{+}:\xi^{2}\leq y\}$.\par
                But $y\in(0,1)$ and therefore $y<1$\hfill
                (Definition of $(0,1)$)\par
                Therefore $A$ is bounded above by $1$.\par
                Thus there exists a
                least upper bound $x$ of $A$\hfill
                (Completeness of $\mathbb{R}$)\par
                If $x^{2}>y$, then $\frac{x^{2}-y}{2}>0$.\hfill
                (Additive Property of Ordered Fields)\par
                Then
                $(x-\frac{x^{2}-y}{2})^{2}=%
                 a+(\frac{x^{2}-y}{2})^{2}>y$\hfill
                (Additive Property of Ordered Fields)\par
                Thus $x-\frac{x^{2}-y}{2}$ is an
                upper bound of A.\hfill
                (Definition of Upper Bounds)\par
                But $x$ is the least upper bound,
                a contradiction.\par
                Therefore $x^{2}\not>a$.\hfill
                (Proof by Contradiction)\par
                If $x^{2}<y$, then $0<\frac{y-x^{2}}{2x+1}$\hfill
                (Additive Property of Ordered Fields)\par
                Let $\epsilon=\min\{\frac{y-x^{2}}{2x+1},1\}$\par
                Then
                $(x+\epsilon)^{2}=x^{2}+2x\epsilon+\epsilon^{2}%
                 <x^{2}+2x\epsilon+\epsilon$\hfill
                (Thm.~\ref{%
                    Theorem:MathEnc:Analysis:%
                    Sum:SqurPresIneqPosNum%
                })\par
                But
                $x^{2}+2x\epsilon+\epsilon=x^{2}+(2x+1)\epsilon=y$
                \hfill (Elementary Algebra)\par
                Therefore $(x+\epsilon)^{2}<y$\hfill
                (Transitive Property of Total Orders)\par
                But $\epsilon>0$, and thus $x+\epsilon>x$.\hfill
                (Additive Property of Ordered Fields)\par
                Thus $x+\epsilon\in A$, a contradiction as
                $x$ is a least upper bound of $A$.\par
                Therefore $x^{2}\not<y$.\hfill
                (Proof by Contradiction)\par
                Therefore $x^{2}=y$\hfill
                (Trichotomous Property of Inequalities)\par
            \end{proof}
\end{document}