\documentclass[crop=false,class=article,oneside]{standalone}
%----------------------------Preamble-------------------------------%
\input{../../preamble.tex}
%--------------------------Main Document----------------------------%
\begin{document}
    \title{Functional Analysis: HW 1}
    \author{Ryan Maguire}
    \date{\vspace{-5ex}}
    \maketitle
    \setcounter{section}{1}
    \begin{problem}
        Show that, for $1\leq{p}\leq{q}\leq\infty$, that
        $\norm{\cdot}_{p}$ and $\norm{\cdot}_{q}$ are strongly
        equivalent.
    \end{problem}
    \begin{solution}
        First, if $X$ is a set, $d_{1},d_{2},d_{3}$ are metrics on
        $X$, and if $d_{1}$ is strongly equivalent to $d_{2}$, and
        $d_{2}$ is strongly equivalent to $d_{3}$, then $d_{1}$ is
        strongly equivalent to $d_{3}$. For if $d_{1}$ is strongly
        equivalent to $d_{2}$, then there are $\alpha,\beta>0$ such
        that, for all $x,y\in{X}$:
        \begin{equation}
            \alpha{d}_{1}(x,y)\leq{d}_{2}(x,y)\leq\beta{d}_{1}(x,y)
        \end{equation}
        But we have seen that strongly equivalent is a symmetric
        relation, and therefore if $d_{2}$ and $d_{3}$ are strongly
        equivalent then there are $a,b>0$ such that:
        \begin{equation}
            ad_{3}(x,y)\leq{d}_{2}(x,y)\leq{b}d_{3}(x,y)
        \end{equation}
        Therefore:
        \begin{equation}
            \frac{\alpha}{b}d_{1}(x,y)\leq{d}_{3}(x,y)
            \leq\frac{\beta}{a}d_{1}(x,y)
        \end{equation}
        Thus, strongly equivalent is a transitive relation.
        Let $n\in\mathbb{N}$, $p\in[1,\infty)$, and let
        $\mathbf{x}\in\mathbb{R}^{n}$. Then, since
        $\norm{\mathbf{x}}_{\infty}$ is the supremum norm, it is greater
        than or equal to all of the compononents of $\mathbf{x}$. Thus:
        \begin{equation}
            n\norm{\mathbf{x}}_{\infty}^{p}=
            \sum_{k=1}^{n}\norm{\mathbf{x}}_{\infty}^{p}
            \geq\sum_{k=1}^{n}|x_{k}|^{p}=\norm{\mathbf{x}}_{p}^{p}
        \end{equation}
        Taking $p^{th}$ roots, we have:
        \begin{equation}
            n^{\frac{1}{p}}\norm{\mathbf{x}}_{\infty}
            \geq\norm{\mathbf{x}}_{p}
        \end{equation}
        Going the other way:
        \begin{equation}
            \norm{\mathbf{x}}_{\infty}^{p}\leq
            \sum_{k=1}^{n}|x_{k}|^{p}
        \end{equation}
        Taking $p^{th}$ roots again, we obtain the following:
        \begin{equation}
            \norm{\mathbf{x}}_{\infty}\leq\norm{\mathbf{x}}_{p}
            \leq{n}^{\frac{1}{p}}\norm{\mathbf{x}}_{\infty}
        \end{equation}
        Thus, for all $p\in[1,\infty)$, $\norm{\cdot}_{p}$ is strongly
        equivalent to $\norm{\cdot}_{\infty}$. But strongly equivalent
        is a transitive relation, thus for all
        $p,q\in[1,\infty]$, $\norm{\cdot}_{p}$ is strongly equivalent to
        $\norm{\cdot}_{q}$.
    \end{solution}
    \begin{problem}
        Give an example of a metric on $\mathbb{R}^{n}$ that is not
        strongly equivalent to $\norm{\cdot}_{p}$ for any
        $p\in[1,\infty]$.
    \end{problem}
    \begin{solution}
        The discrete metric is not strongly equivalent to any of the
        metrics induced by $\norm{\cdot}_{p}$. For suppose not. Then:
        \begin{equation}
            \alpha\norm{\mathbf{x}}_{p}\leq
            d(\mathbf{x},\mathbf{0})\leq{1}
        \end{equation}
        Where $d$ is the discrete metric. But $\norm{\mathbf{x}}_{p}$
        is unbounded, and thus if $\alpha\norm{\mathbf{x}}_{p}\leq{1}$,
        $\alpha=0$. Thus there is no $\alpha>0$ that satisfies the
        inequality.
    \end{solution}
    \begin{problem}
        Show that, if $a,b\geq{0}$ and $0<\lambda<1$, then:
        \begin{equation}
            a^{\lambda}b^{1-\lambda}\leq\lambda{a}+(1-\lambda)b
        \end{equation}
    \end{problem}
    \begin{solution}
        If $a=0$ or $b=0$, then we are done. Suppose not.
        Define $t=ab^{\minus{1}}$.
        Then, if $\lambda\in(0,1)$, and $t\geq{1}$, we have:
        \begin{subequations}
            \begin{align}
                \lambda(t^{\lambda-1}-1)&\geq0\\
                \Rightarrow\int_{1}^{t}\lambda
                    \Big(\tau^{\lambda-1}-1\Big)\diff{\tau}
                    &\geq{0}\\
                \Rightarrow
                (t^{\lambda}-\lambda{t})-(1-\lambda)&\geq{0}
            \end{align}
        \end{subequations}
        For $t\in(0,1)$, we have:
        \begin{subequations}
            \begin{align}
                \lambda(t^{\lambda-1}-1)&\leq{0}\\
                \Rightarrow\int_{t}^{1}\lambda
                    \Big(\tau^{\lambda-1}-1\Big)\diff{\tau}
                    &\leq{0}\\
                \Rightarrow
                (1-\lambda)-(t^{\lambda}-\lambda{t})&\leq{0}
            \end{align}
        \end{subequations}
        Combining these two, we have for $t\in(0,\infty)$:
        \begin{equation}
            t^{\lambda}-\lambda{t}\leq{1}-\lambda
        \end{equation}
        But $t=ab^{\minus{1}}$, and thus multiplying through by $b$:
        \begin{equation}
            a^{\lambda}b^{\lambda-1}\leq
            \lambda{a}+(1-\lambda)b
        \end{equation}
    \end{solution}
    \begin{problem}
        Prove H\"{o}lder's Inequality: If $p\in(1,\infty)$,
        $p^{\minus{1}}+q^{\minus{1}}=1$, then:
        \begin{equation}
            \norm{fg}_{1}\leq\norm{f}_{p}\norm{g}_{q}
        \end{equation}
    \end{problem}
    \begin{solution}
        For let:
        \par
        \begin{subequations}
            \begin{minipage}[b]{0.49\textwidth}
                \centering
                \begin{equation}
                    \tilde{f}=\frac{f}{\norm{f}_{q}}
                \end{equation}
            \end{minipage}
            \hfill
            \begin{minipage}[b]{0.49\textwidth}
                \centering
                \begin{equation}
                    \tilde{g}=\frac{g}{\norm{g}_{q}}
                \end{equation}
            \end{minipage}
        \end{subequations}
        \par\hfill\par
        Then $\norm{\tilde{f}}_{p}=1$ and $\norm{\tilde{g}}_{q}=1$.
        But if $p\in(1,\infty)$, then $p^{\minus{1}}<1$, and thus by the
        previous problem:
        \begin{equation}
            |\tilde{f}(x)\tilde{g}(x)|\leq
                p^{\minus{1}}|\tilde{f}(x)|^{p}+
                (1-p^{\minus{1}})|\tilde{g}(x)|^{q}
        \end{equation}
        But $1-p^{\minus{1}}=q^{\minus{1}}$, so we have:
        \begin{equation}
            |\tilde{f}(x)\tilde{g}(x)|\leq
                p^{\minus{1}}|\tilde{f}(x)|^{p}+
                q^{\minus{1}}|\tilde{g}(x)|^{q}
        \end{equation}
        Integrating, we get:
        \begin{subequations}
            \begin{align}
                \norm{\tilde{f}\tilde{g}}_{1}
                &=\int_{\mathbb{R}}|\tilde{f}(x)\tilde{g}(x)|\diff{x}\\
                &\leq\int_{\mathbb{R}}\Big(
                    p^{\minus{1}}|\tilde{f}(x)|^{p}+
                    q^{\minus{1}}|\tilde{g}(x)|^{q}\Big)\diff{x}\\
                &=p^{\minus{1}}\norm{\tilde{f}}_{p}^{p}+
                q^{\minus{1}}\norm{\tilde{g}}_{q}^{q}\\
                &=p^{\minus{1}}+q^{\minus{1}}
            \end{align}
        \end{subequations}
        But $p^{\minus{1}}+q^{\minus{1}}=1$, and thus
        $\norm{\tilde{f}\tilde{g}}_{1}=1$. But from the definition of
        $\tilde{f}$ and $\tilde{g}$, we can multiply through by
        $\norm{f}_{p}\norm{g}_{q}$ to obtain:
        \begin{equation}
            \norm{fg}_{1}\leq\norm{f}_{p}\norm{g}_{q}
        \end{equation}
    \end{solution}
    \begin{problem}
        Prove Minkowski's Inequality
    \end{problem}
    \begin{problem}
        A limit point of a subspace $(E,d_{E})$ of a metric
        space $(X,d)$ is a point $x\in{X}$ such that there
        exists a sequence $a:\mathbb{N}\rightarrow{E}$ such
        that $a_{n}\rightarrow{x}$. Prove that $E$ is closed
        if and only if it has all of it's limit points.
    \end{problem}
    \begin{solution}
        Suppose $E$ is closed and let $x$ be a limit point
        of $E$. Suppose $x\in{E}^{C}$. But if $E$ is closed,
        then $E^{C}$ is open, and thus there is an $r>0$
        such that:
        \begin{equation}
            B_{r}^{(X,d)}(x)\subseteq{E}^{C}
        \end{equation}
        But if $x$ is a limit point of $E$ then there is a
        sequence $a:\mathbb{N}\rightarrow{E}$ such that
        $a_{n}\rightarrow{x}$. But if $a_{n}\rightarrow{x}$ then
        there is an $N\in\mathbb{N}$ such that, for all $n\in\mathbb{N}$
        such that $n>N$, it is true that $d(x,a_{n})<r/2$. But then,
        for all $n>N$, $a_{n}\in{B}_{r}^{(X,d)}(x)$, and thus
        $a_{n}\in{E}^{C}$. But $a_{n}\in{E}$, a contradiction. Thus,
        $x\in{E}$. Now, suppose $x$ has all of it's limit points and
        suppose $E$ is not closed. Then $E^{C}$ is not open. But then
        there is an $x\in{E}^{C}$ such that, for all $\varepsilon>0$:
        \begin{equation}
            B_{\varepsilon}^{(X,d)}(x)\cap{E}\ne\emptyset
        \end{equation}
        Define the following:
        \begin{equation}
            A_{n}=\Big\{y\in{E}:d(x,y)<\frac{1}{n}\Big\}
        \end{equation}
        Then for all $n\in\mathbb{N}$, $A_{n}$ is non-empty.
        By choice there is a sequence $a:\mathbb{N}\rightarrow{E}$ such
        that, for all $n\in\mathbb{N}$, $a_{n}\in{A}_{n}$. But then,
        for all $n\in\mathbb{N}$, $d(a_{n},x)<n^{\minus{1}}$. Thus
        $a_{n}\rightarrow{x}$ and therefore $x$ is a limit point of $E$.
        But $x\in{E}^{C}$, a contradiction as $E$ contains all of its
        limit points. Therefore, $E$ is closed.
    \end{solution}
    \begin{problem}
        State and prove a result characterizing open sets in a metric
        space in terms of sequences, similar to the previous problem.
    \end{problem}
    \begin{solution}
        A subset $\mathcal{U}\subseteq{X}$ of a metric space $(X,d)$ is
        open if and only if for any convergence sequence
        $a:\mathbb{N}\rightarrow{X}$ such that the limit of $a$ is in
        $\mathcal{U}$, there is an $N\in\mathbb{N}$ such that, for all
        $n\in\mathbb{N}$ and $n>N$, it is true that
        $a_{n}\in\mathcal{U}$. For suppose $\mathcal{U}$ is open, and
        let $a:\mathbb{N}\rightarrow{X}$ be a convergent sequence such
        that there is an $x\in\mathcal{U}$ such that
        $a_{n}\rightarrow{x}$. But if $\mathcal{U}$ is open then there
        is an $\varepsilon>0$ such that:
        \begin{equation}
            B_{\varepsilon}^{(X,d)}(x)\subseteq\mathcal{U}
        \end{equation}
        But if $a_{n}\rightarrow{x}$ then there is an
        $N\in\mathbb{N}$ such that, for all $n\in\mathbb{N}$ such that
        $n>N$, it is true that $d(x,a_{n})<\varepsilon$. But then for all
        $n>N$, $n\in\mathbb{N}$, we have
        $a_{n}\in{B}_{\varepsilon}^{(X,d)}(x)$, and thus
        $a_{n}\in\mathcal{U}$. Now suppose for any sequence that converges
        to a point in $\mathcal{U}$, the sequence is eventually contained
        within $\mathcal{U}$. Suppose $\mathcal{U}$ is not open. Then
        there is an $x\in\mathcal{U}$ such that, for all $\varepsilon>0$
        there is a $y\in\mathcal{U}^{C}$ such that
        $d(x,y)<\varepsilon$. Define the following:
        \begin{equation}
            A_{n}=\Big\{y\in\mathcal{U}^{C}:d(x,y)<\frac{1}{n}\Big\}
        \end{equation}
        Then for all $n\in\mathbb{N}$, $A_{n}$ is non-empty. By choice
        there is a sequence $a:\mathbb{N}\rightarrow\mathcal{U}^{C}$ such
        that $a_{n}\in{A}_{n}$. But then $a_{n}\rightarrow{x}$. But if
        $a_{n}\rightarrow{x}$, then there is an $N\in\mathbb{N}$ such that
        for all $n\in\mathbb{N}$ such that $n>N$ it is true that
        $a_{n}\in\mathcal{U}$, a contradiction. Therefore,
        $\mathcal{U}$ is open.
    \end{solution}
    \begin{problem}
        Let $\rho$ and $\sigma$ be metrics on $X$ and show that
        $\rho$ and $\sigma$ are equivalent if and only if they have
        the same convergent sequences.
    \end{problem}
    \begin{solution}
        For a sequence $a:\mathbb{N}\rightarrow{X}$ converges to
        $x\in{X}$ if and only if for all open subsets
        $\mathcal{U}\subseteq{X}$ such that $x\in\mathcal{U}$, there is
        an $N\in\mathbb{N}$ such that, for all $n\in\mathbb{N}$ and
        $n>N$, it is true that $a_{n}\in\mathcal{U}$. Going one way,
        if $a_{n}\rightarrow{x}$ then for all $\varepsilon>0$ there is
        an $N\in\mathbb{N}$ such that for all $n\in\mathbb{N}$ and
        $n>N$, it is true that $d(x,a_{n})<\varepsilon$. Let
        $\mathcal{U}$ be an open subset such that $x\in\mathcal{U}$.
        But then there is an $\varepsilon>0$ such that:
        \begin{equation}
            B_{\varepsilon}^{(X,d)}(x)\subseteq\mathcal{U}
        \end{equation}
        But there is an $N\in\mathbb{N}$ such that, for all $n>N$,
        $n\in\mathbb{N}$, we have $a_{n}\in{B}_{\varepsilon}^{(X,d)}(x)$.
        Therefore $a_{n}\in\mathcal{U}$. Going the other way, let:
        \begin{equation}
            A_{k}=B_{k^{\minus{1}}}^{(X,d)}(x)
        \end{equation}
        Given $\varepsilon>0$ there is a $k\in\mathbb{N}$ such that
        $k^{\minus{1}}<\varepsilon$. But for all $k\in\mathbb{N}$,
        $A_{k}$ is open and $x\in{A}_{k}$, and thus there is an
        $N\in\mathbb{N}$ such that $n>N$ and $n\in\mathbb{N}$ implies
        $a_{n}\in{A}_{n}$. But then $d(x,a_{n})<\varepsilon$, so
        $a_{n}\rightarrow{x}$. This converts the notion of convergence from
        a metric space property to a topological property. If
        $(X,\rho)$ and $(X,\sigma)$ are equivalent then they have the
        same open sets, and thus convergence of sequences is preserved.
        For suppose $a:\mathbb{N}\rightarrow{X}$ converges to $x$ with
        respect to $\rho$. Then, for all open subsets $\mathcal{U}$ of
        $(X,d)$ such that $x\in\mathcal{U}$, there is an $N\in\mathbb{N}$
        such that, for all $n\in\mathbb{N}$ and $n>N$, it is true that
        $a_{n}\in\mathcal{U}$. But if $\mathcal{U}$ is open in
        $(X,\rho)$, then it is open in $(X,\sigma)$, for the two metrics
        are equivalent. Thus $a_{n}\rightarrow{x}$ with respect to
        $\sigma$.
    \end{solution}
    \begin{problem}
        Let $(X,\mathcal{M},\mu)$ be a measure space and define
        $\mathcal{U}\subseteq{L}^{1}(X)$ by:
        \begin{equation}
            \mathcal{U}=
                \Big\{f\in{L}^{1}(X):\int_{X}\Re(f)\diff{\mu}<1\Big\}
        \end{equation}
        Prove that $\mathcal{U}$ is open with respect to the
        metric induced by $\norm{\cdot}_{1}$.
    \end{problem}
    \begin{solution}
        For let $f\in{L}^{1}(X)$ and let $M=\norm{f}_{1}$. As
        $f\in{L}^{1}(X)$, $M<\infty$. Let
        Let $\alpha=\int_{X}\Re(f)\diff{\mu}$ and let
        $\varepsilon=\min\{1/2M,1-\alpha\}$
        Then if $\norm{f-g}_{1}<\varepsilon$ we have:
        \begin{equation}
            \int_{X}\Re(g)\diff{\mu}=
            \int_{X}\Re(g-f+f)\diff{\mu}=
            \int_{X}\Re(g-f)\diff{\mu}+\int_{X}\Re(f)\diff{\mu}
        \end{equation}
        We can simplify this further to get:
        \begin{equation}
            \int_{X}\Re(g)\diff{\mu}
            =\int_{X}\Re(g-f)\diff{\mu}+\alpha
            <\varepsilon+\alpha<1
        \end{equation}
        Therefore:
        \begin{equation}
            B_{\varepsilon}^{(L^{1}(X),\norm{\cdot}_{1})}(f)
            \subseteq\mathcal{U}
        \end{equation}
        And thus $\mathcal{U}$ is open.
    \end{solution}
    \begin{problem}
        For a metric space $(X,d)$, define
        $\dist:X\times\mathcal{P}(X)\setminus\{\emptyset\}%
         \rightarrow[0,\infty)$ by:
        \begin{equation}
            \dist(x,A)=\inf\{d(x,y):y\in{A}\}
        \end{equation}
        Prove that $\dist(x,A)=0$ if and only if $x\in\overline{A}$.
        Show that, for a fixed non-empty $A\subseteq{X}$, $\dist(x,a)$ is
        continuous. Prove that if $A,B\subseteq{X}$ are closed disjoint
        non-empty subsets, then there is a continuous function
        $f:X\rightarrow[0,1]$ such that $f(x)=0$ if and only if
        $x\in{A}$ and $f(y)=1$ if and only if $x\in{B}$.
    \end{problem}
    \begin{solution}
        If $x\in\overline{A}$, then for all $\varepsilon>0$:
        \begin{equation}
            B_{\varepsilon}^{(X,d)}(x)\cap{A}\ne\emptyset
        \end{equation}
        Thus $\dist(x,A)<\varepsilon$ for all $\varepsilon$, and therefore
        $\dist(x,A)=0$. If $\dist(x,A)=0$ then for all $\varepsilon>0$
        there is a $y\in{A}$ such that $d(x,y)<\varepsilon$. Therefore
        $x$ is a limit point of $A$, and thus $x\in\overline{A}$.
        \par\hfill\par
        Let $\varepsilon>0$ and let $x\in{X}$, and let $\delta=\varepsilon$.
        Then:
        \begin{subequations}
            \begin{align}
                \dist(y,A)&=\inf\{d(y,z):z\in{a}\}\\
                &\leq\inf\{d(x,y)+d(x,z):z\in{A}\}\\
                &=d(x,y)+\inf\{d(x,z):z\in{A}\}\\
                &=d(x,y)+\dist(x,A)
            \end{align}
        \end{subequations}
        Similarly:
        \begin{equation}
            \dist(x,A)\leq{d}(x,y)+\dist(y,A)
        \end{equation}
        And therefore, if $d(x,y)<\varepsilon$:
        \begin{equation}
            \big|\dist(x,A)-\dist(y,A)\big|\leq{d}(x,y)<\varepsilon
        \end{equation}
        Finally, let:
        \begin{equation}
            f(x)=\frac{\dist(x,B)}{\dist(x,A)+\dist(x,B)}
        \end{equation}
        As $A$ and $B$ are disjoint, $f(x)$ is well defined for all
        $x\in{X}$. Moreover, $0\leq{f(x)}\leq{1}$. If $f(x)=0$, then
        $\dist(x,B)=0$, and thus $x\in\overline{B}$. But $B$ is closed,
        and therefore $x\in{B}$. If $f(x)=1$, then $\dist(x,A)=0$, and
        thus $x\in\overline{A}$. Again, as $A$ is closed, $x\in{A}$.
        But $\dist(x,B)$ is continuous, and $\dist(x,A)+\dist(x,B)$ is
        continuous, and the quotient of continuous functions is continuous.
        Thus, $f$ is continuous.
    \end{solution}
    \begin{problem}
        Show that a Cauchy sequence with a convergent subsequence is
        convergent.
    \end{problem}
    \begin{solution}
        For let $a:\mathbb{N}\rightarrow{X}$ be a Cauchy sequence and
        let $k:\mathbb{N}\rightarrow\mathbb{N}$ be such that
        $a\circ{k}$ is a convergent subsequence, and let $x$ be the limit.
        Let $\varepsilon>0$. There is an $N_{1}\in\mathbb{N}$ such that,
        for all $k_{n}>N_{1}$, $n\in\mathbb{N}$,
        $d(x,a_{k_{n}})<\varepsilon<2$. But $a$ is Cauchy, and thus there
        is an $N_{2}\in\mathbb{N}$ such that, for all $n,m>N_{2}$,
        $d(a_{n},a_{m})<\varepsilon/2$. Let $N=\max\{N_{1},N_{2}\}$.
        But then for all $n>N$:
        \begin{equation}
            d(a_{n},x)\leq
            d(a_{n},a_{k_{n}})+d(a_{k_{n}},x)<\varepsilon
        \end{equation}
        Therefore, $a_{n}\rightarrow{x}$.
    \end{solution}
    \begin{problem}
        Let $F:\mathbb{N}\times{X}\rightarrow\mathbb{C}$ be a sequence
        of continuous functions and let $f:X\rightarrow\mathbb{C}$ be
        such that $F_{n}(x)\rightarrow{f}$ uniformly. Show that $f$ is
        continuous.
    \end{problem}
    \begin{solution}
        For let $\varepsilon>0$. As $F_{n}\rightarrow{f}$ uniformly,
        there is an $N\in\mathbb{N}$ such that for all $x\in{X}$:
        \begin{equation}
            |F_{N}(x)-f(x)|<\frac{\varepsilon}{3}
        \end{equation}
        But $F_{N}(x)$ is continuous, and thus for $x\in{X}$ there is
        a $\delta>0$ such that $d(x,x_{0})<\delta$ implies that:
        \begin{equation}
            |F_{N}(x)-F_{N}(x_{0})|<\frac{\varepsilon}{3}
        \end{equation}
        But then:
        \begin{subequations}
            \begin{align}
                |f(x)-f(x_{0})|&\leq
                |f(x)-F_{N}(x)|+|F_{N}(x)-F_{N}(x_{0})|+
                |F_{N}(x_{0})-f(x_{0})|\\
                &<\frac{\varepsilon}{3}+\frac{\varepsilon}{3}+
                    \frac{\varepsilon}{3}\\
                &=\varepsilon
            \end{align}
        \end{subequations}
        Thus, $f$ is continuous.
    \end{solution}
    \begin{problem}
        Let $X$ be a metric space. Recall that we say
        $f:X\rightarrow\mathbb{C}$ is bounded if
        $\norm{f}_{\infty}<\infty$. A sequence of functions
        $f_{n}:X\rightarrow{D}$ is uniformly bounded if there is an
        $M$ such that $\norm{f_{n}}_{\infty}<M$ for all $n$.
        Also, $f_{n}$ is uniformly Cauchy if for all $\varepsilon>0$
        there is an $N\in\mathbb{N}$ such that $n,m>N$ implies
        $|f_{n}(x)-f_{m}(x)|<\varepsilon$ for all $x\in{X}$. Show that
        a uniformly Cauchy sequence $f_{n}$ of bounded functions is
        uniformly bounded.
    \end{problem}
    \begin{problem}
        We say that $D$ is dense in $X$ if $\overline{D}=X$.
        Show that $D$ is dense if and only if $D$ meets every
        non-empty open subset.
    \end{problem}
    \begin{solution}
        Suppose $D$ is a dense subset of $X$ and let
        $\mathcal{U}\subseteq{X}$ be an open subset. Suppose
        $\mathcal{U}\cap{D}=\emptyset$. Let $x\in\mathcal{U}$. As
        $\mathcal{U}$ is open, there is an $r>0$ such that
        $B_{r}^{(X,d)}(x)\subseteq\mathcal{U}$. But if $D$ is
        dense in $X$, then $x$ is a limit point of $D$. Thus there is
        a sequence $a:\mathbb{N}\rightarrow{D}$ such that
        $a_{n}\rightarrow{x}$. But if $a_{n}\rightarrow{x}$, then there
        is an $N\in\mathbb{N}$ such that, for all $n\in\mathbb{N}$ and
        $n>N$, we have $a_{n}\in{B}_{r}^{(X,d)}(x)$, a contradiction
        as $a_{n}\in{D}$ for all $n$. Therefore, etc. Now suppose
        $D$ meets every open set. Suppose $x\notin\overline{D}$.
        Define the following:
        \begin{equation}
            A_{n}=\Big\{y\in{B}_{1/n}^{(X,d)}(x):y\in{D}\Big\}
        \end{equation}
        Then $A_{n}$ is non-empty for all $n\in\mathbb{N}$, since
        $D$ meets every open set. By choice there is a sequence
        $a:\mathbb{N}\rightarrow{D}$ such that $a_{n}\in{A}_{n}$ for all
        $n\in\mathbb{N}$. But then $x$ is a limit point of $D$, a
        contradiction. Thus, $\overline{D}=X$.
    \end{solution}
    \begin{problem}
        Let $(x_{n})$ be a sequence in a complete metric space
        $(X,\rho)$. Suppose that $\rho(x_{n},x_{n+1})<2^{\minus{1}}$ for
        all $n\in\mathbb{N}$. Conclude that $(x_{n})$ is convergent.
        What if instead we have that $\rho(x_{n},x_{n+1})<1/n$?
    \end{problem}
    \begin{solution}
        For let $\varepsilon>0$. Let $N\in\mathbb{N}$ such that
        $2^{1-N}<\varepsilon$. But then for $n,m>N$:
        \begin{equation}
            \rho(x_{n},x_{m})\leq
            \sum_{k=\min(n,m)}^{\max(n,m)}d(x_{k},x_{k+1})
            \leq\sum_{k=N}^{\infty}d(x_{k},x_{k_{n+1}})
            \leq\sum_{k=N}^{\infty}\frac{1}{2^{k}}
        \end{equation}
        But by applying the geometric series, we have:
        \begin{equation}
            \sum_{k=N}^{\infty}\frac{1}{2^{k}}=2^{1-N}<\varepsilon
        \end{equation}
        Thus $x_{n}$ is Cauchy, and Cauchy sequences converge in a
        complete metric space. Therefore, etc. If we replace
        $2^{\minus{n}}$ with $n^{\minus{1}}$, the result may not hold.
        For let $X=\mathbb{R}$, which is complete with the standard
        metric, and let $a:\mathbb{N}\rightarrow\mathbb{R}$ be defined
        by $a_{n}=\ln(n)$. Applying some calculus, we have:
        \begin{equation}
            d(a_{n+1},a_{n})=\ln(n+1)-\ln(n)
            =\int_{n}^{n+1}\frac{1}{x}\diff{x}<\frac{1}{n}
        \end{equation}
        But $\ln(n)$ is not a convergent sequence.
    \end{solution}
\end{document}