%------------------------------------------------------------------------------%
\documentclass{book}                                                            %
%------------------------------Preamble----------------------------------------%
\makeatletter                                                                  %
    \def\input@path{{../../}}                                                  %
\makeatother                                                                   %
\input{preamble.tex}                                                           %
\makeindex[intoc]                                                              %
%----------------------------Main Document-------------------------------------%
\begin{document}
    \pagenumbering{gobble}
    \pagenumbering{roman}
    \title{MATH 102 Geometry Notes}
    \author{%
        Professor: Carolyn Gordon\\
        Notes by: Ryan Maguire%
    }
    \date{\vspace{-5ex}}
    \maketitle
    \tableofcontents
    \pagenumbering{roman}
    \listoffigures
    \chapter{Lie Groups and Lie Algebras}
    \pagenumbering{arabic}
        \section{Review}
            \subsection{Coordinate Charts in a Manifold}
                A coordinate chart in a manifold $M$ is an open subset
                $\mathcal{U}\subseteq{M}$ together with a homeomorphism
                $\varphi:\mathcal{U}\rightarrow\mathcal{V}$ where $\mathcal{V}$
                is an open subset of $\nspace$ for some $n\in\mathbb{N}$.
                Equivalently, $\varphi:\mathcal{U}\rightarrow\nspace$ is a
                continuous injective open mapping
                (Fig.~\ref{fig:Coordinate_Chart}).
                \begin{figure}[H]
                    \centering
                    \captionsetup{type=figure}
                    \includegraphics{images/Chart_in_a_Manifold.pdf}
                    \caption{A Coordinate Chart in a Manifold}
                    \label{fig:Coordinate_Chart}
                \end{figure}
                \begin{example}
                    Given $n\in\mathbb{N}$, the Euclidean space $\nspace$ can be
                    given a manifold structure by a single coordinate chart. Let
                    $\mathcal{U}=\nspace$ and $\varphi=\identity{\nspace}$.
                    Since the identity is always an autohomeomorphism for any
                    topological space, this shows $(\nspace,\identity{\nspace})$
                    is a coordinate chart.
                \end{example}
                \begin{example}
                    Slightly more general, if $\mathcal{U}$ is an open subset of
                    $\nspace$, then the inclusion mapping
                    $\iota:\mathcal{U}\rightarrow\nspace$ is a homeomorphism
                    onto it's image. The image of $\iota$ being $\mathcal{U}$,
                    and $\identity{\mathcal{U}}$ is a homeomorphism. Thus
                    $(\mathcal{U},\iota)$ is a chart for $\mathcal{U}$ making
                    $\mathcal{U}$ an open submanifold of $\nspace$.
                \end{example}
                \begin{example}
                    We can form a coordinate chart on the sphere by mapping the
                    upper hemisphere down to the plane. That is, if we consider
                    points $(x,y,z)\in\nsphere[2]$ such that $z>0$, we can take
                    this open set $\mathcal{U}^{+}$ and map it to $\nspace[2]$
                    by:
                    \begin{equation}
                        \varphi(x,\,y,\,z)=(x,\,y)
                    \end{equation}
                    This is a continuous injective open mapping, satisfying the
                    criterion for a coordinate chart. This type of chart is
                    called an \textit{orthographic} projection and is shown in
                    Fig.~\ref{fig:Sphere_Orthographic_Projection}. We see
                    $\varphi$ has a continuous inverse on it's image given by:
                    \begin{equation}
                        \varphi^{\minus{1}}(X,\,Y)=
                            \big(X,\,Y,\,\sqrt{1-X^{2}-Y^{2}}\big)
                    \end{equation}
                    Using six such charts shows that the sphere is a topological
                    manifold.
                \end{example}
                \begin{figure}[H]
                    \centering
                    \captionsetup{type=figure}
                    \includegraphics{images/Sphere_Orthographic_Projection.pdf}
                    \caption{Orthographic Projection of a Sphere}
                    \label{fig:Sphere_Orthographic_Projection}
                \end{figure}
                The orthographic projection can be defined by taking an observer
                at the north pole and bringing them off to infinity in the
                \textit{up} direction. The orthographic projection is then what
                they would see if they had an amazing telescope. If we stop at
                some finite distance we wouldn't get the entire northern
                hemisphere (if you climb a small latter at the north pole you
                would not be able to see the equator). Instead we obtain a
                \textit{near-sided} projection. This gives us different
                coordinate charts on the sphere.
                Suppose our observer is at geosynchronous orbit which is fairly
                far away. The resulting coordinate chart is shown in
                Fig.~\subref{fig:Near_Sided_Proj}. Further still we can imagine
                removing what the observer can see, hollowing out the Earth, and
                then projecting what is left onto the plane.
                \begin{figure}
                    \centering
                    \captionsetup{type=figure}
                    \begin{subfigure}[b]{0.49\textwidth}
                        \centering
                        \captionsetup{type=figure}
                        \resizebox{!}{0.8\height}{
                            \includegraphics{%
                                images/Sphere_GEO_Near_Sided_Projection.pdf%
                            }
                        }
                        \subcaption{Near-Sided Projection}
                        \label{fig:Near_Sided_Proj}
                    \end{subfigure}
                    \begin{subfigure}[b]{0.49\textwidth}
                        \centering
                        \captionsetup{type=figure}
                        \resizebox{!}{0.8\height}{
                            \includegraphics{%
                                images/Sphere_GEO_Far_Sided_Projection.pdf%
                            }
                        }
                        \subcaption{Far-Sided Projection}
                        \label{fig:Far_Sided_Proj}
                    \end{subfigure}
                    \caption{Different Projections of a Sphere}
                \end{figure}
                This results in the \textit{far-sided} projection and is shown
                in Fig.~\subref{fig:Far_Sided_Proj}.
                \par\vspace{1ex}
                \begin{minipage}[t]{0.52\textwidth}
                    While near sided projections reveal more of the sphere as
                    one moves further away, far-sided projections show less. In
                    the extreme case where the observer is lying on the ground
                    the far-sided projection becomes the \textit{stereographic}
                    projection. This is a particularly attractive concept since
                    it allows one to easily cover the sphere with two charts.
                    The stereographic projection from the north pole has the
                    following function:
                    \begin{equation}
                        \varphi(x,\,y,\,z)=\Big(\frac{x}{1-z},\,\frac{y}{1-z}\Big)
                    \end{equation}
                \end{minipage}
                \hfill
                \fbox{%
                    \begin{minipage}[t]{0.42\textwidth}
                        \begin{figure}[H]
                            \centering
                            \captionsetup{type=figure}
                            \includegraphics{%
                                images/Sphere_Stereographic_Projection.pdf%
                            }
                            \caption{Stereographic Projection}
                            \label{fig:Stereo_Proj}
                        \end{figure}
                    \end{minipage}
                }
                \par
                The inverse is continuous and given by:
                \begin{equation}
                    \varphi^{\minus{1}}(X,\,Y)=
                    \Big(\frac{2X}{1+X^{2}+Y^{2}},\,
                         \frac{2Y}{1+X^{2}+Y^{2}},\,
                         \frac{\minus{1}+X^{2}+Y^{2}}{1+X^{2}+Y^{2}}\Big)
                \end{equation}
                The result is shown in Fig.~\ref{fig:Stereo_Proj}. All of these
                are valid coordinate charts on the sphere $\nsphere[2]$.
                Moreover, they are \textit{smooth} charts which overlap
                smoothly. The smooth structure on a smooth manifold is the
                collection of \textit{all} smoothly overlapping coordinate
                charts. The few charts we've shown all belong to the smooth
                structure of the sphere.
            \subsection{Tangent Spaces}
                There are three ways we can think of the tangent space
                $\tanspace{\vector{x}}{\nspace}$ given a point
                $\vector{x}\in\nspace$. Firstly we can think of the classical
                calculus manner of tangent spaces, which is just a collection of
                vectors starting at $\vector{x}$. We can also use derivations.
                If we let $\Ckspace{\infty}{\nspace}$ denote the set of all
                smooth functions $f:\nspace\rightarrow\nspace[]$, then a
                \textit{derivation} is a function
                $D:\Ckspace{\infty}{\nspace}\rightarrow\nspace[]$ that is linear
                and Liebnizian. That is, for all $a,b\in\nspace[]$ and
                $f,g\in\Ckspace{\infty}{\nspace}$ the following holds:
                \begin{subequations}
                    \begin{align}
                        D(af+bg)&=aD(f)+bD(g)\\
                        D(fg)&=D(f)g(\vector{x})+f(\vector{x})D(g)
                    \end{align}
                \end{subequations}
                \begin{minipage}[t]{0.54\textwidth}
                    There is a basis for the space of derivations consisting of
                    the partial derivatives at $\vector{x}$. Lastly, we can
                    think of equivalence classes of smooth curves passing
                    through the point $\vector{x}$. Using $\nspace[2]$ as an
                    example, the three curves in figure
                    Fig.~\ref{fig:Tan_Vec_as_Curves} passing through the point
                    $p\in\nspace[2]$ belong to the same equivalence classes
                    since they have the same tangent vector at $p$. There's a
                    relationship between these three modes of thought. Given a
                    vector $\vector{v}$ at $\vector{x}$ we can form a derivation
                    $D$ by the equation:
                    \begin{equation}
                        D_{\vector{v}}(f)=\frac{\diff}{\diff{t}}\Big|_{t=0}
                            \big(f(\vector{x}+t\vector{v})\big)
                    \end{equation}
                \end{minipage}
                \hfill
                \fbox{%
                    \begin{minipage}[t]{0.40\textwidth}
                        \begin{figure}[H]
                            \centering
                            \captionsetup{type=figure}
                            \includegraphics{%
                                images/Tangent_Vector_as_Equiv_Curves.pdf%
                            }
                            \caption{Tangent Vectors as Curves}
                            \label{fig:Tan_Vec_as_Curves}
                        \end{figure}
                    \end{minipage}
                }
                \par\hfill\par
                That is, we take $D$ to be the \textit{directional derivative}.
                A curve also gives rise to a derivation since a curve is simply
                a function $\gamma:(0,1)\rightarrow\nspace$. Given
                $f\in\Ckspace{\infty}{\nspace}$ we can compose
                $f\circ\gamma:(0,1)\rightarrow\nspace[]$, and on this we can
                perform ordinary calculus. We define the derivation by:
                \begin{equation}
                    D_{\gamma}(f)=\frac{\diff}{\diff{t}}\Big|_{t=t_{0}}
                        \big(f\circ\gamma\big)
                \end{equation}
                where $t_{0}$ is the time when $\gamma$ passes through $p$. This
                derivation corresponds to the equivalence class of curves with
                the same slope as the curve $\Gamma(t)=\vector{x}+t\vector{v}$.
                \par\hfill\par
                In the manifold setting we may lose the vector space structure
                offered in $\nspace$ and cannot use the first manner of tangent
                vectors, but the latter two are still well defined. Given a
                manifold $M$ and a point $p\in{M}$ one can obtain a basis for
                $\tanspace{p}{M}$ by taking a coordinate chart
                $(\mathcal{U},\varphi)$ with $p\in\mathcal{U}$ and defining the
                \textit{partials} at $p$ with respect to this chart. If we have
                a smooth real value function $f\in\Ckspace{\infty}{M}$ we can
                compose this with $\varphi^{\minus{1}}$ which gives us a
                function from an open subset of $\nspace$ to the real line 
                (Fig.~\ref{fig:Partials_on_Manifold}).
                \begin{figure}
                    \centering
                    \captionsetup{type=figure}
                    \includegraphics{images/Smooth_Real_Valued_Function_on_a_Manifold.pdf}
                    \caption{Smooth Real-Valued Function on a Manifold}
                    \label{fig:Partials_on_Manifold}
                \end{figure}
                We define the partial derivative with respect to the
                $i^{th}$ coordinate as follows:
                \begin{equation}
                    \frac{\partial}{\partial{\varphi}_{i}}\Big|_{p}f
                    =\frac{\partial}{\partial{x}_{i}}\Big|_{\varphi(p)}
                        \big(f\circ\varphi^{\minus{1}}\big)
                \end{equation}
                where $x_{i}=\pi_{i}\circ\varphi$ with $\pi_{i}$ being the
                $i^{th}$ projection mapping.
            \subsection{Differentiation in Euclidean Space}
                Let $f:\nspace[m]\rightarrow\nspace$ be a function. The
                differential of $f$ at a point $\vector{x}\in\nspace[m]$, also
                called the \textit{total} derivative, is the best linear
                approximation of $f$ at that point. First, we define what it
                means for such a function to be totally differentiable.
                \begin{fdefinition}{Totally Differentiable}
                                   {Total_Differentiable}
                    A function from an open subset
                    $\mathcal{U}\subseteq\nspace[m]$ to $\nspace$ that is
                    totally differentiable at $\vector{x}\in\mathcal{U}$ is a
                    function $f:\mathcal{U}\rightarrow\nspace$ such that there
                    exists a linear map
                    $\diff{f}_{\vector{x}}:\nspace[m]\rightarrow\nspace$
                    such that:
                    \begin{equation*}
                        \underset{\vector{h}\rightarrow\vector{0}}{\lim}
                        \frac{%
                            \norm{%
                                f(\vector{x}+\vector{h})-f(\vector{x})-
                                \diff{f}_{\vector{x}}(\vector{h})
                            }_{2}^{n}
                        }{\norm{\vector{h}}_{2}^{m}}
                        =0
                    \end{equation*}
                    where $\norm{\cdot}_{2}^{k}$ denotes the standard Euclidean
                    2 norm in $\mathbb{R}^{k}$.
                \end{fdefinition}
                Before we define the \textit{differential} of a totally
                differentiable function, which is simply the linear mapping
                $\diff{f}_{\vector{x}}$, we must first prove it is unique. Hence
                there is no ambiguity in saying \textit{the} differential.
                \begin{theorem}
                    If $\mathcal{U}\subseteq\nspace[m]$ is open, if
                    $\vector{x}\in\mathcal{U}$, and if
                    $f:\mathcal{U}\rightarrow\nspace$ is totally differentiable
                    at $\vector{x}$, then there is a unique linear function
                    $\diff\phi_{\vector{x}}:\nspace[m]\rightarrow\nspace$ with:
                    \begin{equation*}
                        \underset{\vector{h}\rightarrow\vector{0}}{\lim}
                        \frac{%
                            \norm{%
                                f(\vector{x}+\vector{h})-f(\vector{x})-
                                \diff{f}_{\vector{x}}(\vector{h})
                            }_{2}^{n}
                        }{\norm{\vector{h}}_{2}^{m}}
                        =0
                    \end{equation*}
                \end{theorem}
                \begin{proof}
                    By the definition of a totally differentiable function,
                    there exists such a map $\diff{f}_{\vector{x}}$
                    (Def.~\ref{def:Total_Differentiable}). Suppose
                    $T:\nspace[m]\rightarrow\nspace$ is another such linear map.
                    
                \end{proof}
                \begin{theorem}
                    If $f:\nspace[m]\rightarrow\nspace$ is a linear function,
                    and if $\vector{x}\in\nspace[m]$, then $f$ is differentiable
                    at $\vector{x}$ and
                    $f_{*_{\vector{x}}}(\vector{u})=f(\vector{u})$
                \end{theorem}
                \begin{proof}
                    For if $f$ is linear, let $T:\nspace[m]\rightarrow\nspace$
                    be the linear operator $T\vector{h}=f(\vector{h})$. Then:
                    \begin{subequations}
                        \begin{align}
                            \underset{\vector{h}\rightarrow\vector{0}}{\lim}
                            \frac{%
                                \norm{%
                                    f(\vector{x}+\vector{h})-
                                    f(\vector{x})-
                                    T\vector{h}%
                                }_{2}^{n}%
                            }%
                            {%
                                \norm{\vector{h}}_{2}^{m}%
                            }
                            &=\underset{\vector{h}\rightarrow\vector{0}}{\lim}
                            \frac{%
                                \norm{%
                                    f(\vector{x})+
                                    f(\vector{h})-
                                    f(\vector{x})-
                                    T\vector{h}%
                                }_{2}^{n}%
                            }%
                            {%
                                \norm{\vector{h}}_{2}^{m}%
                            }\\
                            &=\underset{\vector{h}\rightarrow\vector{0}}{\lim}
                            \frac{%
                                \norm{%
                                    f(\vector{h})-
                                    T\vector{h}%
                                }_{2}^{n}%
                            }%
                            {%
                                \norm{\vector{h}}_{2}^{m}%
                            }\\
                            &=\underset{\vector{h}\rightarrow\vector{0}}{\lim}
                            \frac{\norm{\vector{0}}_{2}^{n}}
                                 {\norm{\vector{x}}_{2}^{m}}\\
                            &=0
                        \end{align}
                    \end{subequations}
                    and hence $f$ is differetiable. By definition
                    $f_{*_{\vector{x}}}(\vector{u})=T\vector{u}$ and
                    $T\vector{u}=f(\vector{u})$.
                \end{proof}
                \begin{example}
                    Let $f:\mathbb{R}\rightarrow\nspace[2]$ be defined by
                    $f(t)=\big(\cos(t),\sin(t)\big)$. Let's compute the
                    derivative of $t_{0}\in\mathbb{R}$. We compute:
                    \begin{subequations}
                        \begin{align}
                            &\nonumber\underset{h\rightarrow{0}}{\lim}
                                \frac{%
                                    \norm[\big]{%
                                        f(t_{0}+h)-f(h)-T(h)
                                    }
                                }{|h|}\\
                            &=\underset{h\rightarrow{0}}{\lim}
                            \frac{%
                                \norm{%
                                    \big(\cos(t_{0}+h),\,\sin(t_{0}+h)\big)-
                                    \big(\cos(t_{0}),\,\sin(t_{0})\big)-Th%
                                }%
                            }{h}\\[2ex]
                            &=\underset{h\rightarrow{0}}{\lim}\norm[\bigg]{%
                                \Big(%
                                    \frac{\cos(t_{0}+h)-\cos(t_{0})}{h},\,
                                    \frac{\sin(t_{0}+h)-\sin(t_{0})}{h}
                                \Big)-\frac{Th}{h}
                            }\\[2ex]
                            &=\norm[\bigg]{%
                                \underset{h\rightarrow{0}}{\lim}\Big(%
                                    \frac{\cos(t_{0}+h)-\cos(t_{0})}{h},\,
                                    \frac{\sin(t_{0}+h)-\sin(t_{0})}{h}
                                \Big)
                                -\underset{h\rightarrow{0}}{\lim}\frac{Th}{h}
                            }\\[2ex]
                            &=\norm[\Big]{%
                                \big(\minus\sin(t_{0}),\,\cos(t_{0})\big)-
                                \underset{h\rightarrow{0}}{\lim}\frac{Th}{h}
                            }
                        \end{align}
                    \end{subequations}
                    So let $T:\mathbb{R}\rightarrow\nspace[2]$ be the linear map
                    defined by:
                    \begin{equation}
                        Th=\big(\minus\sin(t_{0})h,\,\cos(t_{0})h\big)
                    \end{equation}
                    The last line then simplifies to the following:
                    \begin{subequations}
                        \begin{align}
                            \nonumber&\norm[\Big]{%
                                \big(\minus\sin(t_{0}),\,\cos(t_{0})\big)-
                                \underset{h\rightarrow{0}}{\lim}\frac{Th}{h}
                            }\\
                            &=\norm[\Big]{%
                                \big(\minus\sin(t_{0}),\,\cos(t_{0})\big)-
                                \underset{h\rightarrow{0}}{\lim}
                                \frac{%
                                    \big(\minus\sin(t_{0})h,\,\cos(t_{0})h\big)
                                }{h}
                            }\\
                            &=\norm[\big]{%
                                \big(\minus\sin(t_{0}),\,\cos(t_{0})\big)-
                                \big(\minus\sin(t_{0}),\,\cos(t_{0})\big)
                            }\\
                            &=\norm{0}
                        \end{align}
                    \end{subequations}
                    Hence we have
                    $f_{*_{t_{0}}}(h)=\big(\minus\sin(t_{0})h,\,\cos(t_{0})h\big)$.
                \end{example}
                \begin{example}
                    Let $f:\nspace[2]\rightarrow\nspace[2]$ be defined by
                    $f(x,y)=(y,x)$ and let's compute the differential.
                \end{example}
                \begin{example}
                    Let $f:\nspace[2]\rightarrow\nspace[2]$ be defined by:
                    \begin{equation}
                        f(x,y)=\big(x\cos(y),\,x\sin(y)\big)
                    \end{equation}
                    Let's compute the total derivative of this at the point
                    $(x_{0},y_{0})$. We seek a linear function
                    $T:\nspace[2]\rightarrow\nspace[2]$ which best approximates
                    $f$ here. Let's examine the $x$ component of
                    $f(\vector{x}+\vector{h})-f(\vector{x})$.
                    \begin{subequations}
                        \begin{align}
                            f(\vector{x}+\vector{h})_{x}-f(\vector{x})_{x}
                            &=f(x+h_{1},\,y+h_{2})_{x}-f(x,\,y)_{x}\\
                            &=(x+h_{1})\cos(y+h_{2})-x\cos(y)\\
                            &=x\big(\cos(y+h_{2})-\cos(y)\big)+
                                h_{1}\cos(y+h_{2})
                        \end{align}
                    \end{subequations}
                \end{example}
                If we consider the curve $\gamma(t)=\vector{x}+t\vector{v}$,
                then we see:
                \begin{equation}
                    F_{*_{\vector{x}}}(\vector{v})=D_{\gamma}F\big|_{\vector{x}}
                \end{equation}
                We compute this as follows:
                \begin{subequations}
                    \begin{align}
                        D_{\gamma}F|_{\vector{x}}
                        &=\frac{\diff}{\diff{t}}\Big|_{t=0}(F\circ\gamma)\\[1ex]
                        &=\frac{\diff}{\diff{t}}\Big|_{t=0}F
                            \big(\vector{x}+t\vector{v}\big)
                    \end{align}
                \end{subequations}
                If $\vector{e}_{i}$ denotes the standard $i^{th}$ basis vector,
                then we have:
                \begin{equation}
                    f_{*_{\vector{x}}}(\vector{e}_{i})=
                        \frac{\partial{f}}{\partial{x}_{i}}(\vector{x})
                \end{equation}
                The matrix corresponding to $f_{*}$ is given by:
                \begingroup
                    \renewcommand*{\arraystretch}{1.5}
                    \begin{equation}
                        J=
                        \begin{bmatrix}
                            \frac{\partial{f}_{1}}{\partial{x}_{1}}&
                            \frac{\partial{f}_{1}}{\partial{x}_{2}}
                            &\dots&
                            \frac{\partial{f}_{1}}{\partial{x}_{n}}\\
                            \frac{\partial{f}_{2}}{\partial{x}_{1}}&
                            \frac{\partial{f}_{2}}{\partial{x}_{2}}
                            &\dots&
                            \frac{\partial{f}_{2}}{\partial{x}_{n}}\\
                            \vdots&\vdots&\ddots&\vdots&\\
                            \frac{\partial{f}_{m}}{\partial{x}_{1}}&
                            \frac{\partial{f}_{m}}{\partial{x}_{2}}
                            &\dots&
                            \frac{\partial{f}_{m}}{\partial{x}_{n}}
                        \end{bmatrix}
                    \end{equation}
                \endgroup
                \begin{example}
                    Let $m,n,p\in\mathbb{N}^{+}$ be positive integers and
                    $B:\nspace[m]\times\nspace\rightarrow\nspace[p]$ a bilinear
                    function. Given
                    $(\vector{u},\vector{v})\in%
                    \tanspace{(\vector{a},\vector{b})}{\nspace[m]\times\nspace}$
                    we can compute the derivative of $B$ as follows:
                    \begin{equation}
                        D_{(\vector{u},\vector{v})}B(\vector{a},\vector{b})=
                        \frac{\diff}{\diff{t}}\Big|_{t_{0}}
                        B(\vector{a}+t\vector{u},\vector{b}+t\vector{v})
                    \end{equation}
                    But since $B$ is bilinear we can simplify the first variable
                    as follows:
                    \begin{equation}
                        D_{(\vector{u},\vector{v})}B(\vector{a},\vector{b})=
                        \frac{\diff}{\diff{t}}\Big|_{t_{0}}\Big(
                            B(\vector{a},\vector{b}+t\vector{v})+
                            tB(\vector{u},\vector{b}+t\vector{v})
                        \Big)
                    \end{equation}
                    But again from bilinearity we can simplify the second
                    slot, obtaining:
                    \begin{subequations}
                        \begin{align}
                            D_{(\vector{u},\vector{v})}B(\vector{a},\vector{b})
                            &=\frac{\diff}{\diff{t}}\Big|_{t_{0}}\Big(
                                B(\vector{a},\vector{b})+
                                tB(\vector{a},\vector{v})+
                                tB(\vector{u},\vector{b})+
                                t^{2}B(\vector{u},\vector{v})
                            \Big)\\
                            &=B(\vector{a},\vector{v})+B(\vector{u},\vector{b})
                                +2t_{0}B(\vector{u},\vector{v})
                        \end{align}
                    \end{subequations}
                    For this problem we have $t_{0}=0$, and so we arrive at the
                    result:
                    \begin{equation}
                        B_{*_{(\vector{a},\vector{b})}}(\vector{u},\vector{v})
                        =B(\vector{a},\vector{v})+B(\vector{u},\vector{b})
                    \end{equation}
                \end{example}
                \begin{ftheorem}{The Chain Rule}{Chain_Rule}
                    If $f:\nspace[m]\rightarrow\nspace$ is differentiable at a
                    point $\vector{x}\in\nspace[m]$, and if
                    $g:\nspace\rightarrow\nspace[p]$ is differentiable at
                    $f(\vector{x})\in\nspace$, then $g\circ{f}$ is
                    differentiable at $\vector{x}$ and:
                    \begin{equation*}
                        (g\circ{f})_{*_{p}}=g_{*_{f(p)}}\circ{f}_{*_{p}}
                    \end{equation*}
                \end{ftheorem}
                Our first use of this is with the Liebniz rule.
                \begin{ltheorem}{Liebniz Rule}{Liebniz_Rule}
                    If $B:\nspace[m]\times\nspace\rightarrow\nspace[p]$ is a
                    bilinear function, if
                    $F_{1}:\nspace[k]\rightarrow\nspace[m]$ and
                    $F_{2}:\nspace[k]\rightarrow\nspace[n]$ are differentiable
                    functions, and if $\vector{x}_{0}\in\nspace[k]$, then the
                    function $H:\nspace[k]\rightarrow\nspace[p]$ defined by:
                    \begin{equation*}
                        H(\vector{x})=
                            B\big(F_{1}(\vector{x}),F_{2}(\vector{x})\big)
                    \end{equation*}
                    then $H$ is differentiable at $\vector{x}_{0}$ and:
                    \begin{equation*}
                        H_{*_{p}}(\vector{u})=
                        B\big(%
                            F_{1_{*_{\vector{x}_{0}}}}(\vector{u}),\,%
                            F_{2}(\vector{u})\big)+
                        B\big(%
                            F_{1}(\vector{u}),\,%
                            F_{1_{*_{\vector{x}}}}(\vector{u})\big)
                    \end{equation*}
                \end{ltheorem}
                \begin{proof}
                    For let $G(x)=(F_{1}(x),F_{2}(x))$ and apply the chain rule
                    to $B\circ{G}$.
                \end{proof}
                \begin{example}
                    Let $\matspace{\nspace[]}$ denote the set of all
                    $n\times{n}$ matrices with entries in $\nspace[]$ and
                    $\GLnR{\nspace[]}$ the set of all invertible $n\times{n}$
                    matrices. That is, the set of all matrices with non-zero
                    determinant. Let
                    $F:\GLnR{\nspace[]}\rightarrow\GLnR{\nspace[]}$ be given by
                    $F(X)=X^{\minus{1}}$. Let's compute $F_{*_{A}}(U)$ for
                    $A\in\GLnR{\nspace[]}$ and
                    $U\in\tanspace{A}{\matspace{\nspace[]}}$. We'll use the fact
                    that $XX^{\minus{1}}=I$ is the identity matrix, and write
                    $G(X)=X$. Then $G(X)F(X)=I$ and hence by the Liebniz rule we
                    get:
                    \begin{equation}
                        G_{*_{A}}(U)F(A)+G(A)F_{*_{A}}(U)=0
                    \end{equation}
                    But $G$ is linear and hence $G_{*_{A}}(U)=G(U)=U$. Moreover,
                    $F(A)=A^{\minus{1}}$. Combining we get:
                    \begin{equation}
                        AF_{*_{A}}(U)=\minus{U}A^{\minus{1}}
                    \end{equation}
                    But $A\in\GLnR{\nspace[]}$ is invertible, and so we can
                    bring this to the other side obtaining:
                    \begin{equation}
                        F_{*_{A}}(U)=\minus{A}^{\minus{1}}UA^{\minus{1}}
                    \end{equation}
                \end{example}
                \begin{example}
                    Let $F:\matspace{\nspace[]}\rightarrow\matspace{\nspace[]}$
                    be defined by:
                    \begin{equation}
                        F(X)=AXA^{\minus{1}}
                    \end{equation}
                    where $A\in\GLnR{\nspace[]}$ is some invertible matrix.
                    Find $F_{*_{B}}$ given a matrix $B$. Since $F$ is linear we
                    know that $F_{*_{B}}(U)=F(U)$ for all $U$, and hence:
                    \begin{equation}
                        F_{*_{B}}(U)=AUA^{\minus{1}}
                    \end{equation}
                \end{example}
                \begin{example}
                    Let $H:\GLnR{\nspace[]}\rightarrow\GLnR{\nspace[]}$ be
                    defined by:
                    \begin{equation}
                        H(X)=XAX^{\minus{1}}
                    \end{equation}
                    with $A\in\matspace{\nspace[]}$. Compute $H_{*_{B}}$ for
                    $B\in\GLnR{\nspace[]}$. We can use the Liebniz rule if we
                    let $F(X)=XA$ and $G(X)=X^{\minus{1}}$. The derivative
                    becomes:
                    \begin{equation}
                        H_{*_{B}}(U)=F_{*_{B}}(U)G(B)+F(B)G_{*_{B}}(U)
                    \end{equation}
                    But $F$ is linear and hence $F_{*_{B}}(U)=F(U)$. Also we've
                    already computed the derivative of $X^{\minus{1}}$ so
                    $G_{*_{B}}(U)=\minus{B}^{\minus{1}}UB^{\minus{1}}$.
                    Combining, we get:
                    \begin{equation}
                        H_{*_{B}}=UAB^{\minus{1}}-BAB^{\minus{1}}UB^{\minus{1}}
                    \end{equation}
                \end{example}
                \begin{example}
                    Let $F:\matspace{\nspace[]}\rightarrow\matspace{\nspace[]}$
                    be defined by:
                    \begin{equation}
                        F(X)=X^{T}X
                    \end{equation}
                    where $X^{T}$ denotes the transpose of $X$. Compute
                    $F_{*_{A}}$. Let $G_{1}(X)=X^{T}$ and $G_{2}(X)=X$. By the
                    Liebniz property, we get:
                    \begin{equation}
                        F_{*_{A}}(U)=G_{1_{*_{A}}}(U)G_{2}(A)+
                            G_{1}(A)G_{2_{*_{A}}}(U)
                    \end{equation}
                    But the transpose is a linear operation, and hence
                    $G_{1_{*_{A}}}(U)=G_{1}(U)=U^{T}$. Similarly $G_{2}$ is
                    linear, and thus:
                    \begin{equation}
                        F_{*_{A}}(U)=U^{T}A+A^{T}U
                    \end{equation}
                \end{example}
                The function $F(X)=X^{T}X$ has it's image in the set of all
                symmetric matrices. If $Y\in{F}[\matspace{\nspace[]}]$, then
                $Y=F(X)$ for some $X\in\matspace{\nspace[]}$ and hence:
                \begin{equation}
                    Y^{T}=(X^{T}X)^{T}=X^{T}X=Y
                \end{equation}
                If $A\in\orthgroup{\nspace[]}$, the group of orthogonal
                matrices, then $F_{*_{A}}$ is surjective with respect to $P$,
                the set of symmetric matrices. For if $Y\in{P}$, then let
                $U=\frac{1}{2}AY$. Then:
                \par
                \begin{subequations}
                    \begin{minipage}[b]{0.58\textwidth}
                        \centering
                        \begin{align}
                            F_{*_{A}}(U)&=U^{T}A+A^{T}U\vphantom{\frac{1}{2}}\\
                                &=(\frac{1}{2}AY)^{T}A+A^{T}(\frac{1}{2}AY)
                                \vphantom{\frac{1}{2}}\\
                                &=\frac{1}{2}\big(Y^{T}A^{T}A+A^{T}AY\big)
                                \vphantom{\frac{1}{2}}
                        \end{align}
                    \end{minipage}
                    \hfill
                    \begin{minipage}[b]{0.41\textwidth}
                        \centering
                        \begin{align}
                            &=\frac{1}{2}\big(Y^{T}I+IY\big)\\
                            &=\frac{1}{2}(2Y)\vphantom{\frac{1}{2}}\\
                            &=Y\vphantom{\frac{1}{2}}
                        \end{align}
                    \end{minipage}
                \end{subequations}
            \subsection{Submanifolds}
                An immersed submanifold is given by an inective immersion
                $f:N\rightarrow{M}$. We write that $(N,f)$ is a submanifold of
                $M$ and usually identify $N$ with $f[N]$. If $f$ is an
                embedding, then we say $(N,f)$ is an embedded submanifold or a
                regular submanifold. The topology we endow $f[N]$ with is not
                necessarily the subspace topology, but rather the topology that
                makes $f$ a homeomorphism onto its image. An embedding is when
                this topology agrees with the subspace topology.
                \begin{example}
                    The first example of an immersed submanifold that is not
                    embedded comes from the function
                    $f:(\minus{1}.2,1)\rightarrow\nspace[2]$ defined by:
                    \begin{equation}
                        f(t)=\big(t^{2}-1,\,t^{3}-t\big)
                    \end{equation}
                    The graph of this parametric equation is shown in
                    Fig.~\ref{fig:Immersed_Submanifold_001}. This is not an
                    embedded submanifold since the subspace topology does not
                    give rise to a manifold. The origin locally looks like the
                    letter \textit{T}, which is not possible for topological
                    manifolds.
                \end{example}
                \begin{figure}[H]
                    \centering
                    \captionsetup{type=figure}
                    \includegraphics{images/Immersed_Not_Embedded_003.pdf}
                    \caption{An Immersed Submanifold}
                    \label{fig:Immersed_Submanifold_001}
                \end{figure}
                \begin{example}
                    A \textit{lemniscate} gives rise to another immersed
                    manifold. If we let $f$ be defined by:
                    \begin{equation}
                        f(t)=\big(\sin(t),\,\sin(2t)\big)
                    \end{equation}
                    If we set the domain to be $(-\pi,\pi)$, we obtain the
                    lemniscate shown in
                    Fig.~\subref{fig:Immersed_Not_Embedded_002}.
                \end{example}
                \begin{figure}[H]
                    \centering
                    \captionsetup{type=figure}
                    \begin{subfigure}[b]{0.49\textwidth}
                        \centering
                        \captionsetup{type=figure}
                        \includegraphics{images/Immersed_Not_Embedded_001.pdf}
                        \subcaption{Lemniscate with Domain $(-\pi,\,\pi)$}
                        \label{fig:Immersed_Not_Embedded_002}
                    \end{subfigure}
                    \begin{subfigure}[b]{0.49\textwidth}
                        \centering
                        \captionsetup{type=figure}
                        \includegraphics{images/Immersed_Not_Embedded_002.pdf}
                        \subcaption{Lemniscate with Domain $(0,\,2\pi)$}
                        \label{fig:Immersed_Not_Embedded_003}
                    \end{subfigure}
                    \caption{Immersed Lemniscates that are not Embeddings}
                    \label{fig:Immersed_Not_Embedded}
                \end{figure}
            \subsection{Differentiation on Manifolds}
                If $M$ and $N$ are smooth manifolds, $\phi:M\rightarrow{N}$ a
                smooth function, then for $p\in{M}$ we define the differential
                pushforward $\diff\phi_{p}$ between tangent spaces,
                $\diff\phi_{p}:\tanspace{p}{M}\rightarrow\tanspace{\phi(p)}{N}$,
                as follows. Given a tangent vector $v$ at $p$, which is just a
                derivation $v:\Ckspace{\infty}{M}\rightarrow\mathbb{R}$, and a
                smooth function $f\in\Ckspace{\infty}{M}$, we simply use
                function composition to obtain a derivation in $N$. That is:
                \begin{equation}
                    \diff\phi_{p}(v)(f)=v(f\circ\phi)
                \end{equation}
                Since $f\circ\phi$ is a function from $M$ to $\mathbb{R}$, $v$
                knows how to evaluate it. Hence this is well defined. The
                diagram for this is shown in
                Fig.~\ref{fig:Differential_Pushforward}.
                \begin{figure}[H]
                    \centering
                    \captionsetup{type=figure}
                    \input{tikz/Differential_Pushforward_of_Tangent_Vector.tex}
                    \caption{Differential Pushforward}
                    \label{fig:Differential_Pushforward}
                \end{figure}
                It is also common to denote $\diff\phi_{p}$ by
                $\phi_{*_{p}}$. The differential pullback $\phi^{*}$ is then:
                \begin{equation}
                    \phi^{*}(f)=f\circ\phi
                \end{equation}
                Using this notation we have
                $\phi_{*_{p}}(v)=v\big(\phi^{*}(f)\big)$. $\diff\phi_{p}$ is
                also called the \textit{derivative} of $\phi$ at $p$. This gives
                a linear function between vector spaces since:
                \begin{subequations}
                    \begin{align}
                        \diff\phi_{p}(av+bu)(f)&=(av+bu)(f\circ\phi)\\
                        &=av(f\circ\phi)+bu(f\circ\phi)\\
                        &=a\diff\phi_{p}(v)(f)+b\diff\phi_{p}(u)(f)
                    \end{align}
                \end{subequations}
                Since the dimension of the tangent space is equal to the
                dimension of the manifold, this is a linear transformation
                between finite dimensional vector spaces and hence can be
                represented by a matrix. Given a chart
                $(\mathcal{U},\varphi)$ of $p$ and $(\mathcal{V},\psi)$ of
                $\phi(p)$ we can obtain the standard bases of $\tanspace{p}{M}$
                and $\tanspace{\phi(p)}{N}$ by
                $\{\partial_{\varphi_{k}}|_{p}\;|\;k\in\mathbb{Z}_{m}\}$ and
                $\{\partial_{\psi_{k}}|_{\phi(p)}\;|\;k\in\mathbb{Z}_{n}\}$. The
                matrix representation of $\diff\phi_{p}$ is then just the
                Jacobian matrix. Since
                $\partial\varphi_{j}$ $\partial_{\psi_{k}}$ form a basis
                for $\tanspace{p}{M}$ and $\tanspace{\phi(p)}{N}$, respectively,
                given any $v\in\tanspace{p}{M}$ we may write:
                \begin{subequations}
                    \begin{align}
                        v&=\sum_{j=0}^{m-1}v(\varphi_{j})
                            \partial_{\varphi_{j}}|_{p}\\
                        \diff\phi_{p}(v)&=\sum_{k=0}^{n-1}
                            \diff\phi_{p}(v)(\psi_{k})
                            \partial_{\psi_{k}}|_{\phi(p)}
                    \end{align}
                \end{subequations}
                But from the definition of the differential pushforward we have:
                \begin{equation}
                    \diff\phi_{p}(v)(\psi_{k})=v(\psi_{k}\circ\phi)
                \end{equation}
                Combining this with the above equations, we obtain:
                \begin{subequations}
                    \begin{align}
                        \diff\phi_{p}(v)(f)&=\sum_{k=0}^{n-1}
                            \diff\phi_{p}(v)(\psi_{k})
                            \partial_{\psi_{k}}|_{\phi(p)}\\
                        &=\sum_{k=0}^{n-1}v(\psi_{k}\circ\phi)
                            \partial_{\psi_{k}}|_{\phi(p)}\\
                        &=\sum_{k=0}^{n-1}\Big(
                            \sum_{j=0}^{m-1}v(\varphi_{j})
                            \partial_{\varphi_{j}}|_{p}(\psi_{k}\circ\phi)
                        \Big)\partial_{\psi_{k}}|_{\phi(p)}
                    \end{align}
                \end{subequations}
                And so the $ij$ entry of the representing matrix is:
                \begin{equation}
                    J_{ij}=\partial_{\varphi_{j}}|_{p}(\psi_{i}\circ\phi)
                    =\frac{\partial(\psi_{i}\circ\phi)}{\partial\varphi_{j}}(p)
                \end{equation}
                which is just the Jacobian matrix. As noted, another way of
                thinking about tangent vectors is by equivalence classes of
                smooth curves. Given $\gamma:J\rightarrow{M}$ where $J$ is some
                interval in $\mathbb{R}$, we define:
                \begin{equation}
                    \dot{\gamma}(t_{0})(f)
                        =\frac{\diff}{\diff{t}}(f\circ\gamma)(t_{0})
                \end{equation}
        \section{Topological Groups}
            \begin{fdefinition}{Topological Group}{Topological_Group}
                A topological group is a topological space $\topspace{G}$ with a
                binary operation $*$ such that $\monoid{G}$ is a group and and
                the functions $h:G\times{G}\rightarrow{G}$ and
                $\nu:G\rightarrow{G}$ defined by $h(x,y)=x*y$ and
                $\nu(g)=g^{\minus{1}}$ are continuous.
            \end{fdefinition}
            \begin{example}
                \label{ex:Top_Group_Indiscrete}%
                Given any group $\monoid{G}$, if we endow $G$ with the trivial
                topology $\tau=\{\emptyset,G\}$ then $\topgroup{G}$ is a
                topological group.
            \end{example}
            \begin{example}
                As another trivial example, if we endow a group $\monoid{G}$
                with the discrete topology $\tau=\powset{G}$, then
                $\topgroup{G}$ is a topological group. 
            \end{example}
            There's often the requirement that a topological group be Hausdorff.
            This is not completely unfounded since it is a remarkable fact that
            if the topology of your topology group is $T_{0}$ (points are
            topologically distinguishable), then the group structure allows you
            to prove that it is automatically $T_{2}$ (also known as Hausdorff).
            Since $T_{0}$ is a \textit{very} weak assumption, there's no harm in
            supposing topological groups are Hausdorff. But, as
            Ex.~\ref{ex:Top_Group_Indiscrete} shows it is possible to find
            counterexamples. If one naturally comes across a topological group
            where the underlying topology is not $T_{0}$ it is often fitting to
            then consider the Kolmogorov quotient of the space. The closure of
            the identity $\closure{e}$ is a normal subgroup of the group
            structure, and by quotienting out by this both topologically and
            group theoretically we obtain a quotient group with a quotient
            topology which is now Hausdorff.
            \begin{fdefinition}{Topological Subgroup}{Topological_Subgroup}
                A topological subgroup of a topological group is a subgroup with
                the subspace topology.
            \end{fdefinition}
            \begin{example}
                If we let $\nspace[]$ have its usual topology and additive
                operation $+$, then $\mathbb{Q}$ is a topological subgroup. The
                subspace topology is the standard metric topology that makes it
                dense in $\nspace[]$.
            \end{example}
            If the topological space is locally Euclidean, then it is $T_{1}$
            and hence by the previous comment our topological group will be
            Hausdorff. Hence, so long as we consider second countable spaces,
            locally Euclidean topological groups are topological manifolds for
            free. With this we transition to Lie groups, which are topological
            groups with a smooth manifold structure.
            \begin{fdefinition}{Lie Group}{Lie_Group}
                A Lie group is a smooth manifold $\manifold{G}$ with a binary
                operation $*$ such that $\monoid{G}$ is a group, and the
                functions $h:G\times{G}\rightarrow{G}$ and $\nu:G\rightarrow{G}$
                defined by $h(x,y)=x*y$ and $\nu(g)=g^{\minus{1}}$ are smooth.
            \end{fdefinition}
            \begin{example}
                Taking the additive structure from the well known vector spaces
                $\nspace$ and $\mathbb{C}^{n}$ give rise to Lie groups.
                Topologically, $\mathbb{C}^{n}$ is homeomorphic to
                $\nspace[2n]$.
            \end{example}
            \begin{example}
                The unit circle $\nsphere[1]$ with the \textit{rotation}
                operation:
                \begin{equation}
                    \exp(i\theta_{1})*\exp(\theta_{2})
                        =\exp(i(\theta_{1}+\theta_{2}))
                \end{equation}
                Using this we can see that the $n$ torus $\ntorus$ is also a
                Lie group since it is the product of circles. We may endow it
                with the algebraic structure of $\nspace/\mathbb{Z}^{n}$.
            \end{example}
            \begin{example}
                Letting $H$ denote the quaternions, the topological structure is
                homeomorphic to $\nspace[4]$. Thus we may embed the 3-sphere
                $\nsphere[3]$ into $H$ by considering quaternions with norm 1.
                This shows that $\nsphere[3]$ has a Lie group structure.
            \end{example}
            \begin{example}
                The matrix groups $GL_{n}(\nspace[])$ are all examples of Lie
                groups when equipped with the topology of $\nspace[n^{2}]$.
            \end{example}
            The following question was posed by Hilbert in his famous list of
            problems released at the turn of the $20^{th}$ century. This is
            known as Hilbert's Fifth Problem.
            \begin{equation}
                \begin{split}
                    &\text{If }\topgroup{X}
                    \text{ is a topological group such that }
                    \topspace{X}\text{ is a topological}\\
                    &\text{manifold, then is this a Lie group?}
                \end{split}
            \end{equation}
            The answer is yes, the proof came in the 1950s. Moreover, the
            smooth structure is unique. This means there is no harm in defining
            a Lie group to be a a topological group with a topological manifold
            topology even though \textit{a priori} this seems weaker.
            \begin{fdefinition}{Lie Group Homomorphism}{Lie_Group_Homomorphism}
                A Lie group homomorphism from a Lie group
                $\topgroup[1]{G}$ to a Lie group $\topgroup[2]{G}$ is a smooth
                function $\phi:G_{1}\rightarrow{G}_{2}$ such that $\phi$ is a
                group homomorphism with respect to $\monoid[1]{G}$ and
                $\monoid[2]{G}$.
            \end{fdefinition}
            \begin{example}
                The exponential function gives rise to a Lie group homomorphism
                $\exp:\nspace[]\rightarrow\nsphere[1]$ by mapping
                $\theta\mapsto\exp(i\theta)$. Topologically this also a covering
                map.
            \end{example}
            \begin{example}
                Given a Lie group $G$ and an element $a\in{G}$, the inner
                automorphism $x\mapsto{a}*x*a^{\minus{1}}$ gives us a Lie group
                homomorphism.
            \end{example}
            \begin{theorem}
                If $\topgroup[1]{G}$ and $\topgroup[2]{G}$ are Lie groups and if
                $\phi:G_{1}\rightarrow{G}_{2}$ is a Lie group homomorphism, then
                $\phi$ is a map of constant rank.
            \end{theorem}
            \begin{proof}
                For $a\in{G}_{1}$, let $L_{a}$ be defined by $x\mapsto{a}*x$.
                This is a diffeomorphism.
            \end{proof}
            \begin{theorem}
                If $\phi:G_{1}\rightarrow{G}_{2}$ is a bijective Lie group
                homomorphism, then it is an isomorphism.
            \end{theorem}
            \begin{proof}
                By the inverse function theorem, together with the fact that the
                map has constant rank.
            \end{proof}
            \begin{fdefinition}{Lie Subgroup}{Lie Subgroup}
                A Lie subgroup of a Lie group $\topgroup[*][G]{G}$ is a Lie
                group $\topgroup[*][H]{H}$ and an injective Lie homomorphism
                $f:H\rightarrow{G}$, denoted $(H,f)$.
            \end{fdefinition}
            Note, given a Lie subgroup $(H,f)$ of a Lie group $G$ we often say
            tjat $f[H]$, the image of $H$ in $G$, is a Lie subgroup of $G$. This
            definition is well founded since a Lie subgroup is an immersed
            submanifold of $G$. This is because a Lie group homomorphism has
            constant rank, and if $f$ is injective then it must be an immersion
            by the theorem on rank. Note that a Lie subgroup of some Lie group
            $G$ need \textit{not} be a topological subgroup. A topological
            subgroup is a subgroup endowed with the subspace topology. Hence a
            Lie subgroup $(H,f)$ yields a topological subgroup if and only if
            $f$ is an embedding of $H$ into $G$.
            \begin{example}
                A line of irrational slope on a torus is an example of a Lie
                subgroup that is not a topological subgroup. It is an immersed
                submanifold, but not an embedded submanifold. If we take a line
                of \textit{rational} slope then we again obtain a Lie subgroup
                that is also a topological subgroup. This is homeomorphic to
                $\nsphere[1]$.
            \end{example}
            We'll need the following results:
            \begin{theorem}
                If $\iota:N\rightarrow{M}$ is an immersion, if $P$ is a
                manifold, and if $f:P\rightarrow{N}$ is a continuous function
                such that $\iota\circ{f}$ is smooth, then $f$ is smooth.
            \end{theorem}
            \begin{theorem}
                If $\iota:N\rightarrow{M}$ is an embedding, and if
                $\iota\circ{f}$ is smooth, then $f$ is smooth.
            \end{theorem}
            With this we may prove the following:
            \begin{theorem}
                If $\topgroup{G}$ is a Lie group, and if $(H,f)$ is a Lie
                subgroup such that $f:H\rightarrow{G}$ is an embedding, then
                $\topgroup[*][H]{H}$ is a Lie group.
            \end{theorem}
        \section{Lecture: 3}
            If we have an embedded submanifold of a Lie group that is also a
            Lie subgroup, then it is a Lie group itself.
            \begin{theorem}
                If $\phi:G_{1}\rightarrow{G}_{2}$ is a Lie group homomorphism,
                then the kernel of $\phi$ is a topological Lie subgroup of
                $G_{1}$.
            \end{theorem}
            \begin{proof}
                Since $\phi$ is a Lie group homomorphism it has constant rank.
                But then all level sets of $\phi$ are embedded submanifolds.
                Since $\phi$ is a homomorphism, $\phi^{\minus{1}}[\{0\}]$ is a
                subgroup as well. Hence, it is a topological Lie subgroup.
            \end{proof}
            \begin{example}
                Let $\mathbf{F}$ be either the real $\mathbb{R}$ or complex
                $\mathbb{C}$ numbers. Let $\SLnR{\mathbb{F}}$ denote the set of
                $n\times{n}$ matrices in $\GLnR{\mathbb{F}}$ such that the
                determinant is zero. This is just the kernel of the determinant
                map $\det:\GLnR{\mathbb{F}}\rightarrow\mathbb{F}^{\times}$,
                where $\mathbb{F}^{\times}$ is the multiplicative group of
                $\mathbb{F}$. Hence, $\det$ is a Lie group homomorphism and
                $\SLnR{\mathbb{F}}$ is a topological Lie subgroup of
                $\GLnR{\mathbb{R}}$.
            \end{example}
            \begin{example}
                Let $U(n)$ be the set of matrices in $\GLnR{\mathbb{C}}$ such
                that $A^{\dagger}A=I$, where $A^{\dagger}$ is the complex
                transpose $A^{\dagger}=\overline{A}^{T}$ where $\overline{A}$
                is the complex conjugate of $A$, and $A^{T}$ denotes the
                transpose. NOte the $U(n)$ can also be seen as the set of all
                endomorphisms $A\in\Endomorphisms{\mathbb{C}^{n}}$ such that $A$
                preserves a Hermitian symmetric bilinear form. Recall that a
                Hermitian blinear form on a vector space $V$ is a bilinear
                function $B:V\times{V}\rightarrow\mathbb{C}$ such that it is
                real bilinear, $B(cv,u)=\overline{c}B(v,u)$, and such that
                $B(v,cu)=cB(v,u)$. We say $B$ is symmetric if
                $B(v,w)=\overline{B(w,v)}$. Moreover, $B$ is positive definite
                if $B(v,v)$ is real and positive for all $v\ne{0}$. Returning to
                $U(n)$.
                The dimension of $U(n)$ over $\mathbb{R}$ is $n^{2}$. That is,
                this is the dimension of it as a real Lie group. It is not a
                complex Lie group.
            \end{example}
            \begin{example}
                The set $O(p,q)$ is the collection of all matrices in
                $\GLnR(\mathbb{R})$ such that $A^{T}I_{(p,q)}A=I_{(p,q)}$, where
                $I_{(p,q)}$ is the matrix:
                \begin{equation}
                    I_{(p,q)}=
                    \begin{bmatrix}
                        I_{p}&0\\
                        0&\minus{I}_{q}
                    \end{bmatrix}
                \end{equation}
                We can also think of $U(p,q)$ as the set of all
                $A\in\GLnR{\mathbb{C}}$ that preserve the Hermitian symmetric
                bilinear form on $\mathbb{C}^{n}$ given by:
                \begin{equation}
                    B(z,w)=\sum_{i=1}^{p}\overline{z}_{i}w_{i}-
                        \sum_{j=p+1}^{n}\overline{z}_{j}\overline{w}_{j}
                \end{equation}
            \end{example}
            \subsection{Classification of Hermitian Forms}
                Let $V$ be a finite dimensional vector space. Bilinear forms
                $B_{1},B_{2}:V\times{V}\rightarrow\mathbb{F}$ are said to be
                equivalent if there exists an isomorphism $T:V\rightarrow{V}$
                such that $B_{2}(v,w)=B_{1}(Tv,Tw)$. Equivalently, if we choose
                any basis $\mathscr{B}$ of $V$, then the matrices of $B_{1}$ and
                $B_{2}$ are similar matrices. That is, we have
                \begin{equation}
                    [B_{2}]_{\mathscr{B}}=
                    [T]_{\mathscr{B}}^{T}[B_{1}]_{\mathscr{B}}[T]_{\mathscr{B}}
                \end{equation}
                Over $\mathbb{R}$, all symmetric bilinear forms are equivalent
                to one of the form $[v,w]\mapsto{v}^{T}I_{(p,q)}w$. We then say
                the form has signature $(p,q)$.
                Over $\mathbb{C}$, all symmetric non-degenerate bilinear forms
                are equivalent. Using $O(n)$, a similarity transformation
                carries $[B]$ to the matrix:
                \begin{equation}
                    A=
                    \begin{bmatrix}
                        a_{1}&0&\dots&0\\
                        0&a_{2}&\dots&0\\
                        \vdots&\vdots&\ddots&\vdots\\
                        0&0&\dots&a_{n}
                    \end{bmatrix}
                \end{equation}
                So let $C$ be the matrix:
                \par
                Hermitian symmetric bilinear forms are classified by signature
                up to equivalence. We use a similar argument. We need to
                classify all of the equivalence classes of symmetric complex
                matrices under the equivalence $C\tilde{C}'$ if there exists a
                complex matrix $A$ such that $A^{\dagger}CA=C'$. Using unitary
                matrices $A\in{U}(n)$ we can always arrange $C'$ to be diagonal.
                Using a further equivalence writing $a_{ii}=1/\sqrt{|c_{ii}'|}$,
                then $A^{\dagger}C'A$ is of the form $I_{(p,q)}$.
                \par
                Finally, one can show that all skew symmetric matrices over
                either $\mathbb{R}$ or $\mathbb{C}$ are equivalent and hence all
                skew-symmetric bilinear forms are equivalent. Moreover, over
                $\mathbb{C}$ they're also equivalent to the symmetric ones. The
                eigenvalues will be purely imaginary.
                \par\hfill\par
                \begin{theorem}
                    Let $G$ be a Lie group and $G_{0}$ be the identity component
                    of $G$, which is the connected component containing the
                    identity elements $e\in{G}$. Then $G_{0}$ is a topological
                    Lie subgroup of $G$ and a normal subgroup.
                \end{theorem}
                \begin{proof}
                    Since $G_{0}$ is a connected component, it is an open
                    submanifold of $G$ and is hence an embedded manifold. So we
                    need to show that $G_{0}$ is a normal subgroup and we are
                    done. But if $F:G\rightarrow{G}$ is any continuous function
                    such that $F(G_{0})\cap{F}_{0}\ne\emptyset$, then
                    $F(G_{0})\subseteq{G}_{0}$. This is simply because $G_{0}$
                    is a connected component. Let $L_{a}$ be the left
                    multiplication function, $f(x)=a*x$ with $a\in{G}_{0}$.
                \end{proof}
        \section{Lie Algebras}
                Let $\mathbb{F}=\mathbb{R}$ or $\mathbb{C}$. A Lie algebra over
                $\mathbb{F}$ is a vector space $\mathfrak{g}$ together with a
                Lie brackek $\bracket{}{}:\mathfrak{g}\times\mathfrak{g}%
                \rightarrow\mathfrak{g}$ such that $\bracket{}{}$ is bilinear,
                anti-symmetric, and satisfies the Jacobi identity. A subalgebra
                is a subspace $\mathfrak{h}$ that is closed under the Lie
                bracket:
                $\bracket{\mathfrak{h}}{\mathfrak{h}}\subseteq\mathfrak{h}$. The
                notation $\bracket{\mathfrak{h},\mathfrak{h}}$ denotes the span
                of all elements of the form $[X,Y]$, $X,Y\in\mathfrak{g}$. A
                subalgebra is an ideal if
                $\bracket{\mathfrak{g},\mathfrak{h}}\subseteq\mathfrak{h}$.
                \begin{example}
                    An Abelian Lie algebra is a vector space $\mathfrak{g}$ with
                    $\bracket{X}{Y}=0$ for all $X,Y\in\mathfrak{g}$. That is,
                    the Lie bracket is symmetric. Since the Lie bracket is also
                    required to be anti-symmetric, it must then be the zero
                    function.
                \end{example}
                \begin{example}
                    Let $M$ be a smooth manifold and $\smoothvecf{M}$ the set of
                    all smooth vector fields on $M$. Then
                    $\bracket{\cdot}{\cdot}$ defined by:
                    \begin{equation}
                        \bracket{V}{W}=VW-WV
                    \end{equation}
                    is a Lie bracket on this space. This space is infinite
                    dimensional.
                \end{example}
                \begin{example}
                    If $V$ is a vector space, then $\Endomorphisms{V}$ can be
                    made into a Lie algebra with bracket:
                    \begin{equation}
                        \bracket{f}{g}=f\circ{g}-g\circ{f}
                    \end{equation}
                    If the dimension of $V$ is $n$ then this space is isomorphic
                    to $\matspace{\mathbb{F}}$ with the bracket:
                    \begin{equation}
                        \bracket{A}{B}=AB-BA
                    \end{equation}
                    The space $sl_{n}(\mathbb{F})$ of matrices with trace equal
                    to zero gives a subalgebra. Similarly $so_{n}(\mathbb{F})$
                    which is the set of all matrices $A$ such that
                    $A^{T}+A=0$.
                \end{example}
                \begin{example}
                    If $\mathfrak{g}$ is a Lie algebra, then the set
                    $\bracket{\mathfrak{g}}{\mathfrak{g}}$ is called the derived
                    algebra and is an ideal.
                \end{example}
                \begin{example}
                    The center of $\mathfrak{g}$, which is the set of all
                    $X\in\mathfrak{g}$ such that $\bracket{X,Y}=0$ for all
                    $Y\in\mathfrak{g}$.
                \end{example}
                \begin{example}
                    The Heisenberg Algebra.
                \end{example}
                More generally, let $V$ and $W$ be vector spaces and
                $B:V\times{V}\rightarrow{W}$ be a bilinear map. Let
                $\mathfrak{g}=V\oplus{W}$ with the bracket:
                \begin{equation}
                    \bracket{X_{1}+W_{1}}{X_{2}+W_{2}}=B(X_{1},X_{2})
                \end{equation}
                A Lie algebra representation $(\rho,V)$ of a Lie Algebra
                $\mathfrak{g}$ is a Lie algebra homomorphism
                $\rho:\mathfrak{g}\rightarrow\Endomorphisms{V}$. A derivation of
                a Lie algebra $\mathfrak{g}$ is a Linear map
                $D:\mathfrak{g}\rightarrow\mathfrak{g}$ such that:
                \begin{equation}
                    D(\bracket{X}{Y})=\bracket{D(X)}{Y}+\bracket{X}{D(Y)}
                \end{equation}
                The set $Der(\mathfrak{g})$ is the space of all derivations.
                There are some interpretations of the Jacobi identity. If $V$ is
                a vector space and $B:V\times{V}\rightarrow{V}$ is a bilinear
                map, then $B$ gives rise to a map
                $\alpha:V\rightarrow\Endomorphisms{V}$ by
                $\alpha(v)=B(v,\cdot)$. In the case of a Lie algebra with
                $B=\bracket{\cdot}{\cdot}$ the map $\alpha(X)$ is called the
                adjoint of $X$, $\adX:\mathfrak{g}\rightarrow\mathfrak{g}$
                defined by $\adX(Y)=\bracket{X}{Y}$.
\end{document}