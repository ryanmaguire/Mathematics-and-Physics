\section{Definitions}
    \begin{fdefinition}{Fields}{Fields}
        A field is a commutative ring $(\mathbb{F},+,\cdot\,)$ such that, for
        all $a\in\mathbb{F}$ such that $a$ is not the unital element of
        $(\mathbb{F},+)$, it is true that $a$ is an invertible element of
        $(\mathbb{F},\cdot\,)$.
    \end{fdefinition}
    \begin{fdefinition}{Subfield}{Subfield}
        A subfield of a field $(F,+,\cdot)$ is a set $K\subset F$, such that
        $(K,+,\cdot)$ is a field.
    \end{fdefinition}
    Given an element $a\in\mathbb{F}$, if $b$ is such that
    $a+b=0$ then we write $b=\minus{a}$. Subtraction of two elements
    $a$ and $c$, denoted $a-c$, is defined as $a+(\minus{c})$. The
    structure $(\mathbb{F},+)$ forms an Abelian group. From this we have
    that the identity is unique, as are additive inverses.
    It is common in the definition of a field to require that
    $0\ne{1}$. This is because if $0=1$ then we have $\mathbb{F}=\{0\}$.
    This comes from the following.
    \begin{ltheorem}{Multiplication by Zero}{Multiplication_by_Zero}
        If $(\mathbb{F},\,+,\,\cdot\,)$ is a field, and if $a\in\mathbb{F}$,
        then $a\cdot{0}=0$.
    \end{ltheorem}
    \begin{proof}
        For we have:
        \begin{equation}
            0=a\cdot(0)-a\cdot(0)=a\cdot(0-0)=a\cdot{0}
        \end{equation}
        This simply combines the distributive law with the additive
        property of zero, completing the proof.
    \end{proof}
    \begin{theorem}
        If $(\mathbb{F},\,+,\,\cdot\,)$ is a field, and if $0=1$, then
        $\mathbb{F}=\{0\}$.
    \end{theorem}
    \begin{proof}
        For suppose not, and let $a\in\mathbb{F}$ be such that $a\ne{0}$.
        But then, by Thm.~\ref{thm:Multiplication_by_Zero}:
        \begin{equation}
            a=a\cdot{1}=a\cdot{0}=0
        \end{equation}
        And thus $a=0$, a contradiction. Therefore,
        $\mathbb{F}$ is trivial.
    \end{proof}
    It is thus common to either call such a field a trivial field, or
    to require that $0\ne{1}$.
    \begin{lexample}{Examples of Fields}{Examples_of_Fields}
        There are several fields that should be familiar to the reader.
        If we let $\mathbb{R}$ denote the real numbers and $+$ and $\cdot$
        be the usual notations of addition and multiplication, then
        $(\mathbb{R},\,+,\,\cdot\,)$ is a field. Similarly, letting
        $\mathbb{Q}$ denote the rational numbers and $\mathbb{C}$ denote
        the complex numbers, $(\mathbb{Q},\,+,\,\cdot\,)$ is a field, as
        is $(\mathbb{C},\,+,\,\cdot\,)$. There are finite fields as well.
        Let $\mathbb{F}_{2}=\{0,\,1\}$ and define multiplication and
        addition as follows:
        \par\hfill\par
        \begin{table}[H]
            \centering
            \captionsetup{type=table}
            \parbox{.45\linewidth}{%
                \centering
                \begin{tabular}{c|cc}
                    $+$&0&1\\
                    \hline
                    0&0&1\\
                    1&1&0
                \end{tabular}
            }
            \parbox{.45\linewidth}{%
                \centering
                \begin{tabular}{c|cc}
                    $\cdot$&0&1\\
                    \hline
                    0&0&0\\
                    1&0&1
                \end{tabular}
            }
            \caption{The Arithmetic of $\mathbb{F}_{2}$}
        \end{table}
        $(\mathbb{F}_{2},\,+,\,\cdot)$ forms a field. Finally, if
        $p\in\mathbb{N}$ is prime, and if $+$ and $\cdot$ are addition
        and multiplication mod $p$, respectively, then
        $(\mathbb{Z}_{p},\,+,\,\cdot\,)$ is a field.
    \end{lexample}
    \begin{fdefinition}{Vector Space}{Vector_Space}
        A vector space over a field $(\mathbb{F},\,+,\,\cdot\,)$ is a
        set $V$ and a function
        $\boldsymbol{\cdot}:\mathbb{F}\times{V}\rightarrow{V}$ and
        a binary operation $\boldsymbol{+}$ on $V$, usuall called
        scalar multiplication and vector addition, respectively, 
        such that for all $\mathbf{x},\mathbf{y},\mathbf{z}\in{V}$,
        and all $a,b\in\mathbf{F}$, the following is true:
        \begin{enumerate}
            \item $\mathbf{x}\boldsymbol{+}%
                   (\mathbf{y}\boldsymbol{+}\mathbf{z})=%
                   (\mathbf{x}\boldsymbol{+}\mathbf{y})%
                   \boldsymbol{+}\mathbf{z}$
                  \hfill[Associative of Vector Addition]
            \item $\mathbf{x}\boldsymbol{+}\mathbf{y}=%
                   \mathbf{y}\boldsymbol{+}\mathbf{x}$
                  \hfill[Commutativity of Vector Addition]
            \item There is a $\mathbf{0}\in{V}$ such that
                  $\mathbf{0}\boldsymbol{+}\mathbf{x}=\mathbf{x}$
                  \hfill[Existence of Zero Vector]
            \item For all $\mathbf{x}$ there is a $\mathbf{y}$ such that
                  $\mathbf{x}\boldsymbol{+}\mathbf{y}=\mathbf{0}$
                  \hfill[Additive Inverses]
            \item $(a\cdot{b})\boldsymbol{\cdot}\mathbf{x}=%
                    a\boldsymbol{\cdot}(b\boldsymbol{\cdot}\mathbf{x})$
                  \hfill[Compatibility of Multiplication]
            \item $(a+b)\boldsymbol{\cdot}\mathbf{x}=%
                   (a\boldsymbol{\cdot}\mathbf{x})\boldsymbol{+}%
                   (b\boldsymbol{\cdot}\mathbf{x})$
                  \hfill[Distributive Law for Field Addition]
            \item $a\boldsymbol{\cdot}(\mathbf{x}\boldsymbol{+}\mathbf{y})=%
                   (a\boldsymbol{\cdot}\mathbf{x})\boldsymbol{+}%
                   (a\boldsymbol{\cdot}\mathbf{y})$
                  \hfill[Distributive Law for Vector Addition]
        \end{enumerate}
    \end{fdefinition}
    It is quite common not to distinguish between scalar multiplication
    $\boldsymbol{\cdot}$ and field multiplication $\cdot$, which may cause
    confusion. It is also common to drop the use of a symbol altogether and
    simply representation multiplication by concatenation of the the
    two variables, for example $a\mathbf{x}$ or $ab$, which represents
    scalar multiplication and field multiplication, respectively.
    \begin{example}
        If we let $\mathbb{F}=\mathbb{R}$ and let
        $V=\mathbb{R}^{n}$, where addition, multiplication, scalar
        multiplication, and vector addition are defined in their usual
        manner, then this forms a vector space. Similarly, the space
        $C([a,b])$ of continuous functions forms a vector space over
        $\mathbb{R}$, as does $L^{2}(\mathbb{R})$, the space of
        square integrable functions.
    \end{example}
    \begin{fdefinition}{Bilinear Operations}{Bilinear_Operations}
        A bilinear operation on a vector space
        $(V,\,\boldsymbol{+},\,\boldsymbol{\cdot}\,)$ over a field
        $(\mathbf{F},\,+,\,\cdot\,)$ is a function
        $[\,]:V\times{V}\rightarrow{V}$ such that, for all
        $\mathbf{x},\mathbf{y},\mathbf{z}\in{V}$, and for all
        $a,b\in\mathbf{F}$, the following is true:
        \begin{enumerate}
            \item $[\mathbf{x}\boldsymbol{+}\mathbf{y}, \mathbf{z}]=%
                   [\mathbf{x},\mathbf{z}]\boldsymbol{+}%
                   [\mathbf{y},\mathbf{z}]$
                  \hfill[Right Distributive Law]
            \item $[\mathbf{x},\mathbf{y}\boldsymbol{+}\mathbf{z}]=%
                   [\mathbf{x},\mathbf{y}]\boldsymbol{+}%
                   [\mathbf{x},\mathbf{z}]$
                  \hfill[Left Distributive Law]
            \item $[a\boldsymbol{\cdot}\mathbf{x},%
                    b\boldsymbol{\cdot}\mathbf{y}]=%
                   (a\cdot{b})\boldsymbol{\cdot}[\mathbf{x},\mathbf{y}]$
                  \hfill[Compatibility with Scalars]
        \end{enumerate}
    \end{fdefinition}
    \begin{lexample}{Examples of Bilinear Operations}
                    {Examples_of_Bilinear_Operation}
        The quintessential example of a bilinear operation is the
        cross product that one encounters in a multivariable calculus
        course. That is, for any three vectors
        $\mathbf{x},\mathbf{y},\mathbf{z}$, we have:
        \begin{equation}
            \mathbf{x}\times(\mathbf{y}+\mathbf{z})=
            \mathbf{x}\times\mathbf{y}+\mathbf{x}\times\mathbf{z}
        \end{equation}
        Similarly for right sided multiplication. The compatibility of
        the cross product with scalar multiplication is also true:
        \begin{equation}
            (a\mathbf{x})\times(b\mathbf{y})=ab(\mathbf{x}\times\mathbf{y})
        \end{equation}
        This serves somewhat as a motivating example for bilinear
        operations. If we think of the field of invertible matrices,
        then multiplication forms a bilinear operation as well, with
        scalar multiplication being the usual entry wise operation that
        is done on matrices. Lastly, if $\langle\,\rangle$ is an inner
        product on $\mathbb{R}$ or $\mathbb{C}$, then this is a bilinear
        operation, the vector space being the underlying field itself.
    \end{lexample}
    \begin{fdefinition}{Algebra over a Field}{Algebra_over_a_Field}
        An algebra of a field $(\mathbf{F},\,+,\,\cdot\,)$ is a
        vector space $(\mathbf{V},\,\boldsymbol{+},\,\boldsymbol{\cdot}\,)$
        and a bilinear operation $[\,]:V\times{V}\rightarrow{V}$.
    \end{fdefinition}
    \begin{fdefinition}{Associative Algebra over a Field}
                       {Associative_Algebra_over_a_Field}
        An associative algebra over a field $(\mathbb{F},\,+,\,\cdot\,)$
        is an algebra $(V,[\,])$ over $\mathbb{F}$ such that, for all
        $r\in\mathbb{F}$ and for all $\mathbf{x},\mathbf{y}\in{V}$,
        the following is true:
        \begin{equation}
            r[\mathbf{x},\,\mathbf{y}]=[r\mathbf{x},\,\mathbf{y}]
                                      =[\mathbf{x},\,r\mathbf{y}]
        \end{equation}
    \end{fdefinition}
    \begin{fdefinition}{Derivation on an Algebra}{Derivation_on_an_Algebra}
        A derivation on an algebra $(V,\,[\,])$ is a function
        $D:V\rightarrow{V}$ such that for all $\mathbf{x},\mathbf{y}\in{V}$,
        the following (Liebniz's Rule) is true:
        \begin{equation}
            D([\mathbf{x},\mathbf{y}])
            =[\mathbf{x},D(\mathbf{y})]+[D(\mathbf{x}),\mathbf{y}]
        \end{equation}
    \end{fdefinition}
    \begin{theorem}
        In a field, $0$ and $1$ are unique.
    \end{theorem}
    \begin{proof}
        For suppose not, and let $0'$ and $1'$ be other identities.
        Then $1'=1'\cdot 1 = 1$ and $0'=0'+0=0$.
    \end{proof}
    \begin{theorem}
        For any field $\langle{F},+,\cdot\rangle$ and $a\in{F}$, $a\cdot{0}=0$.
    \end{theorem}
    \begin{proof}
        For:
        \begin{equation}
            0=a\cdot{0}+(\minus{a}\cdot{0})
             =a\cdot(0+0)+(\minus{a}\cdot{0})
             =a\cdot{0}+a\cdot{0}+(\minus{a}\cdot{0})
             =a\cdot 0
        \end{equation}
        Thus, $a\cdot{0}=0$.
    \end{proof}
    If $1=0$, then $a=a\cdot{1}=a\cdot{0}=0$, and thus every element is
    zero. A very boring field.
    \begin{theorem}
        In a field $\langle F, +,\cdot \rangle$, if $0\ne 1$, then $0$ has no
        inverse.
    \end{theorem}
    \begin{proof}
        For let $a$ be such an inverse. Then $a\cdot{0}=1$. But for any element
        of $F$, $a\cdot{0}=0$. But $0\ne{1}$, a contradiction.
    \end{proof}
    \begin{theorem}
        If $a+b=0$, then $b=(\minus{1})\cdot{a}$ where $(\minus{1})$ is the
        solution to $1+(\minus{1})=0$.
    \end{theorem}
    \begin{proof}
        $a+(\minus{1})a=a(1+(\minus{1}))=a\cdot{0}=0$. From uniqueness,
        $b=(\minus{1})a$. We may thus write additive inverses as $\minus{a}$.
    \end{proof}
    \begin{definition}
        Given two fields $(F,+,\cdot)$ and $(F',+',\times)$, a bijection
        function $f:F\rightarrow{F}'$ is said to be a field isomorphism if and
        only if for allelements $a,b\in{F}$, $f(a+b)=f(a)+'f(b)$, and
        $f(a\cdot{b})=f(a)\times{f}(b)$
    \end{definition}
    \begin{definition}
        $(F,+,\cdot)$ and $(F',+',\times)$, are said to be isomorphic if and
        only if they have an isomorphism.
    \end{definition}
    \begin{theorem}
        If $\ring[F]{F}$ is a field, if $\ring[K]{K}$ is a field, and if
        $\phi:F\rightarrow{K}$ is a field isomorphism, then
        $\phi(1_{F})=1_{K}$ and $\phi(0_{F})=\phi(0_{K})$.
    \end{theorem}
    \begin{proof}
        For suppose not. If $\phi(1_{F})\ne{1}_{K}$, then $\phi(1_{F})$ is not
        the unital element of $K$ and thus there exists $y\in{K}$ such that
        $\phi(1_{F})\cdot_{K}y\ne{y}$. But since $\phi$ is an isomorphism, it is
        bijective and thus there is an $x\in{F}$ such that $\phi(f)=y$. But
        since $\phi$ is an isomorphism, we have:
        \begin{equation}
            y=\phi(x)=\phi(x\cdot_{F}1_{F})=\phi(x)\cdot_{K}\phi(1_{F})
        \end{equation}
        A contradiction. Thus, $\phi(1_{F})=1_{K}$. Similarly for $0_{F}$.
    \end{proof}
    \begin{theorem}
        In a field $(F,+,\cdot)$, $(a+b)^{2}=a^{2}+2ab+b^{2}$
        ($2$ being the solution to $1+1$).
    \end{theorem}
    \begin{proof}
        For:
        \begin{align}
            (a+b)^{2}&=(a+b)(a+b)\\
                     &=a(a+b)+b(a+b)\\
                     &=a^{2}+ab+ba+b^{2}\\
                     &=a^{2}+ab(1+1)+b^{2}\\
                     &=a^{2}+2ab+b^{2}
        \end{align}
    \end{proof}