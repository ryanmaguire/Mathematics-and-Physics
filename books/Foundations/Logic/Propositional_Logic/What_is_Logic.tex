\section{What is Logic?}
    It may seem strange to start a work on mathematics with an entire
    development of logic, as one might think such conversations should reside
    in philosophy. And indeed, much of classical logic was developed by
    philosophers, rather than mathematicians. Many problems, which we will
    discuss in Chapt.~\ref{chapt:Zermelo_Fraenkel_Set_Theory}, arose in the
    early 1900s with the very core of mathematics. Arguments once considered
    sound were shattered, and contradictions were discovered. On the other hand,
    other methods of proof that are very intuitive were shown to be able to
    prove the existence of non-intuitive and almost impossible objects.
    \begin{example}
        A student of calculus most likely knows well the
        \textit{intermediate value theorem}%
        \index{Theorem!Intermediate Value Theorem}%
        \index{Intermediate Value Theorem}. To those who don't, fear not, we
        shall draw pictures. Given a \textit{continuous} function $f$ of real
        numbers (roughly speaking, a curve one can draw from left to right
        without lifting up ones pencil), if $0$ evaluates to a negative number
        and $1$ evaluates to a positive number, then there is some number in the
        middle which evaluates to zero. The method of proof is quite simple:
        We first look at what happens at the point $\frac{1}{2}$. If $f$
        is zero at this point, we are done and the theorem is proved, otherwise
        if $f$ evaluates to a positive number then we may suspect there's a
        point in between 0 and $\frac{1}{2}$ that evaluates to zero. If $f$ is
        negative at the point, then there's probably a zero in between
        $\frac{1}{2}$ and 1. In either case, we divide the range of
        possibilities in half once again and see what happens at $\frac{1}{4}$
        in the first case, and $\frac{3}{4}$ in the latter. We continue
        \textit{inductively} (whatever this means) and obtain a
        \textit{sequence} of real numbers which we then show
        \textit{converge} to some real number between 0 and 1. We then invoke
        continuity to show that $f$ evaluates to zero at this point, and we are
        done (See Fig.~\ref{fig:Sketch_of_IVP}).
    \end{example}
    \begin{figure}[H]
        \centering
        \captionsetup{type=figure}
        \includegraphics{images/Intermediate_Value_Theorem_Sketch.pdf}
        \caption{Sketch of the Intermediate Value Theorem}
        \label{fig:Sketch_of_IVP}
    \end{figure}
    We can see why this may work. After a few iterations we've narrowed down the
    zero point to a very small range between $x_{3}$ and $x_{5}$, and this is a
    nice algorithm that we can tell a computer to execute to arbitrary
    precision, but what went into the proof? That is, if we were to phrase this
    with absolute precision, what definitions, assumptions, and previous
    theorems are we relying on? For one, the existence of \textit{real number},
    a notion of \textit{continuity}, and the definition of a \textit{sequence}.
    Our exposition of logic is to make clear what is required for valid proofs.
    \subsection{Truth}
        Since the aim of mathematics is to prove the validity of mathematical
        statements, we start with a definition of truth. We run into a wall
        instantly with this, since this is essentially an impossible task. Any
        definition will ultimately be circular, and indeed it is a theorem of
        Alfred Tarski\index{Tarski, Alfred} that if one has somehow already
        defined arithmetic, then one cannot use arithmetic to define truth. That
        is to say, if we take upon the assumption of the existence of the
        natural numbers 0, 1, 2, $\dots$ with the familiar notion of addition
        $+$ (i.e. $1+1=2$ and other mathematical gems), then \textit{arithmetic}
        truth cannot be defined using this arithmetic. We propose the following
        work around: Truth is a primitive notion that needs no definition. We
        can then define false to mean \textit{not} true.
        \par\hfill\par
        Tarski's result came about in the 1930's when he tried to mathematically
        work out the \textit{liar's paradox}\index{Paradox!Liar's}%
        \index{Liar's Paradox}. Consider the following sentence:
        \begin{equation}
            \text{This sentence is false.}
        \end{equation}
        Similar statements have been considered throughout the ages, including
        the variant known as Epimenides' paradox\index{Paradox!Epimenides'}.
        Epimenides, who was from Crete, proclaims ``All Cretans are liars.''
        The question was considered again 200 years later in Miletus when
        Eubulides considered the sentence ``I am lying.'' Further still, in the
        Book of Psalms, king David states that all men are liars. Needless to
        say, the paradox is quite old and well studied. Now we ask, is the
        statement \textit{true} or \textit{false} (Assuming that such notions
        have been defined)? Let's work through it, and suppose truth. If
        this sentence is false is true, then the sentence is false even though
        we just claimed it to be true. Hence, it must be false. But if this
        sentence is false is false, then the sentence is true, but we just
        showed it cannot be true. So, which one is it? There are two
        interpretations: The statement is \textit{neither} true nor false, and
        the sentence is \textit{both} true and false. Suppose we accept that the
        statement is neither true nor false. This only leads to another
        sentence in which we cannot make such a conclusion:
        \begin{equation}
            \text{This sentence is not true.}
        \end{equation}
        If this is neither true nor false, then it is not true, and hence true,
        bringing us back to the paradox. So perhaps we claim that is it both
        true and false, but then we arrive at:
        \begin{equation}
            \text{The sentence is false and not true.}
        \end{equation}
        And hence there seems to be no workaround. The problem intensifies if we
        consider pairs of sentences:
        \twocolumneq{%
            \label{eqn:That_Sentence_Is_True}%
            \text{The statement \ref{eqn:That_Statement_Is_False} is true.}
        }
        {%
            \label{eqn:That_Statement_Is_False}%
            \text{The statement \ref{eqn:That_Sentence_Is_True} is false.}
        }
        and now we go round and round in an endless circle. As Alfred Tarski
        pointed out, the problem arises in languages in which statements are
        allowed to be self-referential. To that this is indeed a self refering
        claim, we can write $P$ for the proposition and we arrive at the
        equation:
        \begin{equation}
            P=P\text{ is false.}
        \end{equation}
        if we substitute $P$, we obtain:
        \begin{equation}
            P=(P\textit{ is false})\text{ is false.}
             =\big((P\text{ is false})\text{ is false}\big)\text{ is false.}
        \end{equation}
        While it may seem like this is an unnecessary discussion, the liar's
        paradox actually plays a role in mathematics. For one, as stated before,
        it motivates Tarski's theorem on the defineability of truth, and perhaps
        more famously it allowed Kurt G\"{o}del\index{G\"{o}del, Kurt} to prove
        his \textit{incompleteness theorems}, which really shook most of modern
        mathematics. Indeed, this theorem allegedly made Albert
        Einstein\index{Einstein, Albert} believe that there could be no
        \textit{theory of everything}\index{Theory of Everything}, a theory of
        physics that could solve all problems great and small. For the sake of
        moving on to mathematics, we accept truth to be a primitive notion and
        acknowledge that the foundations of this concept are very shaky.
    \subsection{Sets}
        The main objects in mathematics are \textit{sets}. This development came
        about in the 1800's with figures such as Georg
        Cantor\index{Cantor, Georg}, Augusts De
        Morgan\index{De Morgan, Augustus}, and Bernard
        Bolzano\index{Bolzano, Bernard} making the first strides in the theory.
        The early history is very loose, but intuitive, but the vagueness
        ultimately led to Russell's Paradox\index{Paradox!Russell's} which
        showed the naivity of set theory to be inconsistent. We'll discuss this
        in Chapt.~\ref{chapt:Zermelo_Fraenkel_Set_Theory} when we develop
        Zermelo-Fraenkel set theory, for now we just need a definition. In
        Cantor's 1895 work
        \textit{Beitr\"{a}ge zur Begr\"{u}ndung der transfiniten Mengenlehre}
        (Contributions in Support of Transfinite Set Theory), he writes
        \textit{A set is a gathering together in whole of definite distinct}
        \textit{objects of our perception or of our thought, which are called}
        \textit{the elements of the set}. Beautifully phrased, but circular. The
        word \textit{gathering} is not defined, nor is \textit{objects}. Any
        attempt at defining these will lead to the same problem, and thus we
        find ourselves in need of introducing another primitive notion: The
        notion of set. We adopt the following definition.
        \begin{fdefinition}{Set}{Set}
            A \gls{set} is a collection of objects called the elements of the
            set.\index{Set}
        \end{fdefinition}
        If we wish to stand on a truly solid foundation, it seems we're off to a
        bad start. In defining sets we've used the words \textit{collection} and
        \textit{objects}, neither of which have been defined. This is the same
        problem as the circularity we pointed out in Cantor's definition. To
        begin stating definitions and theorems we need the existence of a
        \textit{thing}. Sets act as our thing. We know they exist, but we don't
        know how to define them all to well. Nevertheless, we can describe how
        they behave and what they can do, as well as how to obtain new sets from
        pre-existing ones.
        \begin{fnotation}{Element Notation}{Element_Notation}
            If $A$ is a \gls{set} and if $x$ is an element\index{Set!Element of}
            of $A$, then we denote this by writing
            \glslink{containmentsymb}{$x\in{A}$}. If $x$ is not an element
            of $A$, we write $x\notin{A}$.\index{Containment $\in$}
        \end{fnotation}
        We are not developing set theory just yet, since we have yet to build up
        logic. In the most elementary systems such as Peano arithmetic
        there is a notion of set, and hence we need to define this first.
        Pedagogically it is poor to proceed without examples, and hence we do
        this presently.
        \begin{example}
            The first three letters of the Latin alphabet can be expressed in
            set notation as follows. If let let the symbol $A$ denote this set,
            we may write:
            \begin{equation}
                A=\{\,a,\,b,\,c\,\}
            \end{equation}
            If we let $B$ denote the first three positive integers, we obtain:
            \begin{equation}
                B=\{\,1,\,2,\,3\,\}
            \end{equation}
            Using element notation (Not.~\ref{not:Element_Notation}) we see that
            $1\in{B}$, but $4\notin{B}$. That is, $B$ contains the number 1 but
            does not contain the number 4. Similarly, $a\in{A}$ and
            $d\notin{A}$. The symbol $\in$ should read \textit{is in}, or
            \textit{is an element of}, or \textit{is contained inside of}. Thus
            $a\in{A}$ read $a$ is an element of $A$, or simply $a$ is in $A$.
            The notation $b\in{A}$ also reads as $b$ is contained inside of $A$.
            The notation $\notin$ is the negation of this: \textit{not in} or
            \textit{not and element of}. Hence, $4\notin{B}$ reads 4 is not an
            element of $B$.
        \end{example}
        \begin{example}
            \label{ex:Everything_is_a_Set}%
            In the set theory that we will be working with, Zermelo-Fraenkel set
            theory, \textit{everything} is a set. This will be explained later,
            but we quite literally mean everything. The integers will be defined
            via John von Neumann's\index{von Neumann, John} construction. We
            start with the empty set $\emptyset$ which is the set that contains
            nothing, often denoted $\emptyset=\{\,\}$, and this will be our
            zero. We proceed and define $1=\{\emptyset\}$, $2=\{0,1\}$,
            $3=\{1,2,3\}$, and so on.
        \end{example}
        Elaborating on the discussion in Ex.~\ref{ex:Everything_is_a_Set}, there
        are other theories for the foundations of mathematics that allow other
        primitive notions such as classes and universes and whatnot. Some of
        these theories are extremely weak (cannot prove much) but very safe
        (there is likely no contradiction), whereas some are very user friendly
        but almost certainly fallacious. Peano's axioms are an example of a weak
        system of which the axioms are so basic and obvious that no one is
        likely to ever find a contradiction, but are so weak that they can't
        even assert the existence of negative integers, let alone the rationals
        or reals. On the other hand, any theory that allows one to say the
        \textit{collection} of all sets (whether the collection is a class, or a
        universe, or whatever) is one that should be treated with skepticism.
        The theory of Zermelo and Fraenkel is a healthy middle ground. Strong
        enough to do most mathematics, and no contradiction found (yet), though
        much of the $20^{th}$ century was spent searching to no avail.
    \subsection{Predicates}
        Propositions and predicates will be two more of our primitive notions
        which will will vaguely define, but mostly rely on intuition.
        \begin{fdefinition}{Predicate}{Predicate}
            A predicate $P$ on a \gls{set} $A$ is a sentence such that for all
            $x\in{A}$ either the sentence is either true of $x$ or it is false.
            That is, either $P(x)$ is true or $P(x)$ is false.
        \end{fdefinition}
        Predicates are the main tool used in set theory for defining and
        building new sets. All of this will be discussed later when we
        encounter the \textit{axiom schema of specificaiton}%
        \index{Axiom!Schema of Specification}. Many describe predicates as
        \textit{functions} from the set $A$ to the Boolean-valued set
        $\{\text{True},\text{False}\}$ and this is a fine way of doing this
        provided the notion function has been defined. Many take function as
        another primitive, but we'll adopt the definition of a function in terms
        of subsets using the axioms of set theory. Hence we have the following
        predicamant: Do we take the word \textit{predicate} as a primitive
        concept, or the word \textit{function}? We're adopting predicate as our
        primitive, but the argument can be made for the latter choice.
    \subsection{Misc}
        \begin{table}[H]
            \centering
            \captionsetup{type=table}
            \begin{tabular}{c c c c c c}
                \hline
                $p$&$q$&$r$&$\neg{q}$&$p\lor\neg{q}$&$(p\lor\neg{q})\land{r}$\\
                \hline
                0&0&0&1&1&0\\
                0&0&1&1&1&1\\
                0&1&0&0&0&0\\
                0&1&1&0&0&0\\
                1&0&0&1&1&0\\
                1&0&1&1&1&1\\
                1&1&0&0&1&0\\
                1&1&1&0&1&1\\
                \hline
            \end{tabular}
            \caption{Truth Table for $(p\lor\neg{q})\land{r}$}
            \label{tab:Truth_Table_Example}
        \end{table}
        \begin{theorem}
            If $a\rightarrow{b}$, if $\neg{c}\rightarrow\neg{b}$, and if
            $\neg{c}$, then $\neg{a}$.
        \end{theorem}
        \begin{proof}
            For if $a\rightarrow{b}$, then $\neg{b}\rightarrow\neg{a}$. But
            $\neg{c}\rightarrow\neg{b}$. But if $\neg{c}\rightarrow\neg{b}$ and
            $\neg{b}\rightarrow\neg{a}$, then $\neg{c}\rightarrow\neg{a}$. Thus
            $a\rightarrow{b}$, $\neg{c}\rightarrow\neg{b}$, and thus
            $\neg{c}\Rightarrow\neg{a}$.
        \end{proof}
        \begin{problem}
            If $a\rightarrow{b}$, if $\neg{c}\rightarrow\neg{b}$, and if
            $\neg{c}$, then $\neg{a}$.
        \end{problem}
        \begin{proof}
            For if $\neg c \rightarrow \neg b$, then $b\rightarrow c$. But if
            $a\rightarrow b$ and $b\rightarrow c$, then $a\rightarrow c$.
            Therefore $a\rightarrow c$. But if $a\rightarrow c$, then
            $\neg c \rightarrow \neg a$. Therefore,
            $a\rightarrow b,\neg c\rightarrow\neg b,\neg c\Rightarrow\neg a$.
        \end{proof}