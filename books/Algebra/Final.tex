%------------------------------------------------------------------------------%
\documentclass[crop=false,class=article]{standalone}                           %
%------------------------------Preamble----------------------------------------%
\makeatletter                                                                  %
    \def\input@path{{../../}}                                                  %
\makeatother                                                                   %
\input{preamble.tex}                                                           %
%----------------------------Main Document-------------------------------------%
\begin{document}
    \title{Final}
    \author{Ryan Maguire}
    \date{\vspace{-5ex}}
    \maketitle
    \section*{Problem 2}
        \setcounter{section}{2}
        Since $\mathbb{C}$ is algebraically closed, there is a Jordan normal
        form for $T$. Since $\lambda$ is the only eigenvalue, we have:
        \begin{equation}
            J=
            \begin{bmatrix}
                \lambda&1&0&\dots&0&0\\
                0&\lambda&1&\dots&0&0\\
                0&0&\lambda&\dots&0&0\\
                \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
                0&0&0&\dots&\lambda&1\\
                0&0&0&\dots&0&\lambda
            \end{bmatrix}
        \end{equation}
        Let $B_{n}$ be the matrix with 1 on the super-diagonal, and 0 everywhere
        else. Then $J=\lambda{I}_{n}+B_{n}$. But then:
        \begin{equation}
            J^{2}-\lambda^{2}I_{n}=(J-\lambda{I}_{n})(J+\lambda{I}_{n})
        \end{equation}
        But $J-\lambda{I}_{n}$ is just the super-diagonal $B_{n}$. If
        $\lambda\ne{0}$, then:
        \begin{equation}
            J+\lambda{I}_{n}=
            \begin{bmatrix}
                2\lambda&1&0&\dots&0&0\\
                0&2\lambda&1&\dots&0&0\\
                0&0&2\lambda&\dots&0&0\\
                \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
                0&0&0&\dots&2\lambda&1\\
                0&0&0&\dots&0&2\lambda
            \end{bmatrix}
        \end{equation}
        Which is invertible, denote this by $P$. But then:
        \begin{equation}
            J^{2}=P^{\minus{1}}\big(\lambda^{2}I_{n}+B_{n}\big)P
        \end{equation}
        And therefore the Jordan normal form of $J^{2}$ is
        $\lambda^{2}I_{n}+B_{n}$:
        \begin{equation}
            J'=
            \begin{bmatrix}
                \lambda^{2}&1&0&\dots&0&0\\
                0&\lambda^{2}&1&\dots&0&0\\
                0&0&\lambda^{2}&\dots&0&0\\
                \vdots&\vdots&\vdots&\ddots&\vdots&\vdots\\
                0&0&0&\dots&\lambda^{2}&1\\
                0&0&0&\dots&0&\lambda^{2}
            \end{bmatrix}
        \end{equation}
    \section*{Problem 3}
        For if $G$ is a finite group and $H$ is a subgroup of $G$, then by
        Lagrange's theorem we have that $|G|=n\cdot|H|$ for some
        $n\in\mathbb{N}^{+}$. But if $H$ is a proper subset of $G$, then
        $n\ne{1}$, and so we have $n\geq{2}$. Looking at the conjugacy classes
        $gHg^{\minus{1}}$, there are at most $n$ such elements for otherwise
        $|G|/|H|>n$. But $H$ is a subgroup, and thus $e\in{H}$, and so
        $g*e*g^{\minus{1}}=e$ is in each conjugacy class. If we sum over the
        $|H|$ possible conjugates, we get, at most, $|H|-1$ distinct elements,
        and the identity element, in each and thus we obtain:
        \begin{equation}
            n\cdot(|H|-1)+1=n|H|-n+1=n|H|-(n-1)
        \end{equation}
        But by hypothesis, $n\geq{2}$ and thus $n-1>0$, so we get:
        \begin{equation}
            n|H|-(n-1)<n|H|
        \end{equation}
        But $n|H|=|G|$, and thus not every element of $G$ will be in one of the
        conjugacy classes. For the infinite case, consider the free group on
        two elements $a,b$ and consider the subgroup of all elements such that
        the first element and the last element of a given word are not inverses
        of each other. Given a word that is not in this form, say
        $x=ab\cdots{a}^{\minus{1}}$, we may reduce this by conjugation by
        multiplying $a^{\minus{1}}*x*a$. Thus every word can be reduced to this
        form, however this subgroup is not the entirety of $F(a,b)$.
    \section*{Problem 5}
        For a matrix $B$ is invertible if and only if $Bx=0$ has only the zero
        vector as a solution. Suppose $A+I$ is not invertible. Then there is a
        non-zero vector $x\in\mathbb{R}^{n}$ such that $(A+I)x=0$. But then:
        \begin{equation}
            Ax=\minus{x}
        \end{equation}
        But if $Ax=\minus{x}$, then:
        \begin{equation}
            (Ax)^{T}=x^{T}A^{T}=\minus{x}^{T}
        \end{equation}
        But $A$ is skew symmetric, and thus $A^{T}=\minus{A}$. Therefore:
        \begin{equation}
            \minus{x}^{T}A=\minus{x}^{T}
            \Longrightarrow
            x^{T}A=x^{T}
        \end{equation}
        But then:
        \begin{equation}
            x^{T}x=(x^{T}A)x=x^{T}(Ax)=\minus{x}^{T}x
        \end{equation}
        And thus $\norm{x}=\minus\norm{x}$ which implies $\norm{x}=0$. But this
        is true if and only if $x=0$, a contradiction as $x$ is a non-zero
        vector. Thus, $A+I$ is invertible.
    \section*{Problem 6}
\end{document}