\chapter{Metric Spaces}
    \section{Definitions}
        \begin{ldefinition}{Pseudo-Metric}{Pseudo_Metric}
            A pseudo-metric on a set $X$ is a function
            $\rho:X\times{X}\rightarrow[0,\infty)$ such that,
            for all $x,y,z\in{X}$, it is true that:
            \begin{align}
                \rho(x,y)&=\rho(y,x)
                \tag{Symmetry}\\
                \rho(x,z)&\leq\rho(x,y)+\rho(y,z)
                \tag{Triangle Inequality}
            \end{align}
        \end{ldefinition}
        \begin{ldefinition}{Pseudo-Metric Space}
              {Pseudo_Metric_Space}
            A pseudo-metric space, $(X,\rho)$, is a set
            $X$ and a pseudo-metric $\rho$ on $X$.
        \end{ldefinition}
        \begin{theorem}
            There exist pseudo-metric spaces $(X,\rho)$
            such that for all $x\in{X}$, $\rho(x,x)>0$.
        \end{theorem}
        \begin{proof}
            For let $X=\mathbb{R}$ and define
            $\rho:\mathbb{R}^{2}\rightarrow[0,\infty)$ by:
            \begin{equation}
                \rho(x,y)=1+|x|+|y|
            \end{equation}
            Then $\rho$ is a pseudo-metric. For it is symmetric,
            since:
            \begin{equation}
                \rho(x,y)=1+|x|+|y|=1+|y|+|x|=\rho(y,x)
            \end{equation}
            Moreover, it obeys the triangle inequality:
            \begin{subequations}
                \begin{align}
                    \rho(x,z)&=1+|x|+|z|\\
                    &\leq{1}+|x|+|z|+2|y|+1\\
                    &=(1+|x|+|y|)+(1+|y|+|z|)\\
                    &=\rho(x,y)+\rho(y,z)
                \end{align}
                Thus, $\rho$ is a pseudo-metric. However, for
                all $x\in\mathbb{R}$:
                \begin{equation}
                    \rho(x,x)=1+|x|+|x|=1+2|x|\geq{1}>0
                \end{equation}
                Thus, there are no $x\in{X}$ such that
                $\rho(x,x)=0$. Therefore, etc
            \end{subequations}
        \end{proof}
        If we require $\rho(x,x)=0$ for all $x\in{X}$, we
        can still have the case where elements cannot be
        distinguished from. That is, there may be
        $x,y\in{X}$ such that $x\ne{y}$, but
        $\rho(x,y)=0$.
        \begin{theorem}
            There exist pseudo-metric spaces $(X,\rho)$
            such that for all $x\in{X}$, $\rho(x,x)=0$,
            and there are distinct elements $x,y\in{X}$
            such that $\rho(x,y)=0$.
        \end{theorem}
        \begin{proof}
            For let $X$ have at least two distinct elements,
            and let $\rho:X^{2}\rightarrow[0,\infty)$
            be defined by:
            \begin{equation}
                \rho(x,y)=0
            \end{equation}
            Then $\rho$ is a pseudo-metric. Symmetry and
            the triangle inequality are both trivial.
            However, since there are at least two distinct
            elements in $X$, we have unique points such that
            $\rho(x,y)=0$. Therefore, etc.
        \end{proof}
        \begin{ldefinition}{Metric Space}
              {Funct_Analysis_Metric_Space}
            A metric space is a pseudo-metric space $(X,d)$
            such that:
            \begin{equation}
                d(x,y)=0\Longleftrightarrow{x}=y
                \tag{Definiteness}
            \end{equation}
        \end{ldefinition}
        \begin{ldefinition}{Semi-Norm}
              {Funct_Analysis_Semi_Norm}
            A semi-norm on a vector space $V$ over a field
            $\mathbb{F}\subseteq\mathbb{C}$ is a function
            $\norm{\cdot}:V\rightarrow[0,\infty)$ such that, for
            all $v\in{V}$ and $\alpha\in\mathbb{F}$,
            it is true that:
            \begin{align}
                \norm{\alpha{v}}
                &=|\alpha|\norm{v}
                \tag{Homogeneity}\\
                \norm{v+w}
                &\leq\norm{v}+\norm{w}
                \tag{Triangle Inequality}
            \end{align}
        \end{ldefinition}
        \begin{theorem}
            If $V$ is a vector space over a field
            $\mathbb{F}\subseteq\mathbb{C}$, and if
            $\norm{\cdot}$ is semi-norm on $V$, then:
            \begin{equation}
                \norm{\mathbf{0}}=0
            \end{equation}
        \end{theorem}
        \begin{proof}
            For:
            \begin{equation}
                \norm{\mathbf{0}}
                =\norm{0\mathbf{0}}
                =|0|\norm{\mathbf{0}}=0
            \end{equation}
            Therefore, etc.
        \end{proof}
        \begin{ldefinition}{Norm}
              {Funct_Analysis_Norm}
            A norm on a vector space $V$ over a
            field $\mathbb{F}\subseteq\mathbb{C}$
            is a semi-norm $\norm{\cdot}$ such that:
            \begin{equation}
                \norm{\mathbf{x}}\Longrightarrow\mathbf{x}
                =\mathbf{0}
            \end{equation}
        \end{ldefinition}
        \begin{lexample}{}{Semi_Norm}
            Suppose that $\norm{\cdot}_{0}$ is a semi-norm
            on a vector space $V$. Define the following:
            \begin{equation}
                N=\{v\in{V}:\norm{v}_{0}=0\}
            \end{equation}
            If follows from the definition of a semi-norm that
            $N$ is a subspace of $V$. Thus we can define a
            function on the quotient space
            $\norm{\cdot}:V/N\rightarrow[0,\infty)$ by:
            \begin{equation}
                \norm{v+N}=\norm{v}_{0}
            \end{equation}
            We can then verify that this is well defined and
            that $\norm{\cdot}$ is a norm on $V/N$.
        \end{lexample}
        If $\norm{\cdot}$ is a norm on $V$, then we get an
        associated metric $\rho$ via:
        \begin{equation}
            \rho(v,u)=\norm{v-u}
        \end{equation}
        \begin{lexample}
            Let $(X,\mathcal{M},\mu)$ be a measure space.
            That is, $X$ is a set, $\mathcal{M}$ is
            $\sigma\textrm{-Algebra}$, and $\mu$ is a measure
            on $X$. Let $1\leq{p}<\infty$. Then:
            \begin{equation}
                \mathcal{L}^{p}(X)=
                \{f:X\rightarrow\mathbb{C}:
                f\textrm{ is measurable and}
                \int_{X}|f|^{p}\diff{\mu}<\infty.\}
            \end{equation}
            The set $\mathcal{L}^{p}(X)$ is a vector space.
            We define the semi-norm on $\mathcal{L}^{p}(X)$
            to be:
            \begin{equation}
                \norm{f}_{p}=
                \Big(\int_{X}|f|^{p}\diff\mu\Big)^{1/p}
            \end{equation}
            This is not a norm, since there are many
            functions such that $\norm{f}_{p}=0$, yet $f\ne{0}$.
            However, if $\norm{f}_{p}=0$, then $f=0$ $\mu$
            almost-everywhere. So we create equivalence
            classes by s comparing functions that are $\mu$
            almost-everywhere. The final thing to check is
            the triangle-inequality. It is not obvious and is a
            consequence of Minkowski's Inequality. We get
            a normed vector space by considering $N$ to be
            the set of functions $f$ such that $\norm{f}_{p}=0$,
            and we define:
            \begin{equation}
                L^{p}(X)=\mathcal{L}^{p}(X)/N
            \end{equation}
            The analyst Halmos said that the only important
            values of $p$ are 1, 2, and $\infty$. If
            $f:X\rightarrow\mathcal{C}$ is
            measurable, then we define:
            \begin{equation}
                \norm{f}_{\infty}=
                \inf\{c\geq{0}:\mu\Big(\{x:|f(x)|>c\}\big)=0\}
            \end{equation}
            With the convention that $\inf\{\emptyset\}=\infty$.
            This defines a semi-norm on:
            \begin{equation}
                \mathcal{L}^{\infty}(X)
                =\{f:\norm{f}_{\infty}<\infty\}
            \end{equation}
            Homogeneity pops out rather quickly, but the
            triangle-inequality is still tricky. We call
            $\norm{\cdot}_{\infty}$ the essential supremum
            of $f$.
        \end{lexample}
        \begin{theorem}
            If $f:X\rightarrow\mathbb{C}$ is measurable, and if:
            \begin{equation}
                E=\{p:\norm{f}_{p}<\infty,p\in[1,\infty)\}
            \end{equation}
            Then $E$ is connected.
        \end{theorem}
        \begin{lexample}
            Let $X$ be a finite set, let
            $\mathcal{M}=\mathcal{P}(X)$, and let $\mu$ be the
            counting measure on $X$. A function on
            $X$ is an n-tuple $x=(x_{1},\dots,x_{n})$. Then:
            \begin{equation}
                \norm{x}_{p}=
                \begin{cases}
                    \Big(\sum_{k=1}^{n}|x_{k}|^{p}\Big)^{1/p},
                    &1\leq{p}<\infty\\
                    \max\{|x|,x\in{X}\}
                \end{cases}
            \end{equation}
            $\norm{\cdot}_{p}$ is a norm on $X$.
        \end{lexample}
        \begin{lexample}
            Let $X=\mathbb{N}$, the set of natural numbers. Let
            $\mathcal{M}=\mathcal{P}(X)$, and let $\mu$ be
            the counting measure. Then functions are sequences
            $a:\mathbb{N}\rightarrow\mathbb{R}$, or
            $a:\mathbb{N}\rightarrow\mathbb{C}$. Then:
            \begin{equation}
                \norm{x}_{p}=
                \begin{cases}
                    \Big(\sum_{n=1}^{\infty}
                        |x_{n}|^{p}\Big)^{1/p},
                    &1\leq{p}<\infty\\
                    \max\{|x|,x\in{X}\}
                \end{cases}
            \end{equation}
            This defines a norm. Recall that a series is
            absolutely convergent if $\sum|a_{n}|<\infty$.
            Given an absolutely convergent series, the original
            series is also convergent. For this space we use
            the following notation:
            \begin{equation}
                \ell^{p}=
                \{a:\mathbb{R}\rightarrow\mathbb{R}:
                    \sum_{n=1}^{\infty}|a_{n}|^{p}<\infty\}
            \end{equation}
        \end{lexample}
        In general, if $X$ is a set then we can equip $X$
        with the counting measure and then if $f$ is any
        bounded function on $f$, then:
        \begin{equation}
            \norm{f}_{\infty}=\sup\{|f(x):x\in{X}\}
        \end{equation}
        For the space of sequences, we write $\ell^{\infty}(X)$.
        \begin{lexample}
            If $X$ is any set, then we define the following
            metric:
            \begin{equation}
                \rho(x,y)=
                \begin{cases}
                    1,&x\ne{y}\\
                    0,&x=1
                \end{cases}
            \end{equation}
            This is often called the discrete metric. It is
            indeed a metric, and $(X,\rho)$ is a metric space.
        \end{lexample}
        \begin{lexample}
            Let $(X,\rho)$ be a metric space. If $Y\subseteq{X}$
            is a non-empty subset of $X$, we can define a new
            metric on $Y$
            be restricting $\rho$ to $Y\times{Y}$. We call
            this the metric subspace.
        \end{lexample}
        \begin{ldefinition}{Strongly Equivalent Metrics}
              {Funct_Analysis_Strongly_Equivalent_Metrics}
            Strongly equilalent metrics on a set $X$ are metrics
            $\rho_{1}$ and $\rho_{2}$ such that there
            exists $c,d\in\mathbb{R}^{+}$ such that, for
            all $x,y\in{X}$:
            \begin{equation}
                c\rho_{1}(x,y)\leq
                    \rho_{2}(x,y)\leq{d}\rho_{1}(x,y)
            \end{equation}
        \end{ldefinition}
        The definition of strongly equivalent metrics is indeed
        symmetric. For since $c,d\in\mathbb{R}^{+}$,
        $c^{-1}$ and $d^{-1}$ are well defined and positive,
        and thus:
        \begin{equation}
            \frac{1}{d}\rho_{2}(x,y)\leq\rho_{1}(x,y)
            \leq\frac{1}{c}\rho_{1}(x,y)
        \end{equation}
        \begin{theorem}
            If $p,q\in[1,\infty)$, then $\norm{\cdot}_{p}$ and
            $\norm{\cdot}_{q}$ are strongly equivalent.
        \end{theorem}
        \begin{proof}
            It suffices to show that for all
            $p\in[1,\infty)$ there exist
            $c,d\in\mathbb{R}^{+}$ such that:
            \begin{equation}
                c\norm{x}_{p}\leq\norm{x}_{2}\leq{d}\norm{x}_{p}
            \end{equation}
            Also note that:
            \begin{equation}
                \partial{\overline{B}_{1}(\mathbf{0})}=
                \{\mathbf{x}\in\mathbb{R}^{n}:\norm{x}_{2}=1\}
            \end{equation}
            Is a closed and bounded subset of $\mathbb{R}^{n}$.
        \end{proof}
        \begin{lexample}
            Let $(X,\rho)$ be a metric space on $X$ and define:
            \begin{equation}
                d(x,y)=\frac{\rho(x,y)}{1+\rho(x,y)}
            \end{equation}
            Then $(X,d)$ is a metric space. Definiteness
            and symmetry come rather immediately from the
            definition and the fact that $\rho$ is a metric.
            The only thing to check is the
            triangle inequality.
        \end{lexample}
        \begin{ldefinition}{Open Ball in a Metric Space}
              {Funct_Analysis_Open_Ball}
            The open ball about a point $x$ in a metric space
            $(X,\rho)$ of radius $r\in\mathbb{R}$ is the set:
            \begin{equation}
                B_{r}(x)=\{y\in{X}:\rho(x,y)<r\}
            \end{equation}
        \end{ldefinition}
        \begin{ldefinition}{Open Subsets of a Metric Space}
              {Funct_Analysis_Open_in_Metric_Space}
            An open subset of a metric space $(X,\rho)$ is a set
            $\mathcal{U}\subseteq{X}$ such that for all
            $x\in\mathcal{U}$ there is an $\varepsilon>0$
            such that:
            \begin{equation}
                B_{\varepsilon}(x)\subseteq\mathcal{U}
            \end{equation}
        \end{ldefinition}
        \begin{theorem}
            Open balls are open.
        \end{theorem}
        \begin{ldefinition}{Neighborhoods}
              {Funct_Analysis_Neighborhoods}
            A neighborhood of a point $x$ in a metric space
            $(X,\rho)$ is a subset $D\subseteq{X}$ such
            that there is an open subset
            $\mathcal{U}\subseteq{D}$ such that
            $x\in\mathcal{U}$.
        \end{ldefinition}
        \begin{theorem}
            IF $(X,\rho)$ is a metric space, then $X$ is
            an open subset.
        \end{theorem}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, then
            $\emptyset$ is an open subset.
        \end{theorem}
        \begin{theorem}
            If $\mathcal{U}_{I}$ is a collection of open subsets
            of a metric space $(X,\rho)$, and if
            $\mathcal{U}$ is defined by:
            \begin{equation}
                \mathcal{U}=\bigcup_{i\in{I}}\mathcal{U}_{i}
            \end{equation}
            Then $\mathcal{U}$ is an open subset.
        \end{theorem}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, and if
            $\mathcal{U}$ and $\mathcal{V}$ are open
            subsets, then the set $\mathcal{D}$ defined by:
            \begin{equation}
                \mathcal{D}=\mathcal{U}\cap\mathcal{V}
            \end{equation}
            Is an open subset of $X$.
        \end{theorem}
        \begin{theorem}
            If $(X,\rho)$ is a metric space and
            $(\mathcal{E},\rho_{\mathcal{E}})$ is a subspace
            of $(X,\rho)$, then a set
            $\mathcal{U}\subseteq\mathcal{E}$
            is open in $\mathcal{E}$ if and only if there is
            an open set $\mathcal{U}$ in $X$ such that:
            \begin{equation}
                \mathcal{V}=\mathcal{U}\cap\mathcal{E}
            \end{equation}
        \end{theorem}
        \begin{ldefinition}{Topology}
              {Funct_Analysis_Topology}
            A topology on a set $X$ is a subset
            $\tau\subseteq\mathcal{P}(X)$ such that:
            $\emptyset\in\tau$ and $X\in\tau$, for any finite
            subset $\mathcal{C}\subseteq\tau$, it is true that:
            \begin{subequations}
                \begin{equation}
                    \bigcap_{C\in\mathcal{C}}C\in\tau
                \end{equation}
                And for any subset $\mathcal{O}\subseteq\tau$
                it is true that:
                \begin{equation}
                    \bigcup_{\mathcal{U}\in\mathcal{O}}
                    \mathcal{U}\in\tau
                \end{equation}
            \end{subequations}
            That is, $\tau$ is closed to finite intersections
            and arbitrary unions.
        \end{ldefinition}
        \begin{lexample}
            If $(X,\rho)$ is a metric space, then the set:
            \begin{equation}
                \tau=\{\mathcal{U}\subseteq{X}:
                    \mathcal{U}\textrm{ is open}\}
            \end{equation}
            is a topology on $X$. This is the \textit{metric}
            topology. Not every topological space can be
            formed from a metric space. If
            $(\mathcal{E},\rho_{\mathcal{E}})$ is a subspace
            of $(X,\rho)$, then the \textit{subspace topology},
            or the relative topology, is the set:
            \begin{equation}
                \tau_{\mathcal{E}}
                =\{\mathcal{E}\cap\mathcal{U}:
                    \mathcal{U}\in\tau\}
            \end{equation}
            This is a topology on $\mathcal{E}$.
        \end{lexample}
        \begin{ldefinition}{Closed Subsets}
              {Funct_Analysis_Closed_in_Metric}
            A closed subset of a metric space $(X,\rho)$
            is a set $\mathcal{C}\subseteq{X}$ such that
            $X\setminus\mathcal{C}$ is an open subset of $X$.
        \end{ldefinition}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, then $X$ is closed.
        \end{theorem}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, then
            $\emptyset$ is closed.
        \end{theorem}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, and if
            $\mathcal{C}_{i}$ is a finite collection of
            closed subsets, then the set
            $\mathcal{C}$ defined by:
            \begin{equation}
                \mathcal{C}=\cup_{i=1}^{n}\mathcal{C}_{i}
            \end{equation}
            is a closed subset of $X$.
        \end{theorem}
        \begin{ldefinition}{Closure of a Set}
              {Funct_Analysis_Closure_in_Metric}
            If $(X,\rho)$ is a metric space and
            $\mathcal{E}\subseteq{X}$, then the closure
            of $\mathcal{E}$ is the set:
            \begin{equation}
                \overline{\mathcal{E}}=
                \bigcap\{\mathcal{F}\subseteq{X}:
                    \mathcal{E}\subseteq\mathcal{F}
                    \land\mathcal{F}\textrm{ is closed.}\}
            \end{equation}
        \end{ldefinition}
        The closure of a set $\mathcal{E}$ is the
        smallest closed set that contains $\mathcal{E}$.
        \begin{theorem}
            If $(X,\rho)$ is a metric space, and if
            $\mathcal{E}$ is a non-empty subset of $X$, then
            $x\in\overline{\mathcal{E}}$ if and only if for
            all $\varepsilon>0$:
            \begin{equation}
                B_{\varepsilon}(x)\cap\mathcal{E}\ne\emptyset
            \end{equation}
        \end{theorem}
        \begin{ldefinition}
              {Convergent Sequences in a Metric Space}
              {Funct_Analysis_Convergent_Seq_in_Metric}
            A convergent sequence in a metric space
            $(X,\rho)$ is a sequence
            $a:\mathbb{N}\rightarrow{X}$ such that there is
            an $x\in{X}$ such that for all $\varepsilon>0$
            there exists an $N\in\mathbb{N}$ such that, for
            all $n\in\mathbb{N}$ and $n>N$, it is true that
            $d(x,a_{n})<\varepsilon$. We write
            $a_{n}\rightarrow{x}$.
        \end{ldefinition}
        \begin{ldefinition}{Limits of Convergent Sequences}
              {Funct_Analysis_Limit_of_Conv_Seq_in_Metric}
            A limit of a convergent sequence
            $a:\mathbb{N}\rightarrow{X}$ in a metric space
            $(X,\rho)$ is a point $x\in{X}$ such that
            $a_{n}\rightarrow{x}$.
        \end{ldefinition}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, if
            $a:\mathbb{N}\rightarrow{X}$ is a convergent
            sequence, and if $x$ and $y$ are limits of $a$,
            then $x=y$.
        \end{theorem}
        \begin{ldefinition}{Equivalent Metrics}
              {Funct_Analysis_Equivalent_Metric}
            Equivalent metrics on a set $X$ and metrics
            $\rho$ and $d$ such that they generate the
            same topology.
        \end{ldefinition}
        \begin{theorem}
            If $X$ is a set and if $\rho$ and $d$ are
            equivalent metrics on $X$, then for all $x\in{X}$
            and for all $r\in\mathbb{R}^{+}$ there exists
            $r_{1},r_{2}\in\mathbb{R}^{+}$ such that:
            \begin{align}
                B_{r_{1}}^{\rho}(x)&\subseteq{B}_{r}^{d}(x)\\
                B_{r_{2}}^{d}(x)&\subseteq{B}_{r}^{\rho}(x)
            \end{align}
        \end{theorem}
        \begin{lexample}
            If $(X,\rho)$ is a metric space and if $d$
            is defined by:
            \begin{equation}
                d(x,y)=\frac{\rho(x,y)}{1+\rho(x,y)}
            \end{equation}
            The $d$ is a metric on $X$. Moreover, $d$
            is equivalent to $\rho$. This shows that the
            notion of boundedness is not a topological one,
            but a metric property. For, given any metric
            $\rho$, $d$ is bounded. For all $x,y\in{X}$,
            $0\leq{d}(x,y)<1$. Letting $\rho$ be the
            standard metric on $\mathbb{R}$,
            $\rho(x,y)=|x-y|$, we see that the topology
            generated by this unbounded metric is equivalent
            to the topology generated by the metric:
            \begin{equation}
                d(x,y)=\frac{|x-y|}{1+|x-y|}
            \end{equation}
        \end{lexample}
        \begin{theorem}
            If $(X,\rho)$ is a metric space, and if
            $d:X^{2}\rightarrow[0,\infty)$ is defined by:
            \begin{equation}
                d(x,y)=\frac{\rho(x,y)}{1+\rho(x,y)}
            \end{equation}
            Then $\rho$ and $d$ are equivalent.
        \end{theorem}
        \begin{proof}
            For let $r>0$. For all $x,y\in{X}$,
            $d(x,y)\leq\rho(x,y)$, and therefore:
            \begin{equation}
                B_{r}^{\rho}(x)\subseteq{B}_{r}^{d}(x)
            \end{equation}
            If $\rho(x,y)\leq{1}$, then
            $\rho(x,y)\leq{2}d(x,y)$. Let
            $r_{1}=\min\{r/2,1\}$, then:
            \begin{equation}
                B_{r/2}^{d}(x)\subseteq{B}_{r}^{\rho}(x)
            \end{equation}
            Therefore, etc.
        \end{proof}
        \begin{ldefinition}
              {Continuous Functions Between Metric Spaces}
              {Funct_Analysis_Cont_Func_Metric}
            A continuous function from a metric space
            $(X,\rho)$ to a metric space $(Y,d)$ is a function
            $f:X\rightarrow{Y}$ such that, for all $x\in{X}$
            and for all $\varepsilon>0$, there is a
            $\delta>0$ such that:
            \begin{equation}
                f\big(B_{\delta}^{\rho}(x)\big)\subset
                B_{\varepsilon}^{d}\big(f(x)\big)
            \end{equation}
        \end{ldefinition}
        \begin{theorem}
            If $(X,\rho)$ and $(Y,d)$ are metric spaces, and
            if $f:X\rightarrow{Y}$ is a function, then
            the following are equivalent:
            \begin{enumerate}
                \item $f$ is continuous at $x_{0}\in{X}$.
                \item If $x_{n}\rightarrow{x_{0}}$ then
                      $f(x_{n})\rightarrow{f}(x_{0})$
                \item If $\mathcal{V}$ is a neighborhood of $f(x_{0})$,
                      then $f^{-1}(\mathcal{V})$ is a neighborhodd of
                      $x_{0}$.
            \end{enumerate}
        \end{theorem}
        \begin{theorem}
            If $(X,\rho)$ and $(Y,d)$ are metric spaces, and if
            $f:X\rightarrow{Y}$ is a function that is
            continuous at $x_{0}\in{X}$, then for
            all $\mathcal{V}\subseteq{Y}$ such that
            $\mathcal{V}$ is open and $f(x_{0})\in\mathcal{V}$,
            then $f^{-1}(\mathcal{V})$ is an open subset
            of $x_{0}$.
        \end{theorem}
        \begin{ldefinition}{Uniformly Continuous Functions}
              {Funct_Analysis_Uni_Cont_Func_Metric}
            A uniformly continuous function from a metric space
            $(X,\rho)$ to a metric space $(Y,d)$ if a function
            $f:X\rightarrow{Y}$ such that for all
            $\varepsilon>0$ there exists a $\delta>0$ such
            that, for all $x,y\in{X}$ such that
            $\rho(x,y)<\delta$, it is true that
            $d(f(x),f(y))<\varepsilon$.
        \end{ldefinition}
        \begin{theorem}
            If $f:X\rightarrow{Y}$ is uniformly continuous,
            then $f$ is continuous.
        \end{theorem}
        The converse is false. For define $f(x)=x^{2}$.
        Functional analysis is concerned with normed spaces.
        This is a vector space $V$ with a function, called
        a norm, from $V$ to $[0,\infty)$. This is usually
        written $\norm{\mathbf{x}}$ for an element
        $\mathbf{x}\in{V}$. This norm must satisfy the
        folllowing for all $\mathbf{x}$, $\mathbf{y}\in{V}$:
        \begin{enumerate}
            \item $\norm{\mathbf{x}}=0$ if and only
                  if $\mathbf{x}=\mathbf{0}$
                  \hfill[Definiteness]
            \item $\norm{c\mathbf{x}}=|c|\norm{\mathbf{x}}$
                  for all $c\in\mathbb{R}$.
                  \hfill[Positiveness]
            \item $\norm{\mathbf{x}+\mathbf{y}}%
                   \leq\norm{\mathbf{x}}+\norm{\mathbf{y}}$
                  \hfill[Triangle Inequality]
        \end{enumerate}
        \begin{example}
            $\mathbb{R}$ with $\norm{x}=|x|$ and
            $\mathbb{R}^{n}$ with $\norm{\mathbf{x}}_{2}$
            defined by:
            \begin{equation*}
                \norm{\mathbf{x}}_{2}
                =\sqrt{\sum_{k=1}^{n}x_{k}^{2}}
            \end{equation*}
            are some of the most commonly used normed spaces.
            $\mathbb{R}^{n}$ can be thought of a the set
            of vectors in $n$ dimensions and the norm
            $\norm{\mathbf{x}}_{2}$ can be thought of as
            the length of $\mathbf{x}$ using the
            Pythagorean Theorem. There are other norms one
            can define on $\mathbb{R}^{n}$. A common
            one is the $p$ norm, defined by:
            \begin{equation*}
                \norm{\mathbf{x}}_{p}
                =\Big(\sum_{k=1}^{n}x_{k}^{p}\Big)^{1/p}
            \end{equation*}
            Together, $(\mathbb{R}^{n},\norm{}_{p})$ defines
            a normed space for all $p\geq{1}$. Another type
            of norm on $\mathbb{R}^{n}$ is the
            $p\textrm{-adic}$ norm.
        \end{example}
        A common family of sets,
        which we will deal with frequently, are the
        $\ell^{p}$ spaces.
        \begin{definition}
            $\ell^{p}$ is the set of all sequences
            $x:\mathbb{R}\rightarrow\mathbb{R}$ such that
            the sequence of partial sums
            $S:\mathbb{N}\rightarrow\mathbb{R}$ defined by
            $S_{N}=\sum_{n=1}^{N}|x_{n}|^{p}$ is bounded.
        \end{definition}
        \begin{definition}
            The $p$ norm on $\ell^{q}$ is the function
            $\norm{}_{p}:\ell^{q}\rightarrow\mathbb{R}$
            defined by:
            \begin{equation*}
                \norm{x}_{p}
                =\Big(\sum_{k=1}^{\infty}x_{k}^{p}\Big)^{1/p}
            \end{equation*}
        \end{definition}
        \begin{theorem}
            If $p\geq{1}$, then $(\ell^{p},\norm{}_{p})$
            is a normed space.
        \end{theorem}
        \begin{definition}
            The supremum norm on $\mathbb{R}^{n}$,
            $\norm{}_{\infty}:%
             \mathbb{R}^{n}\rightarrow\mathbb{R}$,
            is the function:
            \begin{equation*}
                \norm{\mathbf{x}}_{\infty}
                =\max\{|x_{1}|,\hdots,|x_{n}|\}
            \end{equation*}
        \end{definition}
        \begin{theorem}
            If $n\in\mathbb{N}$, then
            $(\mathbb{R}^{n},\norm{}_{\infty})$ is a
            normed space.
        \end{theorem}
        \begin{definition}
            $\ell^{\infty}$ is the set of sequences
            $x:\mathbb{N}\rightarrow\mathbb{R}$ such that
            $x$ is bounded.
        \end{definition}
        \begin{definition}
            The supremum norm on $\ell^{\infty}$
            is the function
            $\norm{}_{\infty}:%
             \ell^{\infty}\rightarrow\mathbb{R}$
            defined by:
            \begin{equation*}
                \norm{x}_{\infty}
                =\sup\{|x_{n}|:n\in\mathbb{N}\}
            \end{equation*}
        \end{definition}
        \begin{theorem}
            If $\norm{}_{\infty}$ is the
            supremum norm on $\ell^{\infty}$, then
            $(\ell^{\infty},\norm{}_{\infty})$
            is a normed space.
        \end{theorem}
        From the fact that $\ell^{\infty}$ is a normed space
        we have that the set of convergent sequences,
        again with the $\norm{}_{\infty}$ norm, is also
        a normed space. The set of null sequences, which
        is the set of sequences that converge to zero,
        is also a normed space.
        A stranger normed space
        is the set of all bounded continuous functions
        $f:S\rightarrow\infty$ with norm
        $\norm{f}=\sup\{|f(x)|\}$. Furthermore, the
        set of all integrable functions with
        bounded integrals, with norm
        $(\int_{S}|f|^{p})^{1/p}$. If you allow integral
        to mean Lebesgue Integrable, then this becomes
        a special space denoted $L^{p}(S)$.
        \begin{definition}
            The Sobolev Space, denoted $W^{n,p}([a,b])$
            is the set of functions
            $f:[a,b]\rightarrow\mathbb{R}$ such that:
            \begin{equation*}
                \int_{a}^{b}\sum_{k=0}^{n}
                |f^{(k)}(x)|^{p}\diff{x}<\infty
            \end{equation*}
        \end{definition}
        \begin{definition}
            The $p$ norm on the Sobolev space
            $W^{n,q}([a,b])$ is the function
            $\norm{}_{p}:W^{n,q}([a,b])\rightarrow\mathbb{R}$
            defined by:
            \begin{equation*}
                \Big(\int_{a}^{b}\sum_{k=0}^{n}
                |f^{(k)}(x)|^{p}\diff{x}\Big)^{1/p}
            \end{equation*}
        \end{definition}
        \begin{theorem}
            If $p\geq{1}$, then
            $(W^{n,p}([a,b]),\norm{}_{p})$ is a
            normed space.
        \end{theorem}
        A lot of the things we wish to
        prove don't rely on the fact that all of these
        spaces are vector spaces. Really, we only care about
        the properties that the norm on the space has.
        What matters is that there's a set and a notion
        of distance on the set. This abstraction is the
        fundamental concept of a metric space.
        \begin{definition}
            A metric space is a set $S$ and a function
            $d:{X}\times{X}\rightarrow[0,\infty)$ such that:
            \begin{enumerate}
                \item For all $x$, $y\in{X}$, $d(x,y)=0$
                      if and only if $x=y$.
                      \hfill[Definitenes]
                \item For all $x$, $y\in{X}$,
                      $d(x,y)=d(y,x)$
                      \hfill[Symmetry]
                \item For all $x$, $y\in{X}$,
                      $d(x,z)\leq{d(x,y)+d(y,z)}$
                      \hfill[Triangile Inequality]
            \end{enumerate}
        \end{definition}
        It turns out
        that we can actually write the following:
        \begin{definition}
            A metric space is a set $X$ and a function
            $d:{X}\times{X}\rightarrow\mathbb{R}$
            such that:
            \begin{enumerate}
                \item $d(x,y)=0$ if and only if
                      $x=y$.
                \item $d(x,z)\leq{d(x,y)+d(z,y)}$
            \end{enumerate}
        \end{definition}
        By writing the triangle inequality in this
        way, symmetry comes for free
        (The fact that $d(x,y)=d(y,x)$), as well
        as positivity (The fact that $d(x,y)\geq{0}$).
        Since it's easier to prove two things are
        true, rather than four things, it's nice to
        take this as the definition of a metric space,
        and then prove that the two definitions are
        equivalent.
        In a metric space $(X,d)$, $d$ is often called the
        \textit{distance function} or
        \textit{metric function}. It is meant to be an
        abstract mimicry of the absolute value function
        that is used with real numbers. Definiteness
        says the only point that is zero meters from a
        point $x$ is $x$ itself. Symmetry says the distance
        walking from $x$ to $y$ is the same as the distance
        walking from $y$ to $x$. The last rule stems from
        Euclidean geometry. It says walking from $x$ to $z$
        is shorter than (or equal to) walking from
        $x$ to $y$ and then $y$ to $z$. In Euclidean
        geometry equality is achieved only when
        $y$ lies between $x$ and $z$. In
        abstract metric spaces there may be no such
        thing as a \textit{line} between two points,
        so we need to be careful.
        \begin{example}
            $\mathbb{R}^{n}$ (for $1\leq{p}<\infty$):
            \begin{equation*}
                d_{p}(\mathbf{x},\mathbf{y})=
                \big(
                    \sum_{k=1}^{n}|x_{k}-y_{k}|
                \big)^{1/p}
                =\norm{\mathbf{x}-\mathbf{y}}_{p}
            \end{equation*}
        \end{example}
        \begin{example}
            In $\ell^{p}$, which are sequences for
            which
            $\sum_{k=1}^{\infty}|x_{k}|^{p}<\infty$,
            $d_{p}(x,y)$ forms a metric, as well
            as
            $d_{\infty}(x,y)=\sup\{|x_{k}-y_{k}|\}$,
            which is called the supremum norm.
        \end{example}
        \begin{example}
            $C(S,\mathbb{R})$, which is the
            set of continuous functions from
            $S$ to $\mathbb{R}$, letting
            $L^{p}(S)$ be the set of of functions
            such that:
            \begin{equation*}
                \int_{S}|x(t)|^{p}<\infty
            \end{equation*}
            Then the following is a metric:
            \begin{equation*}
                d_{p}(x,y)=
                \bigg(
                    \int_{S}|x(t)-y(t)|^{p}dt
                \bigg)^{1/p}
            \end{equation*}
            Also,
            $d_{\infty}(x,y)=\sup\{|x(t)-y(t)|\}$,
            which is called the supremum norm.
        \end{example}
        \begin{example}
            Let $C$ be the set of sequences such that
            $x_{n}\rightarrow{0}$. Then, with
            $d_{p}$, this forms a metric space.
            If $C_{0}$ is set of sequences with
            only finitely many non-zero terms,
            then
            $C_{0}\subset{C}\subset{\ell^{\infty}}$.
            Is there a sequence $x\in{C}$ such
            that, for all $1\leq{p}<\infty$,
            $x\notin{\ell^{p}}$.
        \end{example}
        Since the image of the metric function
        lies in $\mathbb{R}$,
        we may speak of \textit{convergence}
        in metric spaces.
        \begin{definition}
            A convergent sequence in a metric space
            $(X,d)$ is a sequence
            $x:\mathbb{N}\rightarrow{X}$ such that there
            is an $a\in{X}$ such that
            $d(a,x_{n})\rightarrow{0}$.
        \end{definition}
        \begin{definition}
            A limit of a sequence
            $x$ in a metric space $(X,d)$ is an
            $a\in{X}$ such that
            $d(x_{n},a)\rightarrow{0}$.
        \end{definition}
        Much like convergence in real numbers, limits
        in metric spaces are unique.
        \begin{theorem}
            \label{thm:Funct:Limit_of_Metric_Sequence_Unique}
            If $(X,d)$ is a metric space,
            $x:\mathbb{N}\rightarrow{X}$
            is a convergence sequence in $X$,
            and if $a$ and $b$ are limits of $x$,
            then $a=b$.
        \end{theorem}
        \begin{proof}
            For suppose not. As
            $(X,d)$ is a metric space, $d(a,b)>0$.
            Let $\varepsilon=\frac{d(a,b)}{4}$.
            Then, as $d(a,x_{n})\rightarrow{0}$
            and $\varepsilon>0$, there is an
            $N_{1}\in\mathbb{N}$ such that, for all
            $n>N_{1}$, $d(a,x_{n})<\varepsilon$. But,
            as $d(b,x_{n})\rightarrow{0}$ and
            $\varepsilon>0$, there is an $N_{2}$ such
            that, for all $n>N_{2}$,
            $d(b,x_{n})<\varepsilon$.
            Let $n=\max\{N_{1},N_{2}\}+1$.
            But then:
            \begin{equation*}
                d(a,b)\leq{d(a,x_{n})+d(b,x_{n})}
                <2\varepsilon=\frac{d(a,b)}{2}
            \end{equation*}
            A contradiction. Therefore, $a$ is unique.
        \end{proof}
        \begin{theorem}
            If $(X,d)$ be a metric space and if
            $x$, $y$, $z\in{X}$, then
            $|d(x,z)-d(y,z)|\leq{d(x,y)}$
        \end{theorem}
        \begin{proof}
            Suppose $d(x,z)\geq{d(y,z)}$.
            If $d(x,z)<d(y,z)$, the proof is
            symmetric. Thus we have:
            \begin{equation*}
                |d(x,z)-d(y,z)|
                =d(x,z)-d(y,z)
                \leq{(d(x,y)+d(y,z))-d(y,z)}
                =d(x,y)
            \end{equation*}
            Therefore,
            $|d(x,z)-d(y,z)|\leq{d(x,y)}$.
        \end{proof}
        \begin{theorem}
            If $(X,d)$ is a metric space
            and $x_{n}\rightarrow{a}$, then
            for all $b\in{X}$,
            $d(x_{n},b)\rightarrow{d(a,b)}$.
        \end{theorem}
        \begin{proof}
            For
            $|d(x_{n},b)-d(a,b)|\leq{d(x_{n},a)}%
             \rightarrow{0}$.
        \end{proof}
        \begin{theorem}
            If $(V,\norm{})$ is a normed space
            and if $d:{V}\times{V}\rightarrow[0,\infty)$
            is defined by
            $d(\mathbf{x},\mathbf{y})%
             =\norm{\mathbf{x}-\mathbf{y}}$,
            then $(V,d)$ is a metric space.
        \end{theorem}
        \begin{proof}
            In order:
            \begin{enumerate}
                \item If $\norm{\mathbf{x}-\mathbf{y}}=0$,
                      then $\mathbf{x}=\mathbf{y}$.
                      Similarly,
                      $\norm{\mathbf{x}-\mathbf{x}}%
                       =\norm{\mathbf{0}}=0$.
                \item $d(\mathbf{x},\mathbf{y})%
                       =\norm{\mathbf{x}-\mathbf{y}}%
                       =\norm{(-1)(\mathbf{y}-\mathbf{x})}%
                       =|-1|\norm{\mathbf{y}-\mathbf{x}}%
                       =\norm{\mathbf{y}-\mathbf{y}}%
                       =d(y,x)$
                \item The triangle inequality follows
                      from the triangle inequality that
                      norms have.
            \end{enumerate}
        \end{proof}
        There are metric spaces that have nothing to do
        with vector spaces or norms. Metric spaces are
        a more abstract object. Every normed space
        has an associated metric space since there
        is the ``induced'' metric.
        \begin{example}
            Let $X$ be a set and let
            $d(x,y)=\begin{cases}%
                        0,&x=y\\%
                        1,&{x}\ne{y}%
                    \end{cases}$
            This is the discrete metric on $X$.
        \end{example}
        \begin{example}
            Let $X=\{a,b,c\}$, and
            $d(a,b)=1$, $d(b,c)=2$. What value
            must $d(a,c)$ have if $d$ is a metric on $X$?
            Consider the following table:
            \begin{table}[H]
                \captionsetup{type=table}
                \centering
                \begin{tabular}{|c|c|c|c|}
                    \hline
                    $X$&a&b&c\\
                    \hline
                    a&0&1&?\\
                    \hline
                    b&1&0&2\\
                    \hline
                    c&?&2&0\\
                    \hline
                \end{tabular}
            \end{table}
            This obeys everything except the triangle
            inequality. We must pick $d(a,c)$
            such that this is upheld.
            So we need the following:
            \begin{align*}
                d(a,b)&\leq{d(a,c)+d(c,b)}&
                d(a,c)&\leq{d(a,b)+d(b,c)}&
                d(b,c)&\leq{d(b,a)+d(a,c)}\\
                \Rightarrow{1}&\leq{2+d(a,c)}&
                \Rightarrow{d(a,c)}&\leq{3}&
                \Rightarrow{2}&\leq{1+d(a,c)}
            \end{align*}
            So we need $1\leq{d(a,c)}\leq{3}$.
            Pick $d(a,c)=2$.
            This makes $(X,d)$ a metric space.
        \end{example}
        \begin{example}
            Let $X=\mathbb{R}$ and $d(x,y)=|x-y|$.
            Then $(X,d)$ is a metric space.
        \end{example}
        \begin{example}
            $\mathbb{R}$ with
            $d(x,y)=|f(x)-f(y)|$, where
            $f:\mathbb{R}\rightarrow\mathbb{R}$
            is injective, is a metric space.
            Let $f$ be a real-valued function. Then
            from the triangle inequality
            \begin{equation*}
                |f(x)-f(y)|\leq|f(x)-f(z)|+|f(z)-f(y)|
            \end{equation*}
            Therefore $d$ obeys the triangle inequality.
            It also obeys symmetry, for:
            \begin{equation*}
                |f(x)-f(y)|=|(-1)(f(y)-f(x))|=|f(y)-f(x)|
            \end{equation*}
            The absolute value function is doing
            most of the work.
            But finally we require that
            $|f(x)-f(y)|=0$ if and only if
            $x=y$. But $|f(x)-f(y)|=0$ if and only
            if $f(x)=f(y)$. So we require that $f$
            is injective. If $f$ is not injective,
            then there exists $x_{1}$, $x_{2}$
            such that
            $x_{1}\ne{x_{2}}$ and yet
            $f(x_{1})=f(x_{2})$. But then
            $|f(x_{1})-f(x_{2})|=0$, contradicting the
            fact that this is a metric. If $f$ is
            injective, then this is a metric. Note
            injective functions need not be
            continuous, and can be very crazy.
        \end{example}
        \begin{example}
            $\mathbb{R}$ with
            $d(x,y)=|\tan^{-1}(x)-\tan^{-1}(y)|$ is a
            metric. Moreover, $d(x,y)<\pi$ for all
            $x,y\in\mathbb{R}$. Thus, we have found
            a metric that makes $\mathbb{R}$ a bounded
            set. As a fun fact, $x_{n}=n$ is a Cauchy
            sequence in this metric space, but
            this sequence does not converge to anything.
            Thus we've found a metric on
            $\mathbb{R}$ such that
            $(\mathbb{R},d)$ is not complete.
        \end{example}
        \begin{example}
        Can $d(x,y)=f(x-y)$ be a metric on $\mathbb{R}$
        if $f$ is differentiable? Not everywhere.
        $f$ can not be differentiable at the origin for
        $d(x,y)=f(x-y)$ to be a metric function, however
        $f$ can be differentiable everywhere else. Use
        $f(x)=|x|$ as an example.
        If $f(x-y)$ is a metric, $f$
        must be an even function. But
        then $f'(0)=0$. But $f(x-y)$ also must obey
        the triangle inequality. Therefore:
        \begin{equation*}
            f(2x)\leq{f(x)+f(x)}=2f(x)
        \end{equation*}
        Define $h(x)$ by:
        \begin{equation*}
            h(x)=
            \left\{
                \begin{array}{cr}
                \frac{f(x)}{x},&x\ne{0}\\
                0,&x=0
                \end{array}\right.
        \end{equation*}
        Then, from
        the previous statement, $h(2x)\leq{h(x)}$.
        But then:
        \begin{equation*}
            h\Big(\frac{1}{2^{n}}\Big)\leq
            h\Big(\frac{1}{2^{n+1}}\Big)
        \end{equation*}
        But from L'H\^{o}pital's Rule,
        $h(x)\rightarrow{f'(0)}$ as $x\rightarrow{0}$.
        Therefore $h(1)\leq{f'(0)}$. But $h(1)>0$ since
        $f(x-y)$ is a metric, a contradiction.
        Therefore, $f$ can not be differentiable at
        the origin.
        \end{example}
        \subsection{Completeness}
            \begin{ldefinition}{Cauchy Sequences}
                  {Funct_Analysis_Cauchy_Seq_Metric}
                A Cauchy sequence in a metric space $(X,d)$ is a
                sequence $a:\mathbb{N}\rightarrow{X}$ such that,
                for all $\varepsilon>0$ there is an
                $N\in\mathbb{N}$ such that, for all
                $n,m\in\mathbb{N}$ such that $n,m>N$,
                it is true that $d(x_{n},x_{m})<\varepsilon$.
            \end{ldefinition}
            \begin{lexample}
                Let $X=(0,2)$ with the usual metric, and let
                $a:\mathbb{N}\rightarrow{X}$ be defined by:
                \begin{equation}
                    a_{n}=\frac{1}{n}
                \end{equation}
                Then $a$ is a Cauchy sequence since:
                \begin{equation}
                    |a_{n}-a_{m}|=\frac{|n-m|}{nm}
                    <\frac{2}{\min(n,m)}
                \end{equation}
                And this converges to zero. However the sequence
                doesn't converge, since we took zero away.
            \end{lexample}
            \begin{lexample}
                Let $X=C([0,3])$ and let:
                \begin{equation}
                    \norm{f}_{1}=\int_{0}^{3}|f(x)|\diff{x}
                \end{equation}
                Then $\norm{\cdot}_{1}$ is a norm on the set of
                continuous functions, and thus induces a metric.
                Let $f_{n}$ be defined by:
                \begin{equation}
                    f_{n}(x)=
                    \begin{cases}
                        1,&x\leq{x}<2-\frac{1}{n}\\
                        Bob,\\
                        0,&x\geq{2}
                    \end{cases}
                \end{equation}
                Then $f_{n}$ is Cauchy, but does not converge.
            \end{lexample}
            \begin{ldefinition}{Complete Metric Spaces}
                  {Funct_Analysis_Complete_Metric_Space}
                A complete metric space is a metric space
                $(X,d)$ such that, for all Cauchy sequences
                $a:\mathbb{N}\rightarrow{X}$, $a$ is a convergent
                sequence.
            \end{ldefinition}
            \begin{theorem}
                If $(X,d)$ is a metric space, if
                $a:\mathbb{N}\rightarrow{X}$ is a Cauchy
                sequence, and if there is a convergent subseqence
                of $a$, then $a$ is a convergent sequence.
            \end{theorem}
            \begin{theorem}
                A normed vector space $(V,\norm{\cdot})$ is
                complete if and only if every absolutely
                convergent series converges.
            \end{theorem}
            \begin{proof}
                Suppose $V$ is complete and let $u_{n}$
                be absolutely convergent. That is, the sequence
                of partial sums:
                \begin{equation}
                    S_{N}=\sum_{n=1}^{N}\norm{u_{n}}
                \end{equation}
                Converges in $\mathbb{R}$. But then:
                \begin{equation}
                    \underset{N\rightarrow\infty}{\lim}
                    \sum_{k=N}^{\infty}\norm{u_{k}}=0
                \end{equation}
                Define:
                \begin{equation}
                    s_{n}=\sum_{k=1}^{n}u_{k}
                \end{equation}
                But if $m\geq{n}$, then:
                \begin{equation}
                    \norm{s_{n}-s_{m}}
                    \leq\sum_{k=n+1}^{m}\norm{u_{k}}
                    \leq\sum_{k=n+1}^{\infty}\norm{u_{k}}
                \end{equation}
                Thus, if $\varepsilon>0$ there is an $N\in\mathbb{N}$
                such that, for all $n\geq{N}$, it is true that:
                \begin{equation}
                    \sum_{k=n+1}^{\infty}\norm{u_{k}}<\varepsilon
                \end{equation}
                Therefore $s_{n}$ is a Cauchy sequence, and therefore
                there is an $s\in{V}$ such that $s_{n}\rightarrow{s}$.
                Proving the converse, suppose $u_{n}$ is a Cauchy
                sequence. Then there is an $N_{1}\in\mathbb{N}$ such
                that, for all $n,m\geq{N}_{1}$, we have
                $\norm{u_{n}-u_{m}}<1/2$. But then there is also an
                $N_{2}\in\mathbb{N}$ such that $N_{2}>N_{1}$, and for
                all $n,m>N_{2}$, $\norm{u_{n}-u_{m}}$. Continuing
                inductively, we find a sequence $u_{n_{k}}$ such that:
                \begin{equation}
                    \norm{u_{n_{k+1}}-u_{n_{k}}}<\frac{1}{2^{k}}
                \end{equation}
                Let $v_{k}=u_{n_{k+1}}-u_{n_{k}}$, and note that:
                \begin{equation}
                    \sum_{n=1}^{\infty}\norm{v_{n}}<\infty
                \end{equation}
                But then there is a $v\in{V}$ such that:
                \begin{equation}
                    \sum_{n=1}^{\infty}v_{n}=v
                \end{equation}
                But:
                \begin{align}
                    v&=\underset{N\rightarrow\infty}{\lim}
                        \sum_{k=1}^{N}v_{k}\\
                    &=\underset{N\rightarrow\infty}{\lim}
                        v_{n_{N+1}}-u_{n_{1}}
                \end{align}
                Therefore $u_{n_{k}}\rightarrow{v}+u_{n_{1}}$.
                But $u_{n}$ is Cauchy and thus if there is a
                convergent subsequence, then it is a convergent
                sequence. Therefore, $(X,\norm{\cdot})$ is complete.
            \end{proof}
            \begin{theorem}
                If $(X,\mathcal{M},\mu)$ is a measure space, and
                if $1\leq{p}\leq\infty$.
            \end{theorem}
            \begin{proof}
                Suppose that $f_{n}$ is a sequence of functions
                in $L^{P}(X,\mathcal{M},\mu)$ such that:
                \begin{equation}
                    \sum_{k=1}^{\infty}\norm{f_{n}}_{p}=B<\infty
                \end{equation}
                Define $G,G_{n}:X\rightarrow[0,\infty]$ be
                defined by:
                \begin{align}
                    G(x)&=\sum_{k=1}^{\infty}|f_{k}(x)|\\
                    G_{n}(x)&=\sum_{k=1}^{n}|f_{k}(x)|
                \end{align}
                Then, from the triangle inequality, we have that:
                \begin{equation}
                    \norm{G_{n}}_{p}\leq
                    \sum_{k=1}^{n}\norm{f_{k}}_{p}
                    \leq{B}
                \end{equation}
                Thus, by the monotone convergence theorem, we have:
                \begin{equation}
                    \int_{X}G(x)^{p}\diff{\mu}
                    =\underset{n\rightarrow\infty}{\lim}
                    \int_{X}G_{n}(x)^{p}\diff{\mu}\leq{B}^{p}
                \end{equation}
                Therefore $G\in\mathcal{L}^{p}(X)$, and thus
                $G(x)<\infty$ $\mu$ almost-everywhere. But then the
                original series converges $\mu$ almost everywhere.
                Define $F$ be:
                \begin{equation}
                    F(x)=
                    \begin{cases}
                        \sum_{n=1}^{\infty}f_{n}(x),
                        &|\sum_{n=1}^{\infty}f_{n}(x)|<\infty\\
                        0,&\textrm{Otherwise}
                    \end{cases}
                \end{equation}
                Then $|F(x)|\leq{G}(x)$, and thus
                $F\in\mathcal{L}^{p}(X)$. Moreover:
                \begin{equation}
                    \big|F(x)-\sum_{k=1}^{n}f_{k}(x)\big|^{p}
                    \leq{2}^{p}G(x)^{p}
                \end{equation}
                Therefore, by the Lebesgue Dominated Convergence
                Theorem, we have that:
                \begin{equation}
                    \norm{F-\sum_{k=1}^{n}f_{k}(x)}^{p}_{p}
                    \rightarrow{0}
                \end{equation}
                Therefore, $F\in{L}^{p}(X,\mathcal{M},\mu)$.
            \end{proof}
            \begin{ldefinition}
                  {Supremum Norm of Bounded Continuous Function}
                  {Funct_Analysis_Sup_Norm_of_Bound_Cont_Funcs}
                The supremum norm on set $C_{b}(X)$ of bounded
                continuous functions on a metric space $(X,d)$ is:
                \begin{equation}
                    \norm{f}_{\infty}=\sup_{x\in{X}}|f(x)|
                \end{equation}
            \end{ldefinition}
            From this, we can see thatn $f_{n}\rightarrow{f}$ if
            and only if $f_{n}\rightarrow{f}$ uniformly on $X$.
            \begin{theorem}
                $C_{b}(X)$ is complete in the supremum norm.
            \end{theorem}
            \begin{proof}
                Suppose that $f_{n}$ is a Cauchy sequence in
                $C_{b}(X)$. For for all $f_{n}$ and $x\in{X}$,
                $f_{n}(x)$ is a Cauchy sequence in $\mathbb{C}$.
                But $\mathbb{C}$ is complete, and thus there is a
                $c_{x}\in\mathbb{C}$ such that
                $f_{n}(x)\rightarrow{c}_{x}$. Let
                $f(x)=c_{x}$ for all $x\in{X}$. Then
                $f_{n}\rightarrow{f}$. For, let $\varepsilon>0$.
                Then there exists $N\in\mathbb{N}$ sch that, for
                all $n,m>{N}$ implies that:
                \begin{equation}
                    |f_{n}(x)-f_{m}(x)|<\varepsilon/2
                \end{equation}
                But then:
                \begin{equation}
                    |f_{n}(x)-f(x)|=
                    \underset{m\rightarrow\infty}{\lim}
                    |f_{n}(x)-f_{m}(x)|
                    \leq\frac{\varepsilon}{2}<\varepsilon
                \end{equation}
                But the uniform limit of continuous functions is
                continuous. Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $(X,d)$ is a complete metric space, if
                $(E,d')$ is a subspace of $(X,d)$, and if
                $E$ is closed, then $(E,d')$ is complete.
            \end{theorem}
            \begin{proof}
                Suppose $E$ is closed and suppose $(x_{n})$ is a
                Cauchy sequence in $E$. Then $x_{n}$ is a Cauchy
                sequence in $X$, but $X$ is complete. Therefore
                there is an $x\in{X}$ such that
                $x_{n}\rightarrow{x}$. But $E$ is closed,
                and therefore $x\in{E}$. Now suppose $E$ is
                complete. Suppose $x_{n}$ is a sequence in $E$
                and that $x_{n}\rightarrow{y}$ in $X$. But
                convergent sequences are Cauchy sequences, and
                thus $x_{n}$ is a Cauchy sequence. But $E$ is
                complete and therefore $y\in{E}$.
                Therefore, $E$ is closed.
            \end{proof}
            \begin{ldefinition}{Bounded Metric Spaces}
                  {Funct_Analysis_Bounded_Metric_Space}
                A bounded metric space is a metric space
                $(X,d)$ such that there exists an $x\in{X}$
                and an $r>0$ such that:
                \begin{equation}
                    X\subseteq{B}_{r}^{(X,d)}(x)
                \end{equation}
            \end{ldefinition}
            \begin{ldefinition}{Diameter of a Metric Space}
                  {Funct_Analysis_Diam_of_Metric_Space}
                The diameter of a bounded metric space $(X,d)$ is:
                \begin{equation}
                    \mathrm{diam}(X)=\sup_{x\in{X}}\{d(x,y):x,y\in{X}\}
                \end{equation}
            \end{ldefinition}
            Every bounded metric space is contained in some
            open ball.
            \begin{theorem}
                If $(X,d)$ is a metric space, and then it
                is complete if and only if for any sequence
                of non-empty closed sets
                $F:\mathbb{N}\rightarrow\mathcal{P}(X)$ such that
                $F_{n+1}\subseteq{F}_{n}$ and
                $\mathrm{diam}(F_{n})\rightarrow{0}$,
                there is an $x\in{X}$ such that:
                \begin{equation}
                    \{x\}=\cap_{n=1}^{\infty}F_{n}
                \end{equation}
            \end{theorem}
            \begin{proof}
                For suppose $(X,d)$ is complete, and let
                $F:\mathbb{N}\rightarrow\mathcal{P}(X)$ be a
                sequence of non-empty subsets of $X$. Then, for
                all $n\in\mathbb{N}$, $F_{n}$ is non-empty, and
                thus there is a sequence
                $a:\mathbb{N}\rightarrow{X}$ such that, for all
                $n\in\mathbb{N}$, $x_{n}\in{F_{n}}$. But then:
                \begin{equation}
                    d(a_{n},a_{m})\leq\mathrm{diam}(F_{\max\{n,m\}})
                \end{equation}
                But $\mathrm{diam}(F_{n})\rightarrow{0}$, and therefore
                $a$ is a Cauchy sequence. But $(X,d)$ is complete,
                and therefore there is an $x\in{X}$ such that
                $a_{n}\rightarrow{x}$. Moreover, there is an
                $N\in\mathbb{N}$ such that $x\in\overline{F}_{N}$.
                But $F_{N}$ is closed, and thus $x\in{F}_{N}$.
                But for all $n>N$, $F_{n}\subseteq{F}_{N}$.
                Therefore:
                \begin{equation}
                    x\in\cap_{n=1}^{\infty}F_{n}
                \end{equation}
                If $y\in\cap_{n=1}^{\infty}F_{n}$, then
                $d(x,y)\leq\mathrm{diam}(F_{n})$ for all $n\in\mathbb{N}$.
                But $\mathrm{diam}(F_{n})\rightarrow{0}$, and thus
                $d(x,y)=0$. Therefore, $x=y$. Going the other
                way, suppose $X$ has the nested set property and
                let $a:\mathbb{N}\rightarrow{X}$ be a Cauchy
                sequence in $X$. Let
                $F:\mathbb{N}\rightarrow\mathcal{P}(X)$
                be defined by:
                \begin{equation}
                    F_{n}=\overline{\{a_{k}:k\geq{n}\}}
                \end{equation}
                Then, for all $n\in\mathbb{N}$, $F_{n}$
                is non-empty, and $F_{n+1}\subseteq{F}_{n}$.
                Moreover, $\mathrm{diam}(F_{n})\rightarrow{0}$. Thus, by
                the nested sequence property, there is an
                $x\in{X}$ such that $x\in\cap_{n=1}^{\infty}F_{n}$.
                But then:
                \begin{equation}
                    d(a_{n},x)\leq\mathrm{diam}(F_{n})\rightarrow{0}
                \end{equation}
                and therefore $a_{n}\rightarrow{x}$. Thus, $a$ is
                a Cauchy sequence and $(X,d)$ is complete.
            \end{proof}
            \begin{definition}
                A complete metric space is a metric
                space $(X,d)$ such that every
                Cauchy sequence $x_{n}$
                in $X$ converges to a point in $X$
                with respect to $d$.
            \end{definition}
            Recall that a sequence $x_{n}$ is Cauchy if
            $\forall_{\varepsilon>0}\exists_{N\in\mathbb{N}}:%
             \forall_{n,m>N},d(x_{n},x_{m})<\varepsilon$.
            Convergence with respect to $d$ means that
            $d(x,x_{n})\rightarrow{0}$.
            \begin{example}
                $\mathbb{R}$ with the standard metric
                $d(x,y)=|x-y|$ is complete.
            \end{example}
            \begin{example}
                $(\mathbb{R}^{n},d_{p})$ is also complete
                for all $n\in\mathbb{N}$.
            \end{example}
            Completeness is both a property of the set
            and the metric itself. It is not a topological
            property.
            \begin{example}
                $(\mathbb{R},d)$, where
                $d(x,y)=|\tan^{-1}(x)-\tan^{-1}(y)|$
                is \textit{not} complete. For let
                $x_{n}=n$. This is a Cauchy sequence,
                as one can see from the graph
                of $\tan^{-1}(x)$. That is, because
                $\tan^{-1}(x)\rightarrow{\pi/2}$,
                $x_{n}=n$ is a Cauchy sequence in this
                metric. Being even more rigorous, let
                $\varepsilon>0$ and
                $N=\ceil{\tan(\pi/2-\varepsilon)}$.
                Then, for all $n,m>N$,
                $d(x_{n},x_{m})%
                 =|\tan^{-1}(n)-\tan^{-1}(m)|%
                 <|\pi/2-\tan^{-1}(\min\{n,m\})|%
                 <|\pi/2-(\pi/2-\varepsilon)|%
                 =\varepsilon$. But $x_{n}$ does not
                converge. For suppose not.,
                Suppose $x_{n}=n\rightarrow{x}$.
                Then for $n>x+1$,
                $d(x_{n},x)=|\tan^{-1}(n)-\tan^{-1}(x)|%
                 <|\tan^{-1}(x+1)-\tan^{-1}(x)|$,
                so $d(x_{n},x)\not\rightarrow{0}$.
                The sequence does not converge.
            \end{example}
            Let $X=\mathbb{R}\cup\{-\infty,\infty\}$.
            Let $d:X\times{X}\rightarrow\mathbb{R}$
            be defined by
            \begin{align*}
                d(x,y)
                &=|\tan^{-1}(x)-\tan^{-1}(y)|
                &
                d(x,\infty)
                &=\frac{\pi}{2}-\tan^{-1}(x)\\
                d(-\infty,x)
                &=\frac{\pi}{2}+\tan^{-1}(x)
                &
                d(-\infty,\infty)&=\pi
            \end{align*}
            Then $d$ is a metric on $X$, and moreover
            $(X,d)$ is complete. The counterexample
            we found for $(\mathbb{R},d)$ has been
            ``filled,'' in a sense. The hole is
            no longer there. The sequence $x_{n}=n$
            now converges to $\infty$. Somewhat
            unsurpringly, $\mathbb{R}$ is
            dense in $X$, with respect to
            $d$. Every element in $X$ is the limit of
            a sequence of elements in $\mathbb{R}$.
            \begin{definition}
                A completion of a metric space
                $(X,d)$ is a complete metric space
                $(\tilde{X},\tilde{d})$ such that
                $X\subset{\tilde{X}}$ and
                the restriction of
                $\tilde{d}$ onto $X$ is equal to $d$.
            \end{definition}
            \begin{theorem}
                Every metric space has a completion.
            \end{theorem}
            \begin{definition}
                An isometry between
                metric spaces
                $(X,d_{X})$ and
                $(Y,d_{Y})$ is a function
                $f:X\rightarrow{Y}$ such that
                $d_{X}(x,y)=d_{Y}(f(x),f(y))$
                for all $x,y\in{X}$.
            \end{definition}
            \begin{definition}
                Isometric metric spaces are metric spaces
                with an isometry between them.
            \end{definition}
            \begin{theorem}
                If $(X,d)$ is a metric space
                and $(\tilde{X}_{1},\tilde{d}_{1})$
                and $(\tilde{X}_{2},\tilde{d}_{2})$
                are completions of $(X,d)$, then
                $(\tilde{X}_{1},\tilde{d}_{1})$
                and $(\tilde{X}_{2},\tilde{d}_{2})$
                are isometric.
            \end{theorem}
            This says the completion of a metric space is
            unique up to isometry.
            The Lebesgue space $L^{p}(S)$
            can be defined to be the completion of
            $C(S)$ with respect to the $d_{p}$ metric.
            \begin{theorem}
                $(C(S),d_{\infty})$ is complete.
            \end{theorem}
            \begin{proof}
                Suppose $x_{n}$ is a Cauchy sequence
                and let $\varepsilon>0$. As $x_{n}$ is
                Cauchy, there exists $N\in\mathbb{N}$
                such that for all $n,m>N$,
                $\sup|x_{m}(t)-x_{n}(t)|<\frac{\varepsilon}{3}$.
                But then for all $t\in{S}$,
                $|x_{m}(t)-x_{n}(t)|<\frac{\varepsilon}{3}$,
                for all
                $n,m>N$. That is, if $x_{n}$ is
                a Cauchy sequence in $(C(S),d_{\infty})$,
                then it is a Cauchy sequence in
                $(\mathbb{R},d_{1})$. But
                $(\mathbb{R},d_{1})$ is complete, and
                therefore, for all $t\in{S}$, there is
                an $x(t)$ such that
                $x_{n}(t)\rightarrow{x(t)}$ with respect
                to the $d_{1}$ metric on $\mathbb{R}$. We
                now need to show that $x(t)$ is a continuous
                function. That is, that
                $x(t)\in{C(S)}$. Finally we need to show that
                $x_{n}\rightarrow{d}$ with respect to
                $d_{\infty}$. We need to show that
                for all $\varepsilon>0$ and all $t\in{S}$
                there is a $\delta>0$
                such that for all $|t-t_{0}|<\delta$,
                $|x(t)-x(t_{0})|<\varepsilon$. But for
                all $n,m>N$,
                $\sup\{x_{n}(t)-x_{m}(t)\}<\frac{\varepsilon}{3}$.
                Taking the limit on $m$, we have
                $|x(t)-x_{n}(t)|<\frac{\varepsilon}{2}$.
                But $x_{n}(t)$ is continuous, and thus
                there exists $\delta>0$ such that
                for all $|t-t_{0}|<\delta$,
                $|x_{n}(t)-x_{n}(t_{0})|<\frac{\varepsilon}{3}$.
                But
                $|x(t)-x(t_{0})|\leq%
                  |x(t)-x_{n}(t)|%
                 +|x_{n}(t)-x_{m}(t)|%
                 +|x(t_{0})-x_{n}(t_{0})$
                But
                $|x(t_{0})-x_{n}(t_{0})|<%
                 \sup\{|x(t)-x_{n}(t)|\}<\frac{\varepsilon}{3}$,
                and therefore
                $|x(t)-x(t_{0})|<\varepsilon$.
                So $x(t)$ is continuous.
            \end{proof}
            The Weierstrass Approximation Theorem says that,
            for closed finite intervals $S$,
            $(C(S),d_{\infty})$ is the completion
            of the set of polynomials with respect to
            the $d_{\infty}$ metric. On the other hand,
            $(C[0,1],d_{p})$ is not complete when
            $1\leq{p}<\infty$. For define the following:
            \begin{equation*}
                H(x)=
                \begin{cases}
                    0,&0\leq{x}\leq{\frac{1}{2}}\\
                    1,&\frac{1}{2}<x\leq{1}
                \end{cases}
            \end{equation*}
            This is discontinuous and cannot be
            approximated arbitrarily well
            by any continuous function. However, the
            \textit{area} underneath $H$ can be approximated
            arbitrarily well be continuous functions. For define:
            \begin{equation*}
                x_{n}(t)=
                \begin{cases}
                    0,&0\leq{x}\leq{\frac{1}{2}-\frac{1}{n}}\\
                    n(x-\frac{1}{2}+\frac{1}{n}),
                    &\frac{1}{2}-\frac{1}{n}\leq{x}
                     \leq{\frac{1}{2}}\\
                    1,&\frac{1}{2}<{x}\leq{1}
                \end{cases}
            \end{equation*}
            Then the area under $x_{n}(t)$
            is $\frac{1}{2}+\frac{1}{2n}$, and thus
            $d_{1}(x_{n}(t),x_{m}(t))%
             =|\frac{1}{2m}-\frac{1}{2n}|$,
            and therefore $x_{n}(t)$ is a Cauchy sequence.
            But $x_{n}(t)$ does not converge in
            $(C[0,1],d_{1})$. For suppose not, suppose
            $x_{n}(t)\rightarrow{x(t)}$, and
            $x(t)\in{C[0,1]}$.
            If $x(1/2)\geq{1/2}$, then, as $x(t)$ is
            continuous, there is a $\delta>0$ such that
            for all $|t-1/2|<\delta$,
            $x(t)>1/4$. But then
            $d(x_{n},x)=\int_{0}^{1}|x(t)-x_{n}(t)|dt%
            \geq\int_{1/2-\delta/2}^{1/2}|x(t)-x_{n}(t)|dt$.
            But $|x|=|(x-y)+y|\leq{|x-y|+|y|}$,
            and thus
            $|x|-|y|\leq{|x-y|}$. From this we have
            $d(x_{n}(t),x(t))\geq%
             \int_{1/2-\delta/2}^{1/2}(x(t)-x_{n}(t))dt%
             >\int_{1/2-\delta/2}^{1/2}\frac{1}{4}dt%
             -\int_{0}^{1/2}x_{n}(t)dt%
             =\frac{1}{4}\delta-\frac{1}{2n}%
             \rightarrow{\frac{1}{4}}\delta$.
            But then $d(x_{n}(t),x(t))\not\rightarrow{0}$.
            Therefore $x_{n}(t)$ does not converge.
            \begin{theorem}
                If $1\leq{p}<\infty$, then
                $(\ell^{p},d_{p})$ is complete.
            \end{theorem}
            \begin{proof}
                Let $x_{n}$ be a Cauchy sequence
                in $(e\ell^{p},d_{p})$,
                $x_{n}=x_{n}(1),x_{n}(2),\hdots,x_{n}(k),\hdots$
                Then, for $n,m\in\mathbb{N}$,
                $d_{p}(x_{n},x_{m})%
                 =(%
                    \sum_{k=0}^{\infty}|x_{n}(k)-x_{m}(k)|^{p}%
                  )^{1/p}$
                As $x_{n}$ is Cauchy, for all
                $\varepsilon>0$ there is an $N\in\mathbb{N}$
                such that for all $n,m>N$,
                $d_{p}(x_{n},x_{m})<\varepsilon$.
                But then, for all $n,m>N$ and all
                $k\in\mathbb{N}$,
                $|x_{n}(k)-x_{m}(k)|^{p}<d_{p}(x_{n},x_{m})^{P}%
                 <\varepsilon^{p}$.
                But then
                $|x_{n}(k)-x_{m}(k)|<\varepsilon$. Therefore
                $x_{n}(k)$ is a Cauchy sequence in
                $(\mathbb{R},d)$, and this metric space is
                complete. Therefore, for all $k\in\mathbb{N}$,
                there is a $z_{k}$ such that
                $x_{n}(k)\rightarrow{z_{k}}$. We now need to
                show that $z_{k}$ is an element of
                $\ell^{p}$ and that
                $x_{n}\rightarrow{z_{k}}$ with respect to
                the $d_{p}$ metric. For let $N\in\mathbb{N}$.
                Then
                $\sum_{k=0}^{N}|x_{n}(k)-x_{m}(k)|^{p}%
                 \leq{\sum_{k=0}^{\infty}|x_{n}(k)-x_{m}(k)|^{p}}%
                 <\varepsilon^{p}$. Taking the limit on $m$,
                we have
                $\sum_{k=0}^{N}|z_{k}-x_{n}(k)|<\varepsilon^{p}$.
                The reason we have written a finite sum is to
                avoid getting into trouble with limits. An
                infinite sum is itself a limit, and taking
                limits of limits can get very messy very easily.
                For example,
                $f(n,m)=\frac{m}{n+m}$. Taking the limit on
                $m$ first results in $1$, whereas taking the
                limit on $n$ first gives you $0$.
                That is,
                $\lim_{n}\lim_{m}f(n,m)%
                 \ne\lim_{m}\lim_{n}f(n,m)$.
                You have to
                be careful when considering limits of limits.
                With this we have shown that
                $z_{k}-x_{n}(k)\in\ell^{p}$ for all
                $n\in\mathbb{N}$. But $x_{n}\in\ell^{p}$,
                and $\ell^{p}$ is closed under addition.
                Therefore $z_{k}\in\ell^{p}$. But also,
                for $n>N$, we have
                $d_{p}(x_{n},z)<\varepsilon$. Thus,
                $x_{n}$ converges.
            \end{proof}
            \begin{theorem}
                If $(X,d)$ is complete and $S$ is a closed
                subset of $X$, then $(S,d_{S})$ is complete,
                where $d_{S}$ is the restriction of
                $d$ onto $S$.
            \end{theorem}
            \begin{proof}
                Let $x_{n}$ be a Cauchy sequence in $S$. Then
                $x_{n}\rightarrow{x}$, $x\in{X}$,
                since $x_{n}$ is Cauchy in $X$
                and $X$ is complete. Since $S$ is closed,
                $x\in{S}$. Therefore, etc.
            \end{proof}
            \begin{theorem}
                If $(X,d)$ is complete and
                $S\subset{X}$ is not closed,
                then $(S,d_{S})$ is not complete.
            \end{theorem}
            \begin{proof}
                If $S$ is not closed then there
                is a convergent sequence $x_{n}\in{S}$
                whose limit it not in $S$. But
                then $x_{n}$ is a Cauchy sequence in
                $X$, and therefore is also a
                Cauchy sequence in $S$, but
                $x_{n}$ does not converge in $S$.
                Therefore $(S,d_{S})$ is not complete.
            \end{proof}
            Recall that $c_{0}$ is the set of sequences which
            tend to zero. That is, it is the set of
            null sequences.
            \begin{theorem}
                $c_{0}$ is a closed subset of
                $(\ell^{\infty},d_{\infty})$
            \end{theorem}
            \begin{proof}[proof 1]
                Let $x_{n}$ be a sequence in $c_{0}$
                that converges to $z\in\ell^{\infty}$
                with respect to $d_{\infty}$.
                Then
                $\sup\{|x_{n}(k)-z_{k}|\}\rightarrow{0}$.
                We need to show that $z\in{c_{0}}$.
                Let $\varepsilon>0$. Let $N_{1}\in\mathbb{N}$
                be such that
                $n>N$ implies
                $\sup\{|x_{n}(k)-z_{k}\}<\frac{\varepsilon}{2}$.
                But $x_{n}\in{c_{0}}$ for all $n$, and thus
                $x_{n}(k)\rightarrow{0}$ as $k\rightarrow\infty$.
                Thus, there is an $N_{2}\in\mathbb{N}$
                such that $n>N_{2}$ implies
                $|x_{n}(k)<\varepsilon$.
                But then for $n>\max\{N_{1},N_{2}\}$,
                $|z_{k}|\leq|z_{k}-x_{n}(k)|+|x_{n}(k)|%
                 <\varepsilon$.
            \end{proof}
            \begin{proof}[Proof 2]
                We can also show that
                $c_{0}^{C}$ is open.
                Let $x\in{c_{0}^{C}}$. Then there is
                an $r>0$ and a subsequence
                $x_{k_{n}}$ of $x$ such that
                $x_{k_{n}}>r$ for all $n$.
                But then $B_{r/2}(x)$ is
                an open ball contained in $c_{0}^{C}$.
                For if $y\in{B_{r/2}(x)}$, then
                $d_{\infty}(x,y)%
                 =\sup\{|x_{n}-y_{n}|\}<r<2$,
                and thus
                $|y_{k_{n}}-x_{k_{n}}|<r/2$,
                and there for $|y_{k_{n}}|>r/2$.
                Thus, $y$ is not a null sequence and
                $c_{0}^{C}$ is open. So
                $c_{0}$ is closed.
            \end{proof}
            Let $X$ be the set of sequences with only
            finitely many nonzero terms.
            Then $(X,d_{\infty}$ is not complete.
            Let $x_{1}=(1,0,0,\hdots)$,
            $x_{2}=(1,1/2,0,0,\hdots)$,
            $x_{n}=(1,1/2,\hdots,1/n,0,0,\hdots)$.
            Then
            $d_{\infty}(x_{n},x_{m})=1/\max\{n,m\}\rightarrow{0}$.
            But clearly
            $x_{n}\rightarrow(1,1/2,\hdots,1/n,\hdots)$, which
            is an element of $c_{0}$, but not an element
            of $X$. Thus $X$ is not closed, and therefore is
            not complete. Returning to $C[0,1]$, when we had
            that sequence of continuous functions that clearly
            converged to a discontinuous functions, we still
            needed to show that there is no continuous function
            that the $x_{n}(t)$ converged to. Here we've embedded
            $X$ into a bigger space, shown that the
            sequence converges to something outside of $X$,
            in our case an element of
            $c_{0}\setminus{X}$, and then used the uniqueness
            of limits to show that the limit does
            not converge in $X$.
        \subsection{Banach's Fixed Point Theorem}
            If $(X,d)$ is a complete metric space,
            and if $T:X\rightarrow{X}$ satisfies
            the property that, for all $x$ and $y$
            in $X$, $d(T(x),T(y))<kd(x,y)$ for
            some $k<1$, then $T$ has a unique
            point $x$, called a fixed point,
            such that $T(x)=x$.
            \begin{definition}
                A contraction of a metric
                space $(X,d)$ is a function
                $T:{X}\rightarrow{X}$ such that there
                exists a $k\in(0,1)$ such that
                for all $x,y\in{X}$,
                $d(T(x),T(y))<kd(x,y)$.
            \end{definition}
            \begin{definition}
                A fixed point of a function
                $f:X\rightarrow{X}$ is a point
                $x\in{X}$ such that
                $f(x)=x$.
            \end{definition}
            \begin{theorem}[%
                Banach's Fixed Point Theorem%
            ]
                If $(X,d)$ is a complete
                metric space and $T:X\rightarrow{X}$
                is a contraction, then there is
                a unique fixed point $x\in{X}$
                with respect to $T$.
            \end{theorem}
            \begin{definition}
                A Lipschitz continuous function is a
                function $f:[a,b]\rightarrow\mathbb{R}$
                such that there is an $L\in\mathbb{R}$
                such that
                $|f(x)-f(y)|<L|x-y|$ for all
                $x,y\in[a,b]$.
            \end{definition}
            This says that the slopes of the
            secant lines of the
            function are bounded. The square root
            function $y=\sqrt{x}$ is an example
            of a function that is not Lipschitz. The
            slopes of secant lines go to infinity
            as the points tend towards the origin.
            \begin{theorem}[Picard's Theorem]
                If $f:[a,b]\times\mathbb{R}%
                    \rightarrow\mathbb{R}$
                is Lipschitz continuous,
                Then there is a unique function
                $x:[a,b]\rightarrow\mathbb{R}$
                such that
                $\frac{dx}{dt}=f(t,x(t))$ and $x(a)=a$.
            \end{theorem}
            \begin{proof}
                We prove Picard by using the
                Banach Fixed Point Theorem. First
                we write the problem as an integral
                equation.
                If $\dot{x}=f(t,x(t))$, then:
                \begin{equation*}
                    x(t)
                    =\int_{a}^{t}\frac{dx}{dt}dt
                    =x_{0}+\int_{a}^{t}f(t,x(t))dt
                \end{equation*}
                Let $(X,d)$ be $C[a,b]$ with the
                supremum norm $d_{\infty}$. Then
                $(x,d)$ is a complete metric space.
                Let $T:{X}\rightarrow{X}$ be defined
                by:
                \begin{equation*}
                    Tx=x_{0}+\int_{a}^{t}f(t,x(t))dt
                \end{equation*}
                All we need to do is show that $T$ is
                a contraction. Applying the
                Banach Fixed Point theorem then
                shows that there is a unique
                fixed point of $T$, thus showing
                that there is a unique solution
                to our original initial value problem.
                If $x,y\in{X}$, then:
                \begin{align*}
                    d(Tx,Ty)
                    &=\sup\{|Tx(t)-Ty(t)|\}\\
                    &=\sup\{
                        (x_{0}+
                         \int_{a}^{t}f(t,x(t))dt)
                       -(x_{0}+
                         \int_{a}^{t}f(t,y(t))dt)
                    \}\\
                    &=\sup\{
                        \int_{a}^{t}f(t,x(t))dt)-
                        \int_{a}^{t}f(t,y(t))dt)
                    \}\\
                    &\leq\int_{a}^{t}|
                        f(t,x(t))-f(t,y(t))|dt
                \end{align*}
                But from the Lipschitz continuity
                of $f$, we have:
                \begin{align*}
                    d(Tx,Ty)&\leq
                    L\int_{a}^{t}|x(t)-y(t)|dt\\
                    &\leq{L}(t-a)d(x,y)\\
                    &\leq{L}(b-a)d(x,y)
                \end{align*}
                So $T$ is a contraction for
                $L(b-a)<1$. Usually we can
                extend this solution by taking
                $b$ as the initial condition and
                stepping forward one interval
                at a time. We'll take a different
                approach. We have that
                $d(Tx,Ty)\leq{L}(b-a)d(x,y)$. From
                this, we obtain:
                \begin{align*}
                    d(T^{2}x,T^{2}y)
                    &\leq{L}\int_{a}^{b}d(Tx,Ty)dt\\
                    &\leq{L}\int_{a}^{t}
                        L(t-a)d(x,t)dt\\
                    &=\frac{L^{2}}{2}(t-a)^{2}d(x,y)\\
                    &\leq
                    \frac{L^{2}}{2}(b-a)^{2}d(x,y)
                \end{align*}
                Applying induction, we have:
                \begin{equation*}
                    d(T^{n}x,T^{n}y)
                    \leq\frac{L^{n}}{n!}(b-a)^{n}
                \end{equation*}
                But this tends to zero, and thus
                there is an $N$ such that,
                for all $n>N$, $T^{n}$ is a
                contraction. But then, by the
                Banach Fixed Point Theorem, there
                is a unique point $x$ such that
                $T^{n}x=x$. But then
                $Tx=T^{n}(Tx)$, and thus
                $Tx$ is a fixed point of
                $T^{n}$. But the fixed point of
                $T^{n}$ is unique, and $x$ is a
                fixed point. Therefore
                $Tx=x$. Therefore, etc.
            \end{proof}
            Without Lipschitz continuous you may
            lose uniqueness, but you still have
            existence. This is Peano's theorem.
            An example is $\dot{x}=\sqrt{x}$
            with $x(0)=0$.
            This has solutions $x(t)=0$ and
            $(t)=t^{2}/4$. Now back to compactness.