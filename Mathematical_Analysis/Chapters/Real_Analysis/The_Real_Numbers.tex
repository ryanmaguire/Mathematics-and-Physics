\section{The Real Numbers}
    \subsection{Completeness}
        One of the fundamental properties of $\mathbb{R}$ is that is is
        \textit{complete}. This property is fundamental to many theorems
        involved in a standard calculus or real analysis course. For
        example, the concepts of differentiation and convergence rely on
        completeness, and the intermediate value theorem may fail without it.
        On the other hand, $\mathbb{Q}$ is not complete. The rationals are,
        however, \textit{dense} in the reals. That is, elements of $\mathbb{R}$
        can be approximated arbitrarily well by elements of $\mathbb{Q}$.
        $\mathbb{R}$ is also something called a \textit{field}. From algebra,
        a field is just a set with two operations (Usually called addition and
        multiplication) that are defined in such a way as to give rise
        to the usual notions of addition, subtraction, multiplication, and
        non-zero division, and to give them the basic properties of
        associativity, commutativity, and the distributive law that is found in
        arithmetic. $\mathbb{Q}$ is also a field. Moreover, $\mathbb{R}$ and
        $\mathbb{Q}$ are \textit{ordered fields} with respect to their standard
        ordering. What makes $\mathbb{R}$ special is that it is a complete
        ordered field. In fact, $\mathbb{R}$ is the \textit{only} complete
        ordered field (Up to isomorphism). Completeness in $\mathbb{R}$ can be
        stated by fact that the real numbers have the least upper bound
        property.
        \begin{definition}
            A bounded above subset of $\mathbb{R}$ is a nonempty subset
            $S\subseteq{\mathbb{R}}$ such that there exists an $M\in\mathbb{R}$
            such that for all $x\in{S}$, $x\leq{M}$.
        \end{definition}
        \begin{definition}
            An upper bound of a bounded above subset $S\subseteq\mathbb{R}$ is
            a real number $M\in\mathbb{R}$ such that for all $x\in{S}$,
            $x\leq{M}$.
        \end{definition}
        If $S\subseteq\mathbb{R}$ is bounded above, then there exists
        infinitely many bounds. Completeness says that every bounded above
        subset has a smallest upper bound.
        \begin{theorem}[Least Upper Bound Theorem]
            \label{thm:Func_Least_Upper_Bound_Theorem}%
            If $S\subseteq{\mathbb{R}}$ is bounded above, then there exists an
            $s\in\mathbb{R}$, called the least upper bound, such that $s$
            and an upper bound and for all upper bounds $M$ of $S$, $s\leq{M}$.
        \end{theorem}
        The proof of Thm.~\ref{thm:Func_Least_Upper_Bound_Theorem} depends on
        how one defines the real numbers. This is often done via Dedekind cuts
        or equivalence classes of Cauchy sequences in $\mathbb{Q}$.
        \begin{theorem}
            There exist bounded above sets
            $S\subset\mathbb{Q}$ such that for all
            upper bounds $M$ there exists an
            $s\in\mathbb{Q}$ such that $s$ is an upper
            bound of $S$ and $s<M$.
        \end{theorem}
        \textit{Sketch of Proof.}
        For let $S=\{x\in\mathbb{Q}:x^{2}\leq{2}\}$.
        This set has no least upper bound. Loosely
        speaking this is because the
        least upper bound wants to be $\sqrt{2}$,
        but $\sqrt{2}$ is not a rational number. Thus
        there is no rational number to fill the gap.
        \par\hfill\par
        The least upper bound property gives rise
        to many theorems, many of which are equivalent
        to this axiom. Recall that a sequence is a
        function $x:\mathbb{N}\rightarrow{X}$. That is,
        a sequence is a function whose domain is the
        natural numbers, and whose image lies in some
        set $X$. A sequence of real numbers is thus a
        function $x:\mathbb{N}\rightarrow\mathbb{R}$,
        and a sequence of rational numbers is a function
        $x:\mathbb{N}\rightarrow\mathbb{Q}$.
        Often times sequences are denoted $x_{n}$,
        but also the image of $n$ is usually
        denoted $x(n)=x_{n}$ which may be a cause
        for confusion. That is, when we write $x_{n}$
        we often mean $x(n)$, so $x_{0}$, $x_{1}$,
        $x_{2}$ can be written as $x(0)$, $x(1)$,
        $x(2)$ but nobody does this. Similarly,
        we may mean $x_{n}=x$ since nobody writes
        a sequence as $x$. For consistency, we will.
        \begin{definition}
            A sequence in a set $X$ is a function
            $x:\mathbb{N}\rightarrow{X}$.
            We write the image of $n\in\mathbb{N}$
            as $x(n)=x_{n}$.
        \end{definition}
        The notion of \textit{convergence} of a sequence
        in $\mathbb{R}$ is defined as follows.
        \begin{definition}
            A convergent sequence in $S\subseteq\mathbb{R}$
            is a sequence $x:\mathbb{N}\rightarrow{S}$
            such that there exists an $a\in\mathbb{R}$
            such that $|a-x_{n}|\rightarrow{0}$ as
            $n\rightarrow\infty$. We write
            $x_{n}\rightarrow{a}$.
        \end{definition}
        \begin{definition}
            A limit of a sequence $x$
            in a subset $S\subseteq\mathbb{R}$ is an
            element $a\in\mathbb{R}$ such that
            $|a-x_{n}|\rightarrow{0}$.
        \end{definition}
        \begin{theorem}
            If $S\subseteq\mathbb{R}$ and $a$ and $b$ are
            limits of $x:\mathbb{N}\rightarrow{S}$,
            then $a=b$.
        \end{theorem}
        \begin{proof}
            Suppose not. Then $|a-b|>0$. But as $a$ is a
            limit of $x$, there is an $N_{1}\in\mathbb{N}$
            such that, for all $n>N_{1}$,
            $|a-x_{n}|<|a-b|/4$. But, as $b$ is a limit
            of $x$, there is an $N_{2}\in\mathbb{N}$
            such that for all $n>N_{2}$,
            $|b-x_{n}|<|a-b|/4$. Let $N=\max\{N_{1},N_{2}\}+1$.
            But from the triangle inequality:
            $|a-b|\leq|a-x_{N}|+|b-x_{N}|<|a-b|/2$, a
            contradiction. Therefore, $a=b$.
        \end{proof}
        The next notion to discuss is that of
        \textit{subsequences}. There are two ways to define
        a subsequence rigorously. A subsequence of a sequence
        $x:\mathbb{N}\rightarrow{X}$ is a sequence 
        $y:\mathbb{N}\rightarrow{X}$ such that there exists
        a strictly increasing sequence
        $k:\mathbb{N}\rightarrow\mathbb{N}$ such that, for all
        $n\in\mathbb{N}$, $y_{n}=(x\circ{k})(n)$. Here,
        $(x\circ{k})$ is the \textit{composition} of
        the two functions $x$ and $k$. This is
        often written $x_{k_{n}}$, but this can occasionally
        be confusing. We can also just define a subsequence
        to be any strictly increasing sequence
        $k:\mathbb{N}\rightarrow\mathbb{N}$. Given a sequence
        $x:\mathbb{N}\rightarrow{X}$, since $k$ is strictly
        increasing the ordering of $x\circ{k}$
        remains the same, and we've simply skipped over
        some points. Recall that
        monotonic sequences are sequences such
        that, for all $n\in\mathbb{N}$, either
        $x_{n+1}\leq{x_{n}}$ (Monotonically decreasing),
        or $x_{n}\leq{x_{n+1}}$ (Monotonically increasing).
        Strictly monotonic means either $x_{n+1}<x_{n}$
        or $x_{n}<x_{n+1}$ for all $n\in\mathbb{N}$.
        \begin{definition}
            A subsequence is a strictly increasing sequence
            $k:\mathbb{N}\rightarrow\mathbb{N}$
        \end{definition}
        \begin{definition}
            A convergent subsequence of a sequence
            $x:\mathbb{N}\rightarrow{S}$ in
            a subset $S\subseteq\mathbb{R}$ is a
            subsequence $k$ such that
            $x\circ{k}$ is a convergent sequence in $S$.
        \end{definition}
        \begin{definition}
            A monotonic subsequence of a sequence
            $x:\mathbb{N}\rightarrow{S}$ in a subset
            $S\subseteq\mathbb{R}$ is a subsequence
            $k:\mathbb{N}\rightarrow\mathbb{N}$ such
            that $x\circ{k}$ is a monotonic sequence.
        \end{definition}
        \begin{example}
            If $x:\mathbb{N}\rightarrow\mathbb{N}$ is
            the sequence defined by $x_{n}=n$, and if
            $k:\mathbb{N}\rightarrow\mathbb{N}$ is the
            subsequence defined by
            $k_{n}=2n$, then $x_{k_{n}}=2n$. This is the
            subsequence of all even numbers.
            If $k_{n}=2n-1$, then $x_{k_{n}}=2n-1$. This
            is the subsequence of all odd numbers. As a
            boring example, let $k_{n}=n$. Then
            $x_{k_{n}}=n$. This is the identity subsequence.
        \end{example}
        \begin{theorem}
            If $S\subseteq\mathbb{R}$,
            $x:\mathbb{N}\rightarrow\mathbb{R}$ is a
            convergent sequence, and if
            $k:\mathbb{N}\rightarrow\mathbb{N}$ is a
            subequence, then $x\circ{k}$ is a convergent
            sequence.
        \end{theorem}
        \begin{proof}
            For let $\varepsilon>0$.
            As $x$ is a convergent sequence there is
            an $a\in\mathbb{R}$ such that
            $x_{n}\rightarrow{a}$. Thus, there is an
            $N\in\mathbb{N}$ such that, for all
            $n>N$, $|a-x_{n}|<\varepsilon$. But
            $k$ is a subsequence and is therefore
            strictly increasing, so
            for all $n\in\mathbb{N}$, $k_{n}\geq{n}$.
            But then for all $n>N$, $k_{n}>N$, and thus
            $|x_{k_{n}}-a|<\varepsilon$. Therefore,
            $x_{k_{n}}\rightarrow{a}$.
        \end{proof}
        There is an important theorem about
        subsequences of bounded sequences called the
        Bolzano-Weierstrass theorem. It states that
        every bounded sequence has a convergent subsequence,
        and is an equivalent definition of the
        completeness of $\mathbb{R}$. There are a few theorems
        needed before we can prove it.
        \begin{theorem}
            \label{th:funct:bounded_monotone_%
                   sequences_converge}
            If $x:\mathbb{N}\rightarrow\mathbb{R}$
            is a bounded monotonic sequence,
            then $x$ is a convergent sequence.
        \end{theorem}
        \begin{proof}
            Let $x$ be a bounded monotonic sequence that
            is increasing in $\mathbb{R}$.
            If $x$ is decreasing, we replace the least
            upper bound with the greatest lower
            bound and the proof is symmetric.
            Then $S=\{x_{n}:n\in\mathbb{N}\}$ is a
            non-empty subset of $\mathbb{R}$. But $x$ is
            a bounded sequence, and therefore $S$ is a
            bounded subset of $\mathbb{R}$. By the least
            upper bound property there exists a least
            upper bound $s\in\mathbb{R}$ of $S$.
            We now show that $x_{n}\rightarrow{s}$.
            Let $\varepsilon>0$ be given. Since $s$ is
            the least upper bound, $s-\varepsilon$
            is not an upper bound of $S$, since
            $s-\varepsilon<s$. Therefore there exists
            an $N\in\mathbb{N}$ such that
            $s-\varepsilon<x_{N}$. But $x$ is
            monotonically increasing, and therefore
            for all $n>N$, $x_{N}\leq{x_{n}}$.
            But, as $s$ is a least upper
            bound of $S$, $x_{n}\leq{s}$. But then,
            for all $n>N$,
            $0\leq{s-x_{n}}\leq{s-x_{N}}<\varepsilon$.
            Therefore, $x_{n}\rightarrow{s}$.
        \end{proof}
        The least upper bound is, in a sense, the
        reason why decimal expansions of
        real numbers work. For example, let $x$ be the
        sequence 3, 3.1, 3.14, 3.141, 3.1415, 3.14159,
        and so forth. This sequence, which is
        the decimal expansion of $\pi$, is bounded by $4$.
        Therefore it has a least upper bound.
        We define the number $\pi$
        to be the least upper bound of this sequence.
        Completeness is a very important property
        but so far it relies on the ordering
        of the real numbers.
        We want to find an equivalent definition
        of completeness that does not rely on ordering
        so that we may speak of complete spaces,
        or sets, which have no notion of
        order. We start with a different definition
        for the completeness of $\mathbb{R}$.
        \begin{definition}
            A Cauchy sequence in a subset
            $S\subseteq\mathbb{R}$ is a
            sequence $x:\mathbb{N}\rightarrow{S}$
            such that for all $\varepsilon>0$ there
            is an $N\in\mathbb{N}$ such that for all
            $n,m>N$, $|x_{n}-x_{m}|<\varepsilon$.
            That is:
            \begin{equation}
                \label{thm:Func_Def_Cauchy_Sequence}
                \forall_{\varepsilon>0}
                \exists_{N\in\mathbb{N}}:
                n,m>N\Rightarrow
                |x_{n}-x_{m}|<\varepsilon
            \end{equation}
        \end{definition}
        \begin{theorem}
            \label{FUNCTIONAL_ANALYSIS:CONVERGENT_%
                   SEEQUENCES_ARE_CAUCHY_SEQUENCES}
            If $S\subseteq\mathbb{R}$ and if
            $x:\mathbb{N}\rightarrow{S}$
            is a convergent sequence, then it
            is a Cauchy sequence.
        \end{theorem}
        \begin{proof}
            For let $x$ be a convergent sequence and
            let $a$ be it's limit.
            Let $\varepsilon>0$ be given. Then, as
            $x_{n}\rightarrow{a}$, there is an
            $N\in\mathbb{N}$ such that for all $n>N$,
            $|x_{n}-a|<\varepsilon/2$.
            But by the triangle inequality,
            for all $n,m>N$:
            \begin{equation}
                |x_{n}-x_{m}|\leq
                |x_{n}-a|+|x_{m}-a|<
                \frac{\varepsilon}{2}+
                \frac{\varepsilon}{2}
                =\varepsilon
            \end{equation}
            Therefore, $x$ is a Cauchy sequence.
        \end{proof}
        The converse of
        Thm.~\ref{FUNCTIONAL_ANALYSIS:CONVERGENT_%
                  SEEQUENCES_ARE_CAUCHY_SEQUENCES}
        turns out to be a more general notion
        of completeness. That is, we can apply
        this to spaces that do not have
        a notion of order, but do have a notion
        of completeness. There are Cauchy sequences
        $x:\mathbb{N}\rightarrow\mathbb{Q}$ that do
        not converge. This is again related to the fact
        that $\mathbb{Q}$ is not complete. For sequences
        $x:\mathbb{N}\rightarrow\mathbb{R}$,
        if $x$ is Cauchy then it must converge.
        \begin{theorem}
            \label{THM:FUNCTIONAL_ANALYSIS:%
                   SUBSEQ_OF_CAUCHY_IS_CAUCHY}
            If $S\subseteq\mathbb{R}$,
            $x:\mathbb{N}\rightarrow{S}$ is a Cauchy sequence,
            and if $k:\mathbb{N}\rightarrow\mathbb{N}$
            is a subsequence, then
            $x\circ{k}$ is a Cauchy sequence.
        \end{theorem}
        \begin{proof}
            For let $\varepsilon>0$. As $x$ is a Cauchy
            sequence, there is an $N\in\mathbb{N}$ such that,
            for all $n,m>N$, $|x_{n}-x_{m}|<\varepsilon$.
            But, as $k$ is a subsequence it is strictly
            increasing, and thus for all $n\in\mathbb{N}$,
            $k_{n}\geq{n}$. But then for all $n,m>N$,
            $k_{n},k_{m}>N$, and thus
            $|x_{k_{n}}-x_{k_{m}}|<\varepsilon$. Thus,
            $x\circ{k}$ is Cauchy.
        \end{proof}
        \begin{theorem}
            If $S\subseteq\mathbb{R}$ and if
            $x:\mathbb{N}\rightarrow{S}$ is a Cauchy sequence,
            then $x$ is a bounded sequence.
        \end{theorem}
        \begin{proof}
            For as $x$ is a Cauchy sequence there is an
            $N\in\mathbb{N}$ such that, for all $n,m>N$,
            $|x_{n}-x_{m}|<1$. Then, for all $n>N+1$,
            $x_{N+1}-1<x_{n}<x_{N+1}+1$. Let
            $M=\max\{|x_{0}|,|x_{1}|,\hdots,|x_{N+1}|+1\}$.
            Then for all $n\in\mathbb{N}$,
            $|x_{n}|\leq{M}$.
        \end{proof}
        We cannot replace the requirement that,
        for all $n,m>N$, $|x_{n}-x_{m}|<\varepsilon$
        with $n,n+k$ for some fixed $k\in\mathbb{N}$.
        There are sequences such that
        $x_{n+1}-x_{n}\rightarrow{0}$,
        yet $x$ is not Cauchy. Indeed, there are such sequences
        that are bounded.
        \begin{example}
            \begin{subequations}
                There are unbounded sequences $x$ such that
                $x_{n+1}-x_{n}\rightarrow{0}$. For let
                $x:\mathbb{N}\rightarrow\mathbb{R}$
                be the sequence defined
                by $x_{n}=\sqrt{n}$. Then:
                \begin{equation}
                    |x_{n+1}-x_{n}|=|\sqrt{n+1}-\sqrt{n}|
                    =\frac{1}{\sqrt{n+1}+\sqrt{n}}
                    <\frac{1}{2\sqrt{n}}
                    \rightarrow{0}
                \end{equation}
                But $\sqrt{n}\rightarrow\infty$.
                Moreover, there are bounded sequences $x$
                such that $x_{n+1}-x_{n}\rightarrow{0}$,
                yet $x$ is not Cauchy. For let
                $x:\mathbb{N}\rightarrow\mathbb{R}$
                be defined by
                $x_{n}=\cos(\pi\sqrt{n})$.
                Then $x$ is bounded, and:
                \begin{align}
                    x_{n+1}-x_{n}
                    &=\cos\big(\pi\sqrt{n+1})
                        -\cos(\pi\sqrt{n}\big)\\
                    &=-2\sin\Big(\pi
                        \frac{\sqrt{n+1}-\sqrt{n}}{2}\Big)
                        \sin\Big(\pi
                            \frac{\sqrt{n+1}+\sqrt{n}}{2}\Big)
                \end{align}
                But we saw from the previous example that
                $\sqrt{n+1}-\sqrt{n}\rightarrow{0}$, and
                therefore $x_{n+1}-x_{n}\rightarrow{0}$.
                $x$ is not Cauchy, however, for let
                $k:\mathbb{N}\rightarrow\mathbb{N}$ be
                the subsequence defined by $k_{n}=n^{2}$. Then:
                \begin{equation}
                    x_{k_{n}}=\cos(\pi{n})=(-1)^{n}
                \end{equation}
                And this is not a Cauchy sequence. By
                Thm.~\ref{THM:FUNCTIONAL_ANALYSIS:%
                          SUBSEQ_OF_CAUCHY_IS_CAUCHY},
                $x$ is not a Cauchy sequence.
            \end{subequations}
        \end{example}
        \begin{theorem}
            \label{th:funct:sequences_have_%
                   monotonic_subsequence}
            Every sequence in $\mathbb{R}$
            has a monotonic subsequence.
        \end{theorem}
        \begin{proof}
            Let $x$ be a sequence in $\mathbb{R}$.
            Call $n$ a ``peak point'' if
            $x_{n}\geq{x_{m}}$ for all
            ${m}\geq{n}$. If there are infinitely many
            of these peak points, then we have obtained
            a decreasing sequence, since the $n^{th}$
            peak point will be greater than or equal to
            the $(n+1)^{th}$ peak point.
            We have thus obtained
            a monotonically decreasing subsequence.
            If there are finitely many,
            there are either zero or there is a last one,
            $x_{n_{0}}$. Then $x_{n_{0}+1}$ is not a
            peak point. But then there is a
            $k\in\mathbb{N}$ such that $k>n_{0}+1$ and
            $x_{k}\geq{x_{n_{0}+1}}$, for otherwise
            $x_{n_{0}+1}$ would be a peak point. But
            $x_{k}$ is also not a peak point, and so
            there is a $k_{1}$ such that $k_{1}>k$ and
            $x_{k_{1}}\geq{x_{k}}$. This pattern
            continues, and we thus have a monotonically
            increasing subsequence. If there are zero
            peak points, repeat the argument above
            argument with $x_{n_{0}}=x_{1}$.
        \end{proof}
        There's probably some axiom of choice stuff
        going on here.
        \begin{theorem}[Bolzano-Weierstrass Theorem]
            If $x:\mathbb{N}\rightarrow\mathbb{R}$
            is a bounded sequence, then there is
            a convergent subsequence
            $k:\mathbb{N}\rightarrow\mathbb{N}$
            of $x$.
        \end{theorem}
        \begin{proof}
            By Thm.~\ref{th:funct:sequences_%
                         have_monotonic_subsequence},
            if $x:\mathbb{N}\rightarrow\mathbb{R}$ is a
            sequence, then there is a monotonic subsequence
            $k:\mathbb{N}\rightarrow\mathbb{N}$.
            But by Thm.~\ref{th:funct:bounded_%
                             monotone_sequences_converge},
            bounded monotonic sequences converge.
            Thus $x\circ{k}$ converges.
            Therefore $k$ is a convergent
            subsequence of $x$.
        \end{proof}
        This notion is so important it has a name.
        A sequentially compact space is a space such that
        every sequence has a convergent subsequence. The
        Bolzano-Weierstrass Theorem is equivalent
        to saying that every closed and bounded subset
        of $\mathbb{R}$ is sequentially
        compact. The general notion of \textit{compactness}
        is a topological one, but as it turns out
        sequential compactness and compactness are
        identical concepts in a \textit{metric space}.
        Metric spaces will be one of the primary
        subjects of study in functional analysis.
        In $\mathbb{R}^{n}$ there is another equivalent,
        and perhaps more intuitive,
        definition of compactness. A subset of
        $\mathbb{R}^{n}$ is compact if and only if it
        is closed and bounded. A set
        $S\subseteq\mathbb{R}$ is closed if for
        all convergent sequences
        $x:\mathbb{N}\rightarrow{S}$,
        the limit also lies in $S$.
        Compactness will be discussed later in the
        context of continuous functions on a compact set.
        \begin{example}
            \begin{subequations}
                Find a subsequence $k$ of the identity
                $x:\mathbb{N}\rightarrow\mathbb{R}$
                defined by $x_{n}=n$ for which
                both $\sin(x\circ{k})$ and $\cos(x\circ{k})$
                converge. First note that for any subsequence
                $k$, $(x\circ{k})(n)=k_{n}$.
                In degrees this is simple:
                \begin{equation}
                    k_{n}=360n+45
                    \Rightarrow
                    \sin(k_{n})=\cos(k_{n})
                    =\frac{1}{\sqrt{2}}
                \end{equation}
                In radians we need to be a little more careful.
                Let $y:\mathbb{N}\rightarrow\mathbb{R}$
                be defined by $y_{n}=\sin(n)$.
                Then $y$ is bounded and
                by the Bolzano-Weierstrass theorem,
                there is a convergent subsequence $k$.
                Let $z:\mathbb{N}\rightarrow\mathbb{R}$
                be defined by $z_{n}=\cos(k_{n})$. Then $z$
                is bounded and by the
                Bolzano-Weierstrass theorem there is a
                convergent subsequence $j$. Let $k_{j}$
                denote the subsequence $k\circ{j}$. But
                any subsequequence of a convergent sequence
                converges to the same limit, and therefore
                $\sin(k_{j})$ is a convergent sequence. Thus,
                $\sin(k_{j})$ and $\cos(k_{j})$ are
                convergent sequences. It's also
                possible to make them converge to the same
                limit. We need to know that
                $\{n\mod\alpha:n\in\mathbb{N}\}$ is dense
                in $(0,\alpha)$ when $\alpha$ is irrational.
                Thus there is a subsequence such that
                $k_{n}\mod2\pi\rightarrow\pi/4$.
                Then $\sin(k_{n})$ and $\cos(k_{n})$
                both converge to $1/\sqrt{2}$.
                Let's first try to find a subsequence such that
                $\cos(k_{n})\rightarrow{1}$. If we can
                do that, we simply need to modify the
                argument so that
                $\cos(k_{n})\rightarrow{1}/\sqrt{2}$.
                Let $k$ be a sequence of integers
                such that $0<n-2\pi{k_{n}}<2\pi$.
                Let $\varepsilon>0$ and let $N\in\mathbb{N}$
                be such that $N>\frac{2\pi}{\varepsilon}$.
                Now consider the set:
                \begin{equation}
                    A_{N}=\{n-2\pi{k_{n}}:n=1,2,\hdots,N+1\}
                \end{equation}
                Then $A_{N}$ has $N+1$ elements and by the
                pidgeon-hole principle there are
                elements that are within
                $2\pi/\frac{2\pi}{\varepsilon}$ of each other.
                Let $n_{1}$ and $n_{2}$ be such numbers.
                Then:
                \begin{align}
                    \cos(n_{2}-n_{1})
                    &=\cos(n_{2}-n_{1}-2\pi(k_{2}-k_{1}))\\
                    &=\cos((n_{2}-2\pi{k}_{2})
                           -(n_{1}-2\pi{k_{1}}))\\
                    &=\cos(\xi)
                \end{align}
                Where $\xi$ is a number such that
                $0<|\xi|<\varepsilon$. But then
                $|1-\cos(\xi)|<\frac{\varepsilon^{2}}{2}$.
                And $n_{2}-n_{1}$ is a natural number,
                so we can find a subsequence $k$ such
                that $\cos(k_{n})\rightarrow{1}$. Modifying
                this with $\pi/4$
                and $1/\sqrt{2}$ gives the result.
            \end{subequations}
        \end{example}
        \begin{theorem}
            If $x:\mathbb{N}\rightarrow\mathbb{R}$ is
            a Cauchy sequence, then it converges.
        \end{theorem}
        \begin{proof}
            If $x$ is Cauchy, then it is bounded.
            By the Bolzano-Weiestrass theorem there
            is a convergent subsequence $k$. But then there
            is an $a\in\mathbb{R}$ such that
            $x_{k_{n}}\rightarrow{a}$. We now must show that
            $x_{n}\rightarrow{a}$. Let $\varepsilon>0$
            be given. As $x_{k_{n}}\rightarrow{a}$,
            there is an $N_{1}\in\mathbb{N}$ such
            that for all $n>N_{1}$,
            $|x_{k_{n}}-a|<\frac{\varepsilon}{2}$.
            But as $x$ is a Cauchy sequence, there
            is an $N_{2}$ such that for all $n,m>N_{2}$, 
            $|x_{n}-x_{m}|<\frac{\varepsilon}{2}$. Let
            $N=\max\{N_{1},N_{2}\}$. 
            But $k$ is a subsequence, and thus for all
            $n>N$, $k_{n}>N$. But then if $n>N$,
            $|x_{k_{n}}-x_{n}|<\frac{\varepsilon}{2}$.
            By the triangle inequality,
                $|a-x_{n}|\leq
                 |a-x_{k_{n}}|+|x_{k_{n}}-x_{n}|\leq
                 \frac{\varepsilon}{2}+
                 \frac{\varepsilon}{2}%
                 =\varepsilon$.
        \end{proof}
        Real numbers can be constructed by considering
        \textit{equivalence classes} of Cauchy sequences of
        rational numbers. Two Cauchy sequences $x_{n}$ and
        $y_{n}$ are equivalent if $x_{n}-y_{n}\rightarrow{0}$.
        By considering the set
        of all such equivalent sequences, we can give a more
        rigorous construction of the real numbers.
        \begin{example}
            \begin{subequations}
                Let $x:\mathbb{N}\rightarrow\mathbb{Q}$
                be the sequence:
                \begin{equation}
                    x_{n}=\frac{2n+3}{n}
                \end{equation}
                Let $\varepsilon>0$ and let
                $N=\ceil{6/\varepsilon}+1$.
                Then, for $n,m>N$, we have:
                \begin{equation}
                    |x_{n}-x_{m}|=
                    \Big|\frac{2n+3}{n}-\frac{2m+3}{m}\Big|
                    =3\Big|\frac{n-m}{nm}\Big|
                    <\frac{6}{\min\{n,m\}}
                    <\frac{6}{N}<\varepsilon
                \end{equation}
                Therefore $x$ is a Cauchy sequence of rational
                numbers. It has a standard representation
                of 2 since $x_{n}\rightarrow{2}$. To see this:
                \begin{equation}
                    \Big|2-\frac{2n+3}{n}\Big|
                    =\Big|\frac{3}{n}\Big|\rightarrow{0}
                \end{equation}
                There are other elements of the equivalence
                class for 2. Indeed the sequence
                $x:\mathbb{N}\rightarrow\mathbb{Q}$ defined
                by $x_{n}=2$ for all $n\in\mathbb{N}$ is
                such an example. The equivalence classes
                also define the irrational numbers as well.
                For let $x:\mathbb{N}\rightarrow\mathbb{Q}$
                be defined by:
                \begin{equation}
                    x_{n}=\sum_{k=0}^{n}\frac{(-1)^{k}}{n!}
                \end{equation}
                The ratio test, or the alternating series
                test, can be applied to show that this
                converges. Convergent sequences are Cauchy
                sequence, and thus $x$ can be used to
                represent some real number. The number it
                represents is $e^{-1}$, which is irrational.
                If one recalls the history of $e$, we know
                that the equivalence class for $e^{-1}$ also
                contains the following sequence:
                \begin{equation}
                    x_{n}=\Big(1-\frac{1}{n}\Big)^{n}
                \end{equation}
            \end{subequations}
        \end{example}
        We have seen that the least upper bound axiom,
        together with the ordered field structure that
        $\mathbb{R}$ possesses, implies that
        Cauchy sequence in $\mathbb{R}$ converge. This can
        be reversed, showing that we now have two equivalent
        definitions of completeness.
        \begin{theorem}
            If $x:\mathbb{N}\rightarrow\mathbb{R}$
            is a bounded monotonic sequence, then
            $x$ is a Cauchy sequence.
        \end{theorem}
        \begin{proof}
            For suppose not. Suppose $x$ is monotonically
            increasing. If $x$ is not Cauchy
            then there exists an $\varepsilon>0$ such
            that, for all $N\in\mathbb{N}$ there exists
            $n,m>N$ such that
            $|x_{n}-x_{m}|\geq\varepsilon$. But if
            $x$ is bounded, there is an $s$ such that,
            for all $n\in\mathbb{N}$, $|x_{n}|\leq{s}$.
            From the Archimedean principle, as
            $\varepsilon>0$ there is an $N_{1}\in\mathbb{N}$
            such that $x_{1}+N_{1}\varepsilon>s$.
            Let $X=\{x_{n}:n\in\mathbb{N}\}$.
            For all $N\in\mathbb{N}$, $N\geq{2}$,
            there exists a function
            $z:\mathbb{Z}_{N}\rightarrow{X}$ such that, for
            all $n\in\mathbb{Z}_{N-1}$,
            $z_{n}<z_{n+1}$, and
            $\min(\{|z_{n}-z_{m}|:n,m\in\mathbb{Z}_{N}\})%
             \geq\varepsilon$. By induction,
            let $z_{1}=x_{1}$. As $x$ is not Cauchy, there
            are $n,m>1$ such that
            $|x_{n}-x_{m}|\geq\varepsilon$. But from
            monotonicity, $x_{m}\geq{x}_{1}$, and thus
            $|x_{n}-x_{1}|\geq\varepsilon$.
            Let $z_{2}=x_{n}$. Suppose it is true for
            $N\in\mathbb{N}$. Let
            $z:\mathbb{Z}_{N}\rightarrow{X}$ be such a
            function. As $x$ is not Cauchy and
            monotonic, there is an $n>N$ such that
            $|x_{n}-z_{N}|\geq\varepsilon$.
            Let $z':\mathbb{Z}_{N+1}\rightarrow{X}$
            be defined by:
            \begin{subequations}
                \begin{equation}
                    z'_{k}=
                    \begin{cases}
                        z_{k},&1\leq{k}\leq{N}\\
                        x_{n},&k=N+1
                    \end{cases}
                \end{equation}
                From monotonicity, for all
                $n\in\mathbb{Z}_{N}$,
                $z'_{N+1}-z'_{n}\geq\varepsilon$. Moreover,
                $z'_{N+1}>z'_{N}$. Thus $z'$
                satisfies the criterion.
                Thus, there is a function
                $z:\mathbb{Z}_{N_{1}+1}\rightarrow{X}$
                such that $z$ is increasing and
                $\min(\{|z_{n}-z_{m}|:%
                        n,m\in\mathbb{Z}_{N_{1}}\})%
                 \geq\varepsilon$.
                 But then:
                \begin{equation}
                    z_{N_{1}+1}-z_{1}=
                    \sum_{n=1}^{N_{1}}(z_{n+1}-z_{n})
                    \geq{N}_{1}\varepsilon
                \end{equation}
                But then:
                \begin{equation}
                    z_{N_{1}+1}>z_{1}+N_{1}\varepsilon
                \end{equation}
                But $z_{1}\in{X}$, and thus
                $z_{1}\geq{x}_{1}$. But then
                $z_{N_{1}+1}>x_{1}+N\varepsilon$. But
                $s<x_{1}+N\varepsilon$, a contradiction
                as $s\geq{x}_{n}$ for all $n\in\mathbb{N}$.
                Therefore, $x$ is Cauchy.
            \end{subequations}
        \end{proof}
        This shows that the monotone convergence theorem
        can be proved without the least upper bound principle.
        The proof becomes messier, however. We now prove
        the equivalence of completeness and the least upper
        bound axiom.
        \begin{theorem}
            If every Cauchy sequence in $\mathbb{R}$
            is a convergent sequence, then every
            bounded above subset of $\mathbb{R}$ has a
            least upper bound.
        \end{theorem}
        \begin{proof}
            For if $L\subseteq\mathbb{R}$ is non-empty and
            bounded then there is an $a\in{L}$ and an
            $s\in\mathbb{R}$ such that, for all
            $y\in{L}$, $y\leq{s}$. If $s\in{L}$, then
            $s$ is a least upper bound of $L$. Suppose not.
            Let
            $S=\{y\in\mathbb{R}:\forall_{x\in{L}}x\leq{y}\}$.
            Then $S$ is non-empty, as $s\in{S}$.
            Suppose $s$ is not the least upper bound of $L$
            and define the following:
            \begin{subequations}
                \begin{equation}
                    A_{k}
                    =\Big\{s-\frac{n}{2^{k}}:
                           n\in\mathbb{N}\Big\}
                    \bigcap{S}
                \end{equation}
                There exists an $N\in\mathbb{N}$ such that, for
                all $k>N$, $A_{k}\ne\emptyset$, for otherwise
                $s$ would be a least upper bound. Moreover, for
                all $k>N$, $A_{k}$ is finite for by the
                Archimedean property there is an
                $n\in\mathbb{N}$ such that $s-n/2^{k}<x$,
                and thus for all $m>n$,
                $s-m/2^{k}\notin{A_{k}}$.
                Lastly, $A_{k}\subseteq{A_{k+1}}$. Let
                $x:\mathbb{N}\rightarrow\mathbb{R}$
                be defined by:
                \begin{equation}
                    x_{n}=\min(A_{n+N})
                \end{equation}
            \end{subequations}
            This is well defined since, for all
            $n>N$, $A_{n}$ is finite. Then, since
            $A_{n}\subseteq{A_{n+1}}$ for all
            $n>N$, $x$ is a monotonically decreasing
            sequence. But then $x$ is monotonic and
            bounded, and is therefore Cauchy. But Cauchy
            sequences converge, and thus there is a
            $c\in\mathbb{R}$ such that
            $x_{n}\rightarrow{c}$. For all $y\in{L}$,
            $y\leq{c}$. For if there is a
            $y\in{L}$ such that $c<y$, then there is an
            $N$ such that $x_{N}<y$, a contradiction as
            $x_{N}\in{S}$. Thus, $c$ is an upper bound of $L$.
            Suppose $c$ is not
            the least upper bound, and thus there is a
            $d\in{S}$ such that $d<c$. But then there is an
            $k\in\mathbb{N}$ such that $c-d<2^{-k}$. But
            then $x_{k+1}<c$, a contradiction as $x$
            is monotonically decreasing and
            $x_{n}\rightarrow{c}$. Thus, $c$ is the least
            upper bound.
        \end{proof}
        We've now used the Archimedean property twice. This
        says that for any $\varepsilon>0$ and any
        $x>0$, there is an $N\in\mathbb{N}$ such that
        $N\varepsilon>x$. It is equivalent to saying the
        real numbers have no ``infinitesimals.'' We now
        have two ways to talk about the completeness of
        $\mathbb{R}$. The monotone convergence theorem
        can also be taken as axiom, and shown that it
        implies completeness, as well as the
        Bolzano-Weierstrass theorem. Lastly, there is the
        Nested Interval Theorem which will be proved later
        in the context of more general metric spaces.
    \subsection{Inequalities}
        \begin{definition}
            H\"{o}lder Conjugates are non-zero real numbers
            $p$, $q\in\mathbb{R}$ where:
            \begin{equation}
                p^{-1}+q^{-1}=1
            \end{equation}
        \end{definition}
        \begin{theorem}[Young's Inequality]
            If $x,y\geq{0}$, $p>1$, and if $p$ and $q$
            are H\"{o}lder Conjugates, then:
            \begin{equation}
                xy\leq{\frac{1}{p}x^{p}+\frac{1}{q}y^{q}}
            \end{equation}
        \end{theorem}
        \begin{proof}
            If $x$ or $y$ are zero, then we are done.
            Suppose $x,y>0$. Let $t=p^{-1}$. As $p$ and
            $q$ are H\"{o}lder Conjugates,
            $1-t=q^{-1}$. But then, as $p>1$,
            $t$ and $1-t$ are positive, and thus:
            \begin{equation}
                \ln(tx^{p}+(1-t)y^{q})
                \geq{t}\ln(x^{p})+(1-t)\ln(y^{q})
                =\ln(x)+\ln(y)=\ln(xy)
            \end{equation}
            Where the inequality comes from the fact
            that $\ln$ is a concave function.
            Exponentiating completes the proof.
        \end{proof}
        There is another way to prove this without using
        the concavity of the logarithmic function.
        Let $y>0$ and define $f:(0,\infty)$ by:
        \begin{subequations}
            \begin{equation}
                f(x)=p^{-1}x^{p}-xy
            \end{equation}
            Then, differentiating, we have:
            \begin{equation}
                f'(x)=x^{p-1}-y
            \end{equation}
            This has an extremum at
            $x=y^{\frac{1}{p-1}}$. We also have:
            \begin{equation}
                f''(x)=(p-1)x^{p-2}
            \end{equation}
            And this is positive for all $x\in(0,\infty)$,
            and thus $y^{\frac{1}{p-1}}$ is a global minimum.
            Using the fact that $p$ and $q$ are
            H\"{o}lder Conjugates, we have:
            \begin{equation}
                \frac{1}{p-1}=q-1
            \end{equation}
            Applying some algebra obtains the result. We
            also see that equality happens when
            $x^{p}=y^{q}$.
        \end{subequations}
        For $p=q=2$ this is easy, for:
        \begin{equation*}
            0\leq\frac{(x-y)^{2}}{2}=
            \frac{x^{2}+y^{2}}{2}-xy
        \end{equation*}
        Using this, we can prove the Peter-Paul inequality:
        \begin{theorem}[Peter-Paul Inequality]
            If $x,y\in\mathbb{R}$ and $\varepsilon>0$,
            then:
            \begin{equation}
                ab\leq
                \frac{x^{2}}{2\varepsilon}+
                \frac{\varepsilon{y}^{2}}{2}
            \end{equation}
        \end{theorem}
        \begin{proof}
            For we have:
            \begin{equation}
                0\leq\Big(\frac{x}{\sqrt{\varepsilon}}-
                \varepsilon{y}\Big)^{2}
                =\frac{x^{2}}{\varepsilon}-2xy+
                \varepsilon{y}^{2}
            \end{equation}
            Bringing $2xy$ to the left side and dividing
            by 2 completes the proof.
        \end{proof}
        \begin{theorem}[H\"{o}lder's Inequality]
            If $a:\mathbb{N}\rightarrow\mathbb{R}$ and
            $b:\mathbb{N}\rightarrow\mathbb{R}$
            are nonnegative
            sequences, $p>1$, and if $p$ and $q$ are
            H\"{o}lder Conjugates, then:
            \begin{equation}
                \sum_{n=1}^{\infty}a_{n}b_{n}\leq
                \bigg(\sum_{n=1}^{\infty}a_{n}^{p}\bigg)^{1/p}
                \bigg(\sum_{n=1}^{\infty}b_{n}^{q}\bigg)^{1/q}
            \end{equation}
        \end{theorem}
        \begin{proof}
            If $\sum_{n=1}^{\infty}a_{n}b_{n}=0$, then
            $a$ and $b$ are both the zero sequence and
            we are done. Suppose the sum is positive.
            If either $\sum_{n=1}^{\infty}a_{n}^{p}$
            or $\sum_{n=1}^{\infty}b_{n}^{q}$ diverges,
            then the must diverge to $+\infty$ since
            $a$ and $b$ are non-negative sequences, and
            we would again be done. Suppose they both
            converge. Define the following:
            \par\hfill\par
            \begin{subequations}
                \begin{minipage}[b]{0.49\textwidth}
                    \begin{equation}
                        A=\bigg(\sum_{n=1}^{\infty}
                            a_{n}^{p}\bigg)^{1/p}
                    \end{equation}
                \end{minipage}
                \hfill
                \begin{minipage}[b]{0.49\textwidth}
                    \begin{equation}
                        B=\bigg(\sum_{n=1}^{\infty}
                            b_{n}^{q}\bigg)^{1/q}
                    \end{equation}
                \end{minipage}
                \par\hfill\par
                Then, by Young's inequality,
                for all $n\in\mathbb{N}$:
                \begin{equation}
                    \frac{a_{n}b_{n}}{AB}
                    \leq
                    \frac{1}{p}\Big(\frac{a_{n}}{A}\Big)^{p}+
                    \frac{1}{q}\Big(\frac{b_{n}}{B}\Big)^{q}
                \end{equation}
                Summing both sides, we have:
                \begin{equation}
                    \frac{1}{AB}\sum_{n=1}^{\infty}a_{n}b_{n}
                    \leq\frac{1}{p}+\frac{1}{q}=1
                \end{equation}
                As $p$ and $q$ are H\"{o}lder Conjugates.
                Multiplying by $AB$ proves the result.
            \end{subequations}
        \end{proof}
        When $p=q=2$ this is often
        called the Cauchy-Schwartz inequality.
        That is,
        $|\mathbf{a}\cdot\mathbf{b}|%
         \leq\norm{\mathbf{a}}\norm{\mathbf{b}}$.
        It holds for the integrals of continuous
        functions, as well as for sequences.
        \begin{theorem}[Minkowski's Inequality]
            If $a:\mathbb{N}\rightarrow\mathbb{R}$
            and $b:\mathbb{N}\rightarrow\mathbb{R}$ are
            non-negative sequences, and if $p>1$,
            then:
            \begin{equation*}
                \bigg(
                    \sum_{n=1}^{\infty}(a_{n}+b_{n})
                \bigg)^{1/p}
                \leq
                \bigg(
                    \sum_{n=1}^{\infty}a_{n}^{p}
                \bigg)^{1/p}
                +
                \bigg(
                    \sum_{n=1}^{\infty}b_{n}^{p}
                \bigg)^{1/p}
            \end{equation*}
        \end{theorem}