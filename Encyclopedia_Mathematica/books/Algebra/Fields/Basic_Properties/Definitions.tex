\section{Definitions}
    \begin{fdefinition}{Fields}{Fields}
        A field is a set $F$ with two operations $+$ and $\cdot$, denoted $\langle F, +,\cdot \rangle$, with the following properties:
        \begin{enumerate}
            \item   $a+b=b+a$
                    \hfill[Addition is Commutative]
            \item   $a+(b+c)=(a+b)+c$
                    \hfill[Addition is Associative]
            \item   $a\cdot{b}=b\cdot{a}$
                    \hfill[Multiplication is Commutative]
            \item   $a\cdot(b\cdot{c})=(a\cdot{b})\cdot{c}$
                    \hfill[Multiplication is Associative]
            \item   There is a $0\in{F}$ such that $0+a=a$ for all $a\in{F}$
                    \hfill[Existence of Additive Identity]
            \item   There is a $1\in{F}$ such that $1\cdot{a}=a$.
                    \hfill [Existence of Multiplicative Identity]
            \item   For each $a\in{F}$ there is a $b\in{F}$ such that $a+b=0$.
                    $b$ is denoted $\minus{a}$
                    \hfill[Existence of Additive Inverses]
            \item   For each $a\in{F}$, $a\ne{0}$ there is a $b\in{F}$ such that
                    $a\cdot{b}=1$. $b$ is denoted $a^{\minus{1}}$.
                    \hfill[Existence of Multiplicative Inverses]
            \item   $a\cdot(b+c)=a\cdot{b}+a\cdot{c}$
                    \hfill[Distributive Property]
        \end{enumerate}
    \end{fdefinition}
    \begin{fdefinition}{Subfield}{Subfield}
        A subfield of a field $(F,+,\cdot)$ is a set $K\subset F$, such that
        $(K,+,\cdot)$ is a field.
    \end{fdefinition}
    \begin{theorem}
        In a field, $0$ and $1$ are unique.
    \end{theorem}
    \begin{proof}
        For suppose not, and let $0'$ and $1'$ be other identities.
        Then $1'=1'\cdot 1 = 1$ and $0'=0'+0=0$.
    \end{proof}
    \begin{theorem}
        For any field $\langle{F},+,\cdot\rangle$ and $a\in{F}$, $a\cdot{0}=0$.
    \end{theorem}
    \begin{proof}
        For:
        \begin{equation}
            0=a\cdot{0}+(\minus{a}\cdot{0})
             =a\cdot(0+0)+(\minus{a}\cdot{0})
             =a\cdot{0}+a\cdot{0}+(\minus{a}\cdot{0})
             =a\cdot 0
        \end{equation}
        Thus, $a\cdot{0}=0$.
    \end{proof}
    If $1=0$, then $a=a\cdot{1}=a\cdot{0}=0$, and thus every element is
    zero. A very boring field.
    \begin{theorem}
        In a field $\langle F, +,\cdot \rangle$, if $0\ne 1$, then $0$ has no
        inverse.
    \end{theorem}
    \begin{proof}
        For let $a$ be such an inverse. Then $a\cdot{0}=1$. But for any element
        of $F$, $a\cdot{0}=0$. But $0\ne{1}$, a contradiction.
    \end{proof}
    \begin{theorem}
        If $a+b=0$, then $b=(\minus{1})\cdot{a}$ where $(\minus{1})$ is the
        solution to $1+(\minus{1})=0$.
    \end{theorem}
    \begin{proof}
        $a+(\minus{1})a=a(1+(\minus{1}))=a\cdot{0}=0$. From uniqueness,
        $b=(\minus{1})a$. We may thus write additive inverses as $\minus{a}$.
    \end{proof}
    \begin{definition}
        Given two fields $(F,+,\cdot)$ and $(F',+',\times)$, a bijection
        function $f:F\rightarrow{F}'$ is said to be a field isomorphism if and
        only if for allelements $a,b\in{F}$, $f(a+b)=f(a)+'f(b)$, and
        $f(a\cdot{b})=f(a)\times{f}(b)$
    \end{definition}
    \begin{definition}
        $(F,+,\cdot)$ and $(F',+',\times)$, are said to be isomorphic if and
        only if they have an isomorphism.
    \end{definition}
    \begin{theorem}
        Given an ismorphism between two fields $(F,+,\cdot)$ and
        $(F', +',\times)$, $f(1)=1'$ and $f(0)=0'$.
    \end{theorem}
    \begin{proof}
        For let $x\in{F}$. Then $f(x)=f(x\cdot 1)=f(x)\times{f}(1)$, and
        $f(x)=f(x+0)=f(x)+'f(0)$. Therefore, etc.
    \end{proof}
    \begin{theorem}
        In a field $(F,+,\cdot)$, $(a+b)^{2}=a^{2}+2ab+b^{2}$
        ($2$ being the solution to $1+1$).
    \end{theorem}
    \begin{proof}
        For:
        \begin{align}
            (a+b)^{2}&=(a+b)(a+b)\\
                     &=a(a+b)+b(a+b)\\
                     &=a^{2}+ab+ba+b^{2}\\
                     &=a^{2}+ab(1+1)+b^{2}\\
                     &=a^{2}+2ab+b^{2}
        \end{align}
    \end{proof}