\documentclass[../main.tex]{subfiles}
\begin{document}
\subsection{Geometry, Algebra, and Algorithms}
%
This section introduces the basic ideas of the book. Affine varieties are studied, as well as ideals in the polynomial ring $k[x_1,\hdots ,x_n]$. Finally, polynomials in one variable are studied to introduce the role of algorithms.

\subsubsection{Polynomials and Affine Space}
%
To link algebra and geometry, we will study polynomials over a field. Fields are important because linear algebra works over any field $k$. There are three particular fields that will be used the most:
%
\begin{enumerate}
\item $\mathbb{Q}$: This field is used for computer examples.
\item $\mathbb{R}$: This field is used for drawing pictures of curves and surfaces.
\item $\mathbb{C}$: This field is used for proving many theorems.
\end{enumerate}
%
\begin{definition}
A monomial in $x_1,\hdots, x_n$ is a product of the form $x_1^{\alpha_1} \cdots x_n^{\alpha_n}$, where $\alpha_1,\hdots, \alpha_n \in \mathbb{N}_0$
\end{definition}
%
\begin{definition}
The total degree of a monomial $x_1^{\alpha_1}\cdots x_n^{\alpha_n}$ is the sum $\alpha_1+\hdots + \alpha_n$.
\end{definition}
%
\begin{notation}
For $\alpha_1,\hdots, \alpha_n\in \mathbb{N}_0$, let $\alpha = (\alpha_1,\hdots ,\alpha_n)$. We write $x_1^{\alpha_1} \cdots x_n^{\alpha_n}=x^\alpha$. When $\alpha = (0,\hdots, 0)$, $x^\alpha = 1$.
\end{notation}
%
\begin{definition}
A polynomial $f$ in $x_1,\hdots, x_n$ with coefficients in $k$ is a finite linear combination of monomials.
\end{definition}
%
\begin{notation}
The set of all polynomials in $n$ variables with coefficients in $k$ is denoted $k[x_1,\hdots ,x_n]$.
\end{notation}
%
\begin{definition}
For a polynomial $f = \sum_{\alpha} a_\alpha x^\alpha \in k[x_1,\hdots ,x_n]$, $a_\alpha$ is called the coefficient of $x^\alpha$.
\end{definition}
%
\begin{definition}
For a polynomial $f=\sum_{\alpha} a_\alpha x^\alpha \in k[x_1,\hdots ,x_n]$, a term is a product $a_\alpha x^\alpha$ where $a_\alpha \ne 0$.
\end{definition}
%
\begin{definition}
For a polynomial $f=\sum_{\alpha}a_\alpha x^\alpha$, the total degree, denoted $\deg(f)$, is $\deg(f) = \max\{|\alpha|:a_\alpha \ne 0\}$
\end{definition}
%
\begin{definition}
The zero polynomial is the polynomial with all zero coefficients.
\end{definition}
%
\begin{theorem}
The sum and product of two polynomials in $k[x_1,\hdots ,x_n]$ is a again a polynomial in $k[x_1,\hdots ,x_n]$.
\end{theorem}
%
\begin{definition}
For polynomials $f,g\in k[x_1,\hdots ,x_n]$, $f$ divides $g$ if and only if $\exists_{h\in k[x_1,\hdots ,x_n]}$ such that $g = fh$.
\end{definition}
%
\begin{theorem}
For all $n\in \mathbb{N}$, $k[x_1,\hdots ,x_n]$ is a commutative ring.
\end{theorem}
%
\begin{remark}
Because of this we call $k[x_1,\hdots ,x_n]$ a polynomial ring.
\end{remark}
%
\begin{definition}
The $n-$dimensional affine space over a field $k$ is the set $k^n = \{(a_1,\hdots, a_n):a_1,\hdots,a_n \in k\}$.
\end{definition}
%
A polynomial $f\in k[x_1,\hdots ,x_n]$ defines a function $f:k^n \rightarrow k$. Given $a=(a_1,\hdots, a_n) \in k^n$, we replace $x$ with $a$ and compute the sum. 
%
\begin{definition}
A zero function $f:k^n \rightarrow k$ is a function such that $f(x) = 0$ for all $x\in k^n$.
\end{definition}
%
A zero function and the zero polynomial are not necessarily the same thing. That is there are fields $k$ with non-zero polynomials, but such that the polynomial evaluates to zero at every point.
%
\begin{theorem}
There exists fields $k$ and $f\in k[x]$ such $f$ is not the zero polynomial, yet $\forall_{a\in k}$ $f(a) = 0$.
\end{theorem}
%
\begin{theorem}
If $k$ is an infinite field, $f\in k[x_1,\hdots ,x_n]$, then $f$ is a zero function if and only if it is the zero polynomial.
\end{theorem}
%
\begin{theorem}
If $k$ is an infinite field and $f,g\in k[x_1,\hdots ,x_n]$, then $f=g$ if and only if $f:k^n\rightarrow k$ and $g:k^n \rightarrow k$ give the same function.
\end{theorem}
%
There is a special property for polynomials over the complex numbers $\mathbb{C}$.
%
\begin{theorem}
Every non-constant polynomial $f\in \mathbb{C}[x]$ has a root in $\mathbb{C}$.
\end{theorem}
%
\begin{definition}
An algebraically closed field is a field $k$ such that for every non-constant $f\in k[x]$, $\exists_{x\in k}: f(x)=0$.
\end{definition}
%
\subsubsection{Affine Varieties}
%
\begin{definition}
The affine variety of $f_1,\hdots, f_s \in k[x_1,\hdots ,x_n]$ is $\vf = \{x\in k^n:\forall_{1\leq i \leq s},f_i(x) = 0\}$
\end{definition}
%
The affine variety of a finite set of polynomials is the solution set of the system of equations $f_1(x) = \hdots = f_s(x) = 0$. 
%
\begin{example}
In $\mathbb{R}[x,y]$, $\mathbf{V}(x^2+y^2-1) \subset \mathbb{R}^2$ is the set of solutions ot $x^2+y^2-1 = 0$. This is the unit circle.
\end{example}
%
\begin{example}
The conic sections (Circles, ellipses, parabolas, and hyperbolas) are affine varieties. The graphs of rational functions are also affine varieties. For if $y = \frac{P(x)}{Q(x)}$, where $P,Q\in \mathbb{R}[x]$, then $\mathbf{V}\big(yQ(X)-P(X)\big)$ is an affine variety equivalent to that graph.
\end{example}
%
\begin{example}
The surfaces the represent affine varieties need not be smooth everywhere. Indeed, $\mathbf{V}(z^2-x^2-y^2)$ is the graph of a cone with its apex at the origin. As such, the surface obtained is not smooth at the origin. Such points are called singular points.
\end{example}
%
\begin{example}
The twisted cubic is the curve defined by the affine variety $(y-x^2,z-x^3)$. It has the parametrization $\{(t,t^2,t^3):t\in \mathbb{R}\}$.
\end{example}
%
The notion of dimension is very subtle. In previous examples, if we have $m$ polynomials in $\mathbb{R}^n$, we expect a surface of $n-m$ dimension. This is not always the case, however.
%
\begin{example}
$\mathbf{V}(xz,yz)$ is the set of solutions to $xy=yz = 0$. If $z = 0$, then any point $(x,y,0)\in \mathbb{R}^3$ satisfies this. If $z\ne 0$, then $x=y=0$ and thus and point $(0,0,z)\in \mathbb{R}^3$ is a solution. Thus we get $\mathbf{V}(xz,yz)$ is the union of the $xy-$plane and the $z-$axis. So $\mathbf{V}(xz,yz)$ is two dimension, not $1$ dimensional as we might expect.
\end{example}
%
\begin{definition}
A linear variety is an affine variety in which all of the defining polynomials are linear equations.
\end{definition}
%
\begin{example}
Let $k$ be a field and consider the following polynomials:
\begin{align*}
\nonumber a_{11}x_1+\hdots + a_{1n}x_n &= b_1 \\ \nonumber \vdots&  \\ \nonumber a_{m1}x_1+\hdots + a_{mn}x_n &= b_m
\end{align*}
From linear algebra we know that the method of Gaussian Elimination and row-reduction gives us the solution set of the system of equations. We also know that the dimension of the solutions set is $n-r$, where $r$ is the number of independent equations (Also known as the rank of the coefficient matrix). The dimension of an affine variety is also determined by the number of independent equations, however the term "Independent," is much more subtle.
\end{example}
%
\begin{example}
Find the maximum of $f(x,y,z) = x^3+2xyz-z^2$ subject to $g(x,y,z) = x^2+y^2+z^2=1$. From multivariable calculus, specifically the method of Lagrange Multipliers, we know this occurs when $\nabla(f) = \lambda \nabla(g)$, for some $\lambda \in \mathbb{R}$. This gives us the following:
\begin{align}
\nonumber x^2+2yz &= 2\lambda x\\
\nonumber 2xz &= 2\lambda y \\
\nonumber 2xy-2z &= 2\lambda z\\
\nonumber x^2+y^2+z^2 &= 1
\end{align}
Solving this via algebraic means can be a nightmare. Various algorithms can be used to solve this problem, however.
\end{example}
%
\begin{remark}
It is possible for an affine variety to be the empty set. Let $k = \mathbb{R}$, and $f = x^2+y^2+1$. Then $\mathbf{V}(f) = \emptyset$. That is, there is not solution to $x^2+y^2 = -1$.
\end{remark}
%
\begin{example}
Consider a robot arm. The "Armpit," is at the origin, and the "Elbow," is at the point $(x,y)\in \mathbb{R}^2$ where $x^2+y^2 = r^2$ (r is the length of "Bicep.") The "Hand," we then be at $(z,w)\in \mathbb{R}^2$ where $(x-z)^2 + (y-w)^2 = \ell^2$ ($\ell$ is the length of the "Forearm.") Not every point $(x,y,z,w)\in \mathbb{R}^4$ represents a possible position of the robot arm, there are the following constraints:
\begin{align}
\nonumber x^2+y^2 &= r^2 \\ 
\nonumber (x-z)^2+(y-z)^2 &= \ell^2
\end{align}
This solution set defines an affine variety in $\mathbb{R}^4$. If we allowed the arms to be in $\mathbb{R}^3$, the analogous solution set would be in $\mathbb{R}^6$.
\end{example}
%
\begin{theorem}
If $V,W\subset k^n$ are affine varieties, then so are $V\cup W$ and $V\cap W$. Moreover, the following are true:
\begin{enumerate}
\item $\vf \cap \vg = \mathbf{V}(f_1,\hdots, f_s,g_1,\hdots, g_t)$
\item $\vf \cup \vg = \mathbf{V}(f_i g_j: 1\leq i \leq s, 1\leq j\leq t)$
\end{enumerate}
\end{theorem}
%
\begin{example}
$\mathbf{V}(xz,yz) = \mathbf{V}(xy)\cup \mathbf{V}(z)$. We see that $\mathbf{V}(xz,yz)$ is the union of the $xy-$plane and the $z-$axis.
\end{example}
%
\begin{example}
The twisted cubic $\mathbf{V}(y-x^2,z-x^3)$ is the intersection $\mathbf{V}(y-x^2,z-x^3) = \mathbf{V}(y-x^2)\cap \mathbf{V}(z-x^3)$
\end{example}
%
Several problems arise concerning affine varieties
%
\begin{enumerate}
\item Can we determine if $\vf \ne \emptyset$? \hfill [Consistency]
\item Can we determine if $\vf$ is finite? \hfill [Finiteness]
\item Can we determine the "Dimension," of $\vf$?
\end{enumerate}
%
The answer to these questions is yes, although we must be careful in choosing the field $k$ we are working with. 
%
\subsubsection{Parametrizations of Affine Varieties}
%
We now arrive at the problem of describing all of the points in an affine variety. 

\begin{example}
Consider the system in $\mathbb{R}[x,y,z]$.
\begin{align*}
\nonumber x+y+z &= 1 \\
\nonumber x+2y-z &= 3
\end{align*}
From linear algebra we get the row echelon matrix $\begin{bmatrix}[1 & 0 & 3 & \vline & -1 \\ 0 & 1 & -2 & \vline & 2 \end{bmatrix}$. Letting $z=t$, we get $x = -3t-1$ and $y = 2+2t$. The parametrization of the affine variety is thus $\{(-3t-1,2t+2,t):t\in \mathbb{R}\}$. We call $t$ a parameter, and $(-3t-1,2t+2,t)$ a parametrization.
\end{example}

\begin{example}
Parametrize the unit circle $x^2+y^2=1$. The common way to do this is $\{(\cos(t),\sin(t)):t\in \mathbb{R}\}$. There are other ways. A rational way to do this is $\big(\frac{1-t^2}{1+t^2}, \frac{2t}{1+t^2}\big)$. This parametrizing the entire unit circle, with the exception of the point $(-1,0)$. This point is $\underset{t\rightarrow -\infty} \lim \big(\frac{1-t^2}{1+t^2},\frac{2t}{1+t^2}\big)$. So in a sense, $(-1,0)$ is a "Point at infinity."
\end{example}

\begin{definition}
A parametrization of an affine variety $\vf \subset k^n$ is a set of equations $x_k = f_k(t_1,\hdots, t_m)$, $1\leq k \leq n$, such that $ \{\big(f_1(t_1,\hdots, t_m),\hdots, f_n(t_1,\hdots, f_m)\big): t_1,\hdots, t_m \in \mathbb{R}\}\subset \vf$, and if $\{\big(f_1(t_1,\hdots, t_m),\hdots, f_n(t_1,\hdots, f_m)\big): t_1,\hdots, t_m \in \mathbb{R}\}\subset \vg$, then $\vf \subset \vg$.
\end{definition}

\begin{remark}
That is the the points $(x_1,\hdots, x_n)$, $x_k = f_k(t_1,\hdots, t_m)$, all lie in $\vf$, and $\vf$ is the smallest affine variety containing these points.
\end{remark}

\begin{definition}
A rational function over a field $k$ in $x_1,\hdots, x_n$ is a quotient $\frac{P(x)}{Q(x)}$: $P,Q \in k[x_1,\hdots ,x_n]$, $Q\ne 0$.
\end{definition}

\begin{definition}
$k(x_1,\hdots ,x_n)$ is the set of all rational functions over a field $k$ in $x_1,\hdots, x_n$.
\end{definition}

\begin{definition}
Two rational functions $\frac{P_1}{Q_1}, \frac{P_2}{Q_2} \in k(x_1,\hdots ,x_n)$ are equal if and only if $P_1Q_2 = P_2Q_1$.
\end{definition}

\begin{theorem}
If $k$ is a field, then $k(x_1,\hdots ,x_n)$ is a field.
\end{theorem}

\begin{definition}
A rational representation of an affine variety is a parametrization using only rational functions.
\end{definition}

\begin{definition}
A polynomial representation of an affine variety is a parametrization using only polynomials.
\end{definition}

\begin{remark}
Writing out an affine variety $V$ as $V=\vf$ is also called the implicit representation of $V$.
\end{remark}
%
There are two questions that arise from parametrization:
%
\begin{enumerate}
\item Does every affine variety have a rational parametric representation?
\item Given a parametric representation of an affine variety, can we find the implicit representation?
\end{enumerate}
%
The answers are: No the first question, yes to the second. Indeed, most affine varieties cannot be parametrized by rational functions.
%
\begin{example}
Find the affine variety parametrized by:
\begin{align}
\nonumber x &= 1+t \\
\nonumber y &= 1+t^2
\end{align}
We have that $t = x-1$, and thus $y = 1+(x-1)^2 = x^2-2x+2$.
\end{example}
%
\begin{remark}
The process described above involved eliminating the variable $t$ and creating a polynomial in $x$ and $y$. This illustrates the role played by elimination theory.
\end{remark}
%
\begin{example}
Let's parametrize the unit circle in a rational manner. Let $(x,y)$ be a point on the unit circle and draw a line from the point $(-1,0)$ to $(x,y)$. This line intersects the $y-$axis at some point $(0,t)$. We have that the slope of this line is $m = \frac{t-0}{0-(-1)} = \frac{y-0}{x-(-1)} = \frac{y}{x+1}$. So $y = t(x+1)$. But from the definition of the unit circle, $x^2+y^2=1$. So $x^2+t^2(x+1)^2 = 1$. From this we get $x^2(1+t^2)+2xt^2 + t^2 = 1 \Leftrightarrow x^2+x\frac{2t^2}{1+t^2} = \frac{1-t^2}{1+t^2} \Leftrightarrow (x+ \frac{t^2}{1+t^2})^2 = \frac{1 }{(1+t^2)^2}\Leftrightarrow x = \frac{-t^2 \pm 1}{1+t^2}$. But $x\in [-1,1]$, and thus we get $x = \frac{1-t^2}{1+t^2}$. But $y = t(x+1)$, and thus $y = \frac{2t}{1+t^2}$. The parametrization of the circle is $\big(\frac{1-t^2}{1+t^2},\frac{2t}{1+t^2}\big)$.
\end{example}
%
\begin{definition}
If $\Gamma:\mathbb{R}\rightarrow \mathbb{R}^n$, $\Gamma(t) = \mathbf{r}(t)$, is a smooth curve, then the tangent surface of $\Gamma$ is $\{\mathbf{r}(t)+u\mathbf{r}'(t):t,u\in \mathbb{R}\}$
\end{definition}
%
\begin{remark}
The tangent surface is obtained by taking the union of all of the tangent lines to every point on the curve. $t$ tells us which point on the curve we are one, and $u$ tells us how far along the tangent line we are.
\end{remark}
%
\begin{example}
The twisted cubic is the curve $\mathbf{r}(t) = (t,t^2,t^3)$. It has the tangent surface $\mathbf{r}+u\mathbf{r}'(t)=(t,t^2,t^3)+u(1,2t,3t^3) = (t+u,t^2+2ut,t^3+3ut^2)$. One question that arises is "Is this an affine variety? If so, what are the defining polynomials." The answer for this particular surface is yes. The graph of this surface is equal to $\mathbf{V}(-4x^3z+3x^2y^2-4y^3+6xyz-z^2)$.
\end{example}
%
An application of this is in the design of complex objects such as automobile hoods and airplane wings. Engineers need curves and surfaces that are easy to describe, quick to draw, and varied in shape. Polynomials and rational functions satisfy this criteria. Complicated curves are usually formed by joining together simpler curves. Suppose a design engineer needs to draw a curve in the plane. The curves in question need to join smoothly, and thus the tangent directions need to match at the endpoints. The engineer must control the following:
%
\begin{enumerate}
\item The starting and ending points of the curve.
\item The tangent directions at the starting and ending points.
\end{enumerate}
%
The B\'{e}zier Cubic does this.
%
\begin{definition}
The B\'{e}zier Cubic in $\mathbb{R}^2$ is defined by:
\begin{align}
x &= (1-t)^3 x_0+3t(1-t)^2x_1+3t^2(1-t)x_2+t^3x_3 \\
y &= (1-t)^2 y_0+3t(1-t)^2y_1+3t^2(1-t)y_2+t^3y_3
\end{align}
Where $x_0,x_1,x_2,x_3,y_0,y_1,y_2,y_3$ are input parameters.
\end{definition}
%
When $t=0$, we have $x = x_0, y=y_0$. Thus $(x_0,y_0)$ is the starting point. Similarly $(x_3,y_3)$ is the end point. The derivatives are:
\begin{align}
x' &= -3(1-t)^2x_0 + 3(1-t)(1-3t)x_1+3t(2-3t)x_2+3t^2x_3 \\
y' &= -3(1-t)^2y_0 + 3(1-t)(1-3t)y_1+3t(2-3t)y_2+3t^2y_3
\end{align}
%
So $(x'(0),y'(0)) = \big(3(x_1-x_0),3(y_1-y_0)\big)$ and $(x'(1),y'(1)) = \big(3(x_3-x_2),3(y_3-y_2)\big)$. Hence, choosing $x_1,x_2$ and $y_1,y_2$ carefully allows that designer to control the tangent of the curve at the endpoints. Moreover, choosing the point $(x_1,y_1)$ makes the tangent at $(x(0),y(0))$ point in the same direction as the line from $(x_0,y_0)$ to $(x_1,y_1)$. Similarly, choosing $(x_2,y_2)$ makes the tangent at $(x(1),y(1))$ point in the same direction as the line from $(x_2,y_2)$ to $(x_3,y_3)$.
%
\begin{definition}
The control polygon of a B\'{e}zier Cubic in $\mathbb{R}^2$ is the polygon formed by the lines $(x_0,y_0)\rightarrow(x_1,y_1)\rightarrow(x_2,y_2)\rightarrow(x_3,y_3)\rightarrow (x_0,y_0)$.
\end{definition}
%
Interestingly enough, the B\'{e}zier Cubic always lies inside the control polygon. The final thing to control is the length of the tangents at the endpoint. But from equations $1.3$ and $1.4$, the lengths are three times the distance from $(x_0,y_0)$ to $(x_1,y_1)$ and $(x_2,y_2)$ to $(x_3,y_3)$, respectively. 
%
\subsubsection{Ideals}
%
\begin{definition}
An ideal of a polynomial ring $k[x_1,\hdots ,x_n]$ is a set $I\subset k[x_1,\hdots ,x_n]$ such that:
\begin{enumerate}
\item $0\in I$
\item $\forall_{f,g\in I}, f+g\in I$ 
\item $\forall_{f\in I, h\in k[x_1,\hdots ,x_n]}, hf\in I$
\end{enumerate}
\end{definition}
%
\begin{definition}
The ideal generated by a set $\{f_1,\hdots, f_s\} \subset k[x_1,\hdots ,x_n]$ is the set $\langle f_1,\hdots, f_s\rangle = \{\sum_{i=1}^{s} h_i f_i:h_1,\hdots, h_s\in k[x_1,\hdots ,x_n]\}$.
\end{definition}

\begin{theorem}
If $f_1,\hdots, f_s\in k[x_1,\hdots ,x_n]$, then $\langle f_1,\hdots, f_s\rangle$ is an ideal.
\end{theorem}
%
\begin{remark}
The ideal $\langle f_1,\hdots, f_s\rangle$ has a nice interpretation. If $x\in k$ such that $f_1(x) = \hdots = f_s(x) = 0$, then for any set of polynomials $h_1,\hdots, h_s$, we have $h_1(x)f_1(x) = \hdots = h_s(x)f_s(x) = 0$, and adding the equations we get $h_1(x)f_1(x)+\hdots + h_s(x)f_s(x) = 0$. Thus we can think of $\langle f_1,\hdots, f_s\rangle$ as the set of all "Polynomial consequences," of the equations $f_1 = \hdots = f_s = 0$.
\end{remark}
%
\begin{example}
Consider the following system:
\begin{align}
\nonumber x &= 1+t \\
\nonumber y &= 1+t^2
\end{align}
We can eliminate $t$ to obtain $y = x^2-2x+2$. To see this, write
\begin{align}
x - 1 - t &= 0 \\
-y+1+t^2 &=0
\end{align}
Multiplying $(1.7)$ by $x-1+t$ and $(1.8)$ by $-1$ and then adding, we get $(x-1)^2-y+1 = 0$. Thus $y = x^2-2x+2$.
\end{example}
%
\begin{definition}
A finitely generated ideal $I\subset k[x_1,\hdots ,x_n]$ is an ideal such that there $\exists_{f_1,\hdots, f_s}: I = \langle f_1,\hdots, f_s\rangle$.
\end{definition}
%
\begin{definition}
A basis of an ideal $I\subset k[x_1,\hdots ,x_n]$ is a set $f_1,\hdots, f_s\in k[x_1,\hdots ,x_n]$ such that $I = \langle f_1,\hdots, f_s\rangle$.
\end{definition}
%
Hilbert's Basis Theorem, to be proved later, states that every ideal in $k[x_1,\hdots ,x_n]$ is finitely generated. An ideal in $k[x_1,\hdots ,x_n]$ is similar to a subspace in linear algebra. Both must be closed under multiplication and addition, except that in a subspace we multiply by scalars and in an ideal we multiply by polynomials. 
%
\begin{theorem}
If $f_1,\hdots, f_s ,g_1,\hdots, g_t \in k[x_1,\hdots ,x_n]$ and $\langle f_1,\hdots, f_s\rangle = \langle g_1,\hdots, g_t\rangle$, then $\vf = \vg$.
\end{theorem}
%
\begin{example}
It can be shown that $\langle2x^2+3y^2-11,x^2-y^2-3\rangle = \langle x^2-4,y^2-1\rangle$. Thus $\mathbf{V}(2x^2+3y^2-11,x^2-y^2-3) = \{(2,1),(-2,1),(2,-1),(-2,-1)\}$. Changing basis simplifies the problem.
\end{example}
%
\begin{definition}
The ideal of an affine variety $V \subset k^n$ is the set $\mathbf{I}(V)=\{f\in k[x_1,\hdots ,x_n]:f(x)=0\ \forall{x\in V}\}$
\end{definition}
%
\begin{theorem}
If $V\subset k^n$ is an affine variety, then $\mathbf{I}(V)$ is an ideal of $k[x_1,\hdots ,x_n]$.
\end{theorem}
%
\begin{theorem}
For any field $k$, $\mathbf{I}\big(\{(0,0)\}\big) = \langle x,y\rangle$.
\end{theorem}
%
\begin{theorem}
For any infinite field $k$, $\mathbf{I}(k^n) = \{0\}$.
\end{theorem}
%
\begin{theorem}
If $V = \mathbf{V}(y-x^2,z-x^3)\subset \mathbb{R}^3$, $f\in \mathbf{I}(V)$, then $\exists_{h_1,h_2,r(x)\in \mathbb{R}[x,y,z]}$ such that $f=h_1(y-x^2)+h_2(z-x^3)+r$.
\end{theorem}
%
\begin{theorem}
If $V = \mathbf{V}(y-x^2,z-x^3)\subset \mathbb{R}^3$, then $\mathbf{I}(V) = \langle y-x^2,z-x^3\rangle$
\end{theorem}
%
\begin{remark}
It is not always true that $\mathbf{I}(\vf) = \langle f_1,\hdots, f_s\rangle$.
\end{remark}
%
\begin{theorem}
If $f_1,\hdots, f_s \in k[x_1,\hdots ,x_n]$, then $\langle f_1,\hdots, f_s \rangle \subset \mathbf{I}(\vf)$.
\end{theorem}
%
\begin{theorem}
There exists fields $k$ and polynomials $f_1,\hdots, f_s\in k[x_1,\hdots ,x_n]$ such that $\langle f_1,\hdots,f_s\rangle \ne \mathbf{I}(\vf)$.
\end{theorem}
%
\begin{theorem}
If $k$ is a field and $V,W\subset k^n$ are affine varieties, then $V\subset W$ if and only if $\mathbf{I}(W)\subset \mathbf{I}(V)$.
\end{theorem}
%
\begin{theorem}
If $k$ is a field and $W,W\subset k^n$ are affine varieties, then $V=W$ if and only if $\mathbf{I}(W)=\mathbf{I}(V)$.
\end{theorem}
%
Three questions arise concerning ideals in $k[x_1,\hdots ,x_n]$.
\begin{enumerate}
\item Can every ideal $I\subset k[x_1,\hdots ,x_n]$ be written as $\langle f_1,\hdots, f_s\rangle$ for some $f_1,\hdots, f_s \in k[x_1,\hdots ,x_n]$?
\item If $f_1,\hdots, f_s\in k[x_1,\hdots ,x_n]$, is there an algorithm for deciding if $f\in k[x_1,\hdots ,x_n]$ lies in $\langle f_1,\hdots, f_s\rangle$?
\item Is there a relation between $\langle f_1,\hdots, f_s\rangle$ and $\mathbf{I}(\vf)$?
\end{enumerate}
%
\subsubsection{Polynomials in One Variable}
%
This section studies the division algorithm of polynomials in one variable. This can be used to explore the concept of greatest common divisor. 

\begin{definition}
The leading term of a polynomial $f = \sum_{k=1}^{n} a_kx^k \in k[x]$, where $a_n \ne 0$, is $\LT(f)=a_nx^n$. 
\end{definition}

\begin{example}
If $f = 2x^3-4x+3$, then $\LT(f) = 2x^3$.
\end{example}

\begin{theorem}
If $k$ is a field and $g\in k[x],g\ne 0$, then $\forall_{f\in k[x]}, \exists_{q,r\in k[x]}: f = qg+r$, where either $r=0$ or $\deg(r)<\deg(g)$. Furthermore, $q$ and $r$ are unique.
\end{theorem}

\begin{remark}
From the uniqueness of $r$, we call $r$ the remainder of $f$ with respect to $g$.
\end{remark}

\begin{theorem}
If $k$ is a field and $f\in k[x]$ is a non-zero polynomial, then $f$ has at most $\deg(f)$ roots.
\end{theorem}

\begin{definition}
A principal ideal is an ideal generated by a single element.
\end{definition}

\begin{theorem}
If $k$ is a field, then every ideal of $k[x]$ is principal.
\end{theorem}

\begin{theorem}
If $\langle f \rangle = \langle g$ are ideals in $k[x]$, then there is a constant $h$ such that $f=hg$.
\end{theorem}

\begin{definition}
A greatest common divisor of polynomials $f,g\in k[x]$ is a polynomial $h\in k[x]$ such that:
\begin{enumerate}
\item $h$ divides $f$ and $g$
\item For all $p\in k[x]$ such that $p$ divides $f$ and $g$, $p$ divides $h$.
\end{enumerate}
\end{definition}

\begin{theorem}
If $f,g\in k[x]$, then there is a greatest common divisor of $f$ and $g$.
\end{theorem}

\begin{theorem}
If $f,g\in k[x]$, and $h_1,h_2$ are greatest common divisors of $f$ and $g$, then there is a constant $c\in k$ such that $h_1 = ch_2$.
\end{theorem}

\begin{remark}
The Euclidean Algorithm is used for computational purposes to compute the greatest common divisor of two polynomials. Let $f,g\in k[x]$.
\begin{enumerate}
\item Let $h_1 = f$
\item Let $s_1 = g$
\item While $s_n \ne 0$, do the following:
\begin{enumerate}
\item $r_n = remainder(h_n,s_n)$
\item $h_{n+1} = s_n$
\item $s_{n+1} = r_n$
\end{enumerate}
\end{enumerate}
There is an $N\in \mathbb{N}$ such that for all $n>N$, $h_n = h_N$. Letting $h = h_N$, this is the greatest common divisor of $f$ and $g$. This comes from $GCD(f,g) = GCD(f-qg,g) = GCD(r,g)$ and the fact that $\deg(r)< \deg(g)$. So $\deg(r_{n+1})<\deg(r_n)$, and eventually $\deg(r_N) = 0$.
\end{remark}

\begin{definition}
A greatest common divisor of polynomials $f_1,\hdots, f_s \in k[x]$ is a polynomial $h\in k[x]$ such that $h$ divides $f_1,\hdots, f_s$ and if $p\in k[x]$ such that $p$ divides $f_1,\hdots, f_s$, then $p$ divides $h$.
\end{definition}

\begin{theorem}
If $f_1,\hdots, f_s\in k[x]$, then there is a polynomial $h\in k[x]$ that is a greatest common divisor of $f_1,\hdots, f_s$.
\end{theorem}

\begin{theorem}
If $f_1,\hdots, f_s\in k[x]$, and if $h$ is a greatest common divisor of $f_1,\hdots, f_s$, then $\langle h \rangle = \langle f_1,\hdots, f_s\rangle$
\end{theorem}
\end{document}