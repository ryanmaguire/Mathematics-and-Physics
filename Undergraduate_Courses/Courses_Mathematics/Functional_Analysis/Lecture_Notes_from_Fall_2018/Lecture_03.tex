\documentclass[crop=false,class=article,oneside]{standalone}
%----------------------------Preamble-------------------------------%
\input{../../../../preamble.tex}
%--------------------------Main Document----------------------------%
\begin{document}
    \ifx\ifsub\undefined
        \section*{Functional Analysis}
        \setcounter{section}{1}
        \setcounter{subsection}{1}
    \fi
    \subsection{Lecture 3: September 24, 2018}
        \subsubsection{Some notes on Homework 1}
            Try to find a subsequence of $n$ such
            that $\cos(k_{n})$ and $\sin(k_{n})$
            have the same limit. Let's first just
            try to find a subsequence such that
            $\cos(k_{n})\rightarrow{1}$. If we can
            do that, we simply need to modify the
            argument so that
            $\cos(k_{n})\rightarrow{\frac{1}{\sqrt{2}}}$.
            Let $k_{n}$ be a sequence of integers
            such that $0<n-2\pi{k_{n}}<2\pi$.
            Let $\varepsilon>0$ and let $N\in\mathbb{N}$
            be such that $N>\frac{2\pi}{\varepsilon}$.
            Then the set
            $\{n-2\pi{k_{n}}:n=1,2,\hdots,N+1\}$
            has $N+1$ elements, and thus by the
            pidgeonhole principle there are two
            elements that are within
            $2\pi/\frac{2\pi}{\varepsilon}$ of each other.
            Let $n_{1}$ and $n_{2}$ be such numbers.
            Then:
            \begin{equation*}
                \cos(n_{2}-n_{1})
                =\cos(n_{2}-n_{1}-2\pi(k_{2}-k_{1}))
                =\cos((n_{2}-2\pi{k}_{2})
                       -(n_{1}-2\pi{k_{1}})
                =\cos(\xi)
            \end{equation*}
            Where $\xi$ is a number such that
            $0<|\xi|<\varepsilon$. But then
            $|1-\cos(\xi)|<\frac{\varepsilon^{2}}{2}$.
            And $n_{2}-n_{1}$ is a natural number,
            so we can find a subsequence of $n$ such
            that $\cos(k_{n})\rightarrow{1}$. Modifying
            this with $\frac{\pi}{4}$
            and $\frac{1}{\sqrt{2}}$ gives the
            desired result.
        \subsubsection{Back to Metric Spaces}
            $X$ is a set and
            $d:{x}\times{X}\rightarrow[0,\infty)$
            is a function such that for all $x$, $y\in{X}$,
            $d(x,y)=0$ if and only if $x=y$,
            $d(x,y)=d(y,x)$, and for all
            $x$, $y$, $z\in{X}$,
            $d(x,z)\leq{d(x,z)+d(z,y)}$. It turns out
            that we can actually write the following:
            \begin{definition}
                A metric space is a set $X$ and a function
                $d:{X}\times{X}\rightarrow\mathbb{R}$
                such that:
                \begin{enumerate}
                    \item $d(x,y)=0$ if and only if
                          $x=y$.
                    \item $d(x,z)\leq{d(x,y)+d(z,y)}$
                \end{enumerate}
            \end{definition}
            By writing the triangle inequality in this
            way, symmetry comes for free
            (The fact that $d(x,y)=d(y,x)$), as well
            as positivity (The fact that $d(x,y)\geq{0}$).
            Since it's easier to prove two things are
            true, rather than four things, it's nice to
            take this as the definition of a metric space,
            and then prove that the two definitions are
            equivalent. Some examples of metric spaces:
            \begin{example}
                If $(X,\norm{})$ is a normed space,
                then $(X,d)$ is a metric space with
                the metric
                $d(\mathbf{x},\mathbf{y})%
                 =\norm{\mathbf{x}-\mathbf{y}}$.
            \end{example}
            \begin{example}
                $\mathbb{R}^{n}$ (for $1\leq{p}<\infty$):
                \begin{equation*}
                    d_{p}(\mathbf{x},\mathbf{y})=
                    \big(
                        \sum_{k=1}^{n}|x_{k}-y_{k}|
                    \big)^{1/p}
                    =\norm{\mathbf{x}-\mathbf{y}}_{p}
                \end{equation*}
            \end{example}
            \begin{example}
                In $\ell^{p}$, which are sequences for
                which
                $\sum_{k=1}^{\infty}|x_{k}|^{p}<\infty$,
                $d_{p}(x,y)$ forms a metric, as well
                as
                $d_{\infty}(x,y)=\sup\{|x_{k}-y_{k}|\}$,
                which is called the supremum norm.
            \end{example}
            \begin{example}
                $C(S,\mathbb{R})$, which is the
                set of continuous functions from
                $S$ to $\mathbb{R}$, letting
                $L^{p}(S)$ be the set of of functions
                such that:
                \begin{equation*}
                    \int_{S}|x(t)|^{p}<\infty
                \end{equation*}
                Then the following is a metric:
                \begin{equation*}
                    d_{p}(x,y)=
                    \bigg(
                        \int_{S}|x(t)-y(t)|^{p}dt
                    \bigg)^{1/p}
                \end{equation*}
                Also,
                $d_{\infty}(x,y)=\sup\{|x(t)-y(t)|\}$,
                which is called the supremum norm.
            \end{example}
            \begin{example}
                Let $C$ be the set of sequences such that
                $x_{n}\rightarrow{0}$. Then, with
                $d_{p}$, this forms a metric space.
                If $C_{0}$ is set of sequences with
                only finitely many non-zero terms,
                then
                $C_{0}\subset{C}\subset{\ell^{\infty}}$.
                Is there a sequence $x\in{C}$ such
                that, for all $1\leq{p}<\infty$,
                $x\notin{\ell^{p}}$.
            \end{example}
        \subsubsection{Inequality of Minkowski and Holder}
            \begin{theorem}
                For non-negative sequences
                $a_{n}$, $b_{n}$, and for $p>1$:
                \begin{equation*}
                    \bigg(
                        \sum_{n=1}^{\infty}(a_{n}+b_{n})
                    \bigg)^{1/p}
                    \leq
                    \bigg(
                        \sum_{n=1}^{\infty}a_{n}^{p}
                    \bigg)^{1/p}
                    +
                    \bigg(
                        \sum_{n=1}^{\infty}b_{n}^{p}
                    \bigg)^{1/p}
                \end{equation*}
            \end{theorem}
            This says that
            $\norm{a+b}_{p}\leq\norm{a}_{p}+\norm{b}_{p}$.
            Which says that $\norm{}_{p}$ satisfies
            the triangle inequality. Proving this result
            requires H\"{o}lder's inequality.
            \begin{theorem}
                If $a_{n}$ and $b_{n}$ are nonnegative
                sequences, if $p>1$, and if $q$ is
                such that
                $\frac{1}{p}+\frac{1}{q}=1$, then:
                \begin{equation*}
                    \sum_{n=1}^{\infty}a_{n}b_{n}
                    \leq
                    \bigg(
                        \sum_{n=1}^{\infty}a_{n}^{p}
                    \bigg)^{1/p}
                    \bigg(
                        \sum_{n=1}^{\infty}b_{n}^{q}
                    \bigg)^{1/q}
                \end{equation*}
            \end{theorem}
            Numbers $p$ and $q$ such that
            $\frac{1}{p}+\frac{1}{q}=1$ are called
            conjugate exponents. When $p=q=2$, this
            is called the Cauchy-Schwartz inequality.
            That is,
            $|\mathbf{a}\cdot\mathbf{b}|%
             \leq\norm{\mathbf{a}}\norm{\mathbf{b}}$
            Proving H\"{o}lder's Inequality requires the
            following from Calc I:
            \begin{theorem}
                If $x$, $y>0$, $p>1$, and if
                $\frac{1}{p}+\frac{1}{q}=1$, then
                $y\leq{\frac{1}{p}x^{p}+\frac{1}{q}y^{q}}$.
            \end{theorem}
            Again, for $p=q=2$, this is easy.
            This says
            $0\leq{\frac{x^{2}+y^{2}}{2}-xy}%
             =\frac{(x-y)^{2}}{2}$, which is indeed true.
            A cute proof of this theorem comes from
            consider the area under the graph of
            $x^{p-1}$. There's an even more general
            result called Young's inequality.
        \subsubsection{Back to Open Sets}
            Let $(X,d)$ be a metric space.
            Recall that the open ball
            of radius $r>0$ centered about the
            point $x\in{X}$ is the set
            $B_{r}(x)=\{y\in{X}:d(x,y)<r\}$.
            We then defined open sets.
            A subset $S\subset{X}$ is a set such that
            for all $x\in{S}$, there is an $r_{x}>0$
            such $B_{r_{x}}(x)\subset{S}$. The subscript
            $r_{x}$ denotes the fact that the radius
            of the ball may depend on the point
            $x$. We then showed the open balls are indeed
            open sets. Moreover, all of $X$ is open,
            and the emptyset $\emptyset$ is open
            in a vacuous sense. That is, you cannot
            find a point that would make $\emptyset$
            \textit{not} open, and thus we say that it
            is open. We then proved the following, which
            led us into a brief discussion on topology:
            Finite unions of open sets are open, and
            arbitrary unions of open sets are open. A
            \textit{topology} on $X$ is a collection of
            subsets of $X$ that obey these two properties
            (And require that $X$ and $\emptyset$ are
            included in this collection).
            \begin{definition}
                Let $(X,d_{X})$ and $(Y,d_{Y})$ be
                metric spaces. A function
                $f:X\rightarrow{Y}$ is continuous
                at a point $x\in{X}$
                if for all $\varepsilon>0$ there is
                a $\delta>0$ such that for all
                $x_{o}\in{X}$ such that
                $d_{X}(x,x_{0})<\delta$, we have
                $d_{Y}(f(x),f(x_{0})<\varepsilon$
            \end{definition}
            \begin{definition}
                If $f:X\rightarrow{Y}$ is a function,
                then the pre-image of
                $S\subset{Y}$ is the set
                $f^{-1}(S)=\{x\in{X}:f(x)\in{S}\}$.
            \end{definition}
            A surprising theorem, and the entire
            basis of the study of topology, goes as
            follows:
            \begin{theorem}
                If $(X,d_{x})$ and $(Y,d_{Y})$
                are metric spaces, the
                $f:X\rightarrow{Y}$ is continuous
                at $x\in{X}$ if and only if
                for all open subsets
                of $S\subset{Y}$ such that
                $f(x)\in{S}$, the prem-image
                $f^{-1}(S)$ is an open subset of $X$.
            \end{theorem}
            This allows us to talk about continuous
            functions without a notion of metric.
            Thus, for topological spaces, this is
            the \textit{definition} of continuity.
            When the space we're discussing is a
            metric space, this theorem shows that the
            definition from topology and the defintition
            from real analysis are in fact equivalent.
            \begin{theorem}
                A function $f:X\rightarrow{Y}$ between
                metric spaces is continuous at a point
                $x\in{X}$ if and only if for all
                sequences $x_{n}$ such that
                $d_{X}(x,x_{n})\rightarrow{0}$, we have
                $d_{Y}(f(x),f(x_{n})\rightarrow{0}$.
            \end{theorem}
            We now have three different ways to talk
            about continuity.
            \begin{definition}
                A sequence $x_{n}$ is a metric space
                $X$ converges to a point $x\in{X}$
                if $d(x,x_{n})\rightarrow{0}$.
            \end{definition}
            \begin{theorem}
                If $(X,d)$ is a metric space,
                $x_{n}\rightarrow{x}$,
                and $x_{n}\rightarrow{y}$,
                then $x=y$.
            \end{theorem}
            \begin{proof}
                For
                $d(x,y)\leq{d(x_{n},x)+d(x_{n},y)}%
                 \rightarrow{0}$. Therefore, etc.
            \end{proof}
            This is not true in a topological space
            In a topological space you can have sequences
            which converge to every single point in the
            space simultaneously. The ability to
            ``Separate,'' points is a special property.
            Hausdorff spaces have this feature. But
            that's for a topology course.
            \begin{theorem}
                If $(X,d)$ is a metric space
                and $x_{n}\rightarrow{x}$, then
                for all $y\in{X}$,
                $d(x_{n},y)\rightarrow{d(x,y)}$.
            \end{theorem}
            \begin{proof}
                For
                $|d(x_{n},y)-d(x,y)|\leq{d(x_{n},x)}%
                 \rightarrow{0}$.
            \end{proof}
            \begin{theorem}
                If $(X,d)$ is a metric space,
                $y\in{X}$, then
                $f:X\rightarrow\mathbb{R}$ defined by
                $f(x)=d(x,y)$ is a continuous function.
                (In fact, it's uniformly continuous).
            \end{theorem}
        \subsubsection{Closed Sets}
            \begin{definition}
                A subset $S$ of a metric space $X$
                is closed if for all
                convergent sequences $x_{n}$
                in $S$, the limit of $x_{n}$ is also
                contained in $x$.
            \end{definition}
            This says that if $S$ is closed, and
            $x_{n}$ is a sequence in $S$ such
            that $x_{n}\rightarrow{x}$, then
            $x\in{S}$.
            \begin{example}
                In $\mathbb{R}$, with the standard
                metric, $(a,b)$ is open,
                $(-\infty,\infty)$ is open (and closed),
                $[a,b]$ is closed,
                $[a,\infty)$ is closed.
            \end{example}
            \begin{example}
                If $X=(0,1)$, and
                $d(x,y)=|x-y|$, then
                $(0,1)$ is closed. This is because
                there is no sequence that converges
                to a point in the space whose limit
                is not in the space. If you have a sequence
                converge to $0$ or $1$, then the
                limit is NOT in $(0,1)$, so we have not
                violated the definition of closedness.
            \end{example}
            \begin{theorem}
                If $(X,d)$ is a metric space,
                then a subset $S\subset{X}$ is open
                if and only if it's compliment $S^{c}$
                is closed.
            \end{theorem}
            \begin{proof}
                Suppose $S$ is open, and let
                $x_{n}$ be a sequence in $S^{c}$.
                Suppose $x_{n}\rightarrow{x}$ and
                $x\in{S}$. But $S$ is open, and thus
                there is an $\varepsilon>0$ such that
                $B_{\varepsilon}(x)\subset{S}$.
                But $x_{n}\rightarrow{x}$, and thus
                this is an $N\in\mathbb{N}$ such that
                for all $n>N$, $d(x,x_{n})<\varepsilon$.
                But then for all $n>N$,
                $x_{n}\in{B_{\varepsilon}(x)}$. But
                $x_{n}\in{S^{c}}$, a contradiction.
                Therefore, $S^{c}$ is closed. On the
                other hand, if $S^{c}$ is closed
                and there is an $x\in{S}$ such that
                for all $r>0$,
                $B_{r}(x)\cap{S}\ne\emptyset$, then
                for all $n\in\mathbb{N}$ there is
                an $x_{n}\in{S^{c}}$ such that
                $d(x,x_{n})<\frac{1}{n}$. But then
                $x_{n}\rightarrow{x}$, and therefore
                $x\in{S^{c}}$. But $x\in{S}$,
                a contradiction. Thus, $S$ is open.
            \end{proof}
            In topology we take the definition of
            closed sets to be the compliment of open
            sets. This theorem shows that the
            topological definition and the real analysis
            definition are equivalent when we consider
            metric spaces.
            \begin{definition}
                A point $x$ in a metric space
                $(X,d)$ is a limit point of a set
                $S\subset{X}$ if there is a sequence
                $x_{n}$ in $S$ such that
                $x_{n}\rightarrow{x}$.
            \end{definition}
            \begin{definition}
                The closure of a subset
                $S$ of a metric space
                $(X,d)$, denoted $\overline{S}$,
                is the set of all
                limit points of $S$.
            \end{definition}
            \begin{theorem}
                The closure of a subset
                $S$ of a metric space $(X,d)$
                is the intersection of all
                closed sets $\Delta$ such that
                $S\subset{\Delta}$.
            \end{theorem}
            With this theorem, we may loosely say that
            the closure of a set $S$ is the
            ``Smallest,'' closed set that contains $S$.
            \begin{definition}
                The closed ball of radius $r>0$ about
                a point $x$ in a metric space
                $(X,d)$ is the set
                $\overline{B}_{r}(x)%
                 =\{y\in{X}:d(x,y)\leq{r}\}$
            \end{definition}
            There exists metric spaces $(X,d)$
            such that
            $\overline{B}_{r}(x)\ne\overline{B_{r}(x)}$.
            For take the discrete metric, $r=1$.
            Then the closure of $B_{1}(x)$ is simply
            the point $x$. However, the closed ball
            $\overline{B}_{1}(x)$ is the entire space.
            Metric spaces can be very weird like this.
            They have a property, that given a nested
            sequence of closed balls whose radius
            tends to zero, there is precisely one
            point that lies in the intersection. However,
            if the radius does not tend to zero it is
            possible that the intersection is empty.
            This is very counter-intuitive.
        \subsubsection{Density}
            \begin{definition}
                A subset $S$ of a metric space $(X,d)$
                is dense if the $\overline{S}=X$.
            \end{definition}
            A subset $S$ is dense in $X$ if every point
            in $X$ can be approximated arbitrarily well
            by points in $S$. For any point $x\in{X}$
            there is a sequence $x_{n}\in{S}$
            such that $x_{n}\rightarrow{X}$. The
            classic example is $\mathbb{Q}$ and
            $\mathbb{R}$. Every real number can be
            approximated arbitrary well by a rational
            number. To see this, just take the continued
            fraction of a real number and stop once
            the approximation is less than
            $\varepsilon$. When we say $\mathbb{Q}$ is
            dense in $\mathbb{R}$, we of course mean with
            respect to the standard metric on $\mathbb{R}$.
            With the discrete metric, this is no longer
            true. 
            \begin{example}
                $\mathbb{Q}$ is dense in $\mathbb{R}$
                with respect to $d(x,y)=|x-y|$.
            \end{example}
            \begin{example}
                $\mathbb{Q}$ is dense in
                $\mathbb{R}$ with respect to
                $d_{p}(x,y)$ for $p\geq{1}$.
            \end{example}
            \begin{example}
                The set of polynomials on the interval
                $[a,b]$ are dense in the set of
                continuous functions on $[a,b]$ with
                respect to the $d_{\infty}$ metric.
                This comes from Weierstrass's Theorem.
            \end{example}
            \begin{example}
                The set of polynomials on $[a,b]$
                is dense in the set of continuous
                functions on $[a,b]$ with respect to
                the $d_{p}$ metric, for $p\geq{1}$. This
                comes from:
                \begin{align*}
                    d_{p}(P,x)&=
                    \bigg(
                        \int_{a}^{b}|P(t)-x(t)|^{p}dt
                    \bigg)^{1/p}\\
                    &\leq\bigg(
                        \int_{a}^{b}
                        |\max\{P(t)-x(t)\}|^{p}dt
                    \bigg)^{1/p}\\
                    &=\bigg(
                        d_{\infty}(P,x)^{p}\int_{a}^{b}dt
                    \bigg)^{1/p}\\
                    &=(b-a)^{1/p}d_{\infty}(P,x)
                \end{align*}
            \end{example}
            \begin{example}
                The continuous functions are not dense
                in the set of integrable functions,
                with respect to the supremum metric
                $d_{\infty}$. This is more or less
                because integrable functions can
                be discontinuous, or have jumps. This
                means, with respect to $d_{\infty}$,
                that no continuous functions could
                approximate such a discontinuous function
                arbitrary well.
            \end{example}
            \begin{definition}
                A countable s is a set
                $X$ such that there is a bijection
                $f:\mathbb{N}\rightarrow{X}$.
            \end{definition}
            Being countable means you can write
            the elements out in a list, or a
            one-to-one correspondence with all of
            the positive integers.
            \begin{example}
                $\mathbb{Q}$ is countable.
            \end{example}
            \begin{example}
                $\mathbb{R}$ is not countable.
            \end{example}
        \subsubsection{A Strange Divergence}
            For any set $A$, you can show
            that $A$ is strictly smaller
            than $\mathcal{P}(A)$. If you
            take $\mathcal{P}(\mathbb{N})$,
            you can show that this is the
            same size as $\mathbb{R}$. The
            question then becomes, is there
            any set whose ``Size,'' is in
            between $\mathbb{N}$ and $\mathbb{R}$?
            Continuing, you can ask the same thing
            about $\mathbb{R}$ and
            $\mathcal{P}(\mathbb{R})$, and so on
            This is called the continuum hypothesis.
            It turns out to be independent of
            the standard axioms of mathematics.
            Random stuff about $\gamma$.
            Transcendental numbers are cool.
        \subsubsection{Back to Reality}
            \begin{definition}
                A separable metric space
                is a metric space $(X,d)$ with
                a countable dense subset $S$.
            \end{definition}
            \begin{example}
                $\mathbb{R}$ is separable, with
                the standard metric, since
                $\mathbb{Q}$ is countable and also
                dense in $\mathbb{R}$.
            \end{example}
            \begin{theorem}
                A finite or countable union
                of countable sets is again countable.
            \end{theorem}
            \begin{example}
                The set of continuous functions on
                $[a,b]$ is separable. For
                take the set of polynomials with
                rational coefficients. This can
                be seen as a countable union of
                countably many elements. For let
                $P_{N}$ be the set of polynomials
                of degree $N$ with rational
                coefficients. This is countable,
                and the set of all polynomials with
                rational coefficients is simply the
                union of $P_{N}$ over all $N$. This
                is dense in the set of polynomials,
                and the set of polynomials is dense
                in $C[a,b]$, and thus
                the set of polynomials with rational
                coefficients is dense in $C[a,b]$. Thus
                $C[a,b]$ is separable.
            \end{example}
            \begin{example}
                $\ell^{p}$ is separable with the
                $d_{p}$ metric, simply use elements
                with rational entries. That is,
                sequences of rational numbers.
            \end{example}
            \begin{example}
                $\ell^{p}$ with the $d_{\infty}$ metric
                is NOT separable. Consider the real
                numbers in $(0,1)$.
            \end{example}
\end{document}