\documentclass[crop=false,class=article,oneside]{standalone}
%----------------------------Preamble-------------------------------%
\input{../../../../preamble.tex}
%--------------------------Main Document----------------------------%
\begin{document}
    \ifx\ifmathcoursesfunctional\undefined
        \section*{Functional Analysis}
        \setcounter{section}{1}
    \fi
    \subsection{Summary of Lectures}
        \subsubsection{Preliminaries}
            There are many sets commonly discussed,
            $\mathbb{N}$, $\mathbb{Z}$, $\mathbb{Q}$,
            $\mathbb{R}$, and $\mathbb{C}$.
            $\mathbb{Q}$ is an example of a
            \textit{countable} subset of $\mathbb{R}$ that is
            \textit{dense} in $\mathbb{R}$.
            $\sqrt{2}\notin\mathbb{Q}$, but can be approximated
            arbitrarily well be elements of $\mathbb{Q}$.
            The least upper bound axiom will also be used a lot,
            including the notions of $\sup$ and $\inf$. Sequences
            are functions from $\mathbb{N}$ to some set
            $\mathbb{R}$, later we will allow them to be functions
            into abstract sets. For now, convergence to a point $x$
            means that $|x-x_{n}|\rightarrow{0}$. More precisely,
            for all $\varepsilon>0$ there is an $N\in\mathbb{N}$
            such that, for all integers $n>N$,
            $|x-x_{n}|<\varepsilon$. Cauchy sequences are
            sequences such that, for all $\varepsilon>0$, there
            is an $N\in\mathbb{N}$ such that, for all integers
            $n,m>N$, $|x_{n}-x_{m}|<\varepsilon$. All convergent
            sequences are Cauchy, but it is not true that all
            Cauchy sequences converge. Loosely speaking, you can
            take a Cauchy sequence in $\mathbb{Q}$ that ``wants''
            to converge to $\sqrt{2}$, but $\sqrt{2}$ is not
            in $\mathbb{Q}$, so the sequence can't converge.
            However, all Cauchy sequences are bounded. A
            subsequence of a sequence $x_{n}$ is a sequence
            $x_{k_{n}}$, where $k_{n}$ is a strictly increasing
            function $k_{n}:\mathbb{N}\rightarrow\mathbb{N}$. One
            way to think of this is as the \textit{composition}
            of functions. Given a sequence (Which is a function)
            $x_{n}:\mathbb{N}\rightarrow\mathbb{R}$, and a
            strictly increasing function
            $k_{n}:\mathbb{N}\rightarrow\mathbb{N}$, the subsequence
            $x_{k_{n}}$ is the composition of the two functions:
            $x_{k_{n}}=(x\circ{k})(n)$.
            In $\mathbb{R}$, the least upper bound axiom gives
            us that every Cauchy sequence converges. The
            rational numbers lack this because there are
            bounded sets with no least upper bound. Sets such
            that every Cauchy sequence converges are called
            \textit{complete}. Cauchy sequences can actually be
            used to define the real numbers from the rational
            numbers by considering the set of
            \textit{equivalence classes} of Cauchy sequences on
            $\mathbb{Q}$. That is, two Cauchy sequences
            $x_{n}$ and $y_{n}$ are \textit{equivalent} if
            $x_{n}-y_{n}\rightarrow{0}$. This is a way to define
            the real numbers. The next notion to discuss is that
            of \textit{compactness}. A set is compact if every
            sequence $x_{n}$ has a \textit{convergent subsequence}
            $x_{k_{n}}$, the limit of which is also contained in
            the set. This is actually
            \textit{sequential compactness}. The notion of
            compactness is a topological one. As it turns out,
            sequential compactness and compactness are
            equivalent notions in \textit{metric spaces}, of
            which $\mathbb{R}$ is one of them. Metric spaces
            will be one of the main subjects of study in
            Functional Analysis. In $\mathbb{R}^{n}$ there is
            an equivalent, and perhaps more intuitive/useful
            notion of compactness. A subset of $\mathbb{R}^{n}$
            is compact if and only if it is
            \textit{closed} and \textit{bounded}. A set $X$ is
            closed if for all convergent sequences $x_{n}$,
            the limit is contained in $X$. Compactness gives rise
            to the Extreme Value Theorem: If $f:X\rightarrow\mathbb{R}$
            is continuous, and $X$ is compact, then $f$ is bounded
            and attains both its minimum and maximum at some points
            in $X$. Compactness also gives us uniform continuity:
            If $f:X\rightarrow\mathbb{R}$ is continuous and $X$
            is compact, then $f$ is uniformly continuous.
            An extra gem is, if $f:[a,b]\rightarrow\mathbb{R}$
            is continuous, and if $\varepsilon>0$, then there is
            a polynomial $P$ with coefficients in $\mathbb{Q}$
            such that $\sup\{|P(x)-f(x)|:x\in[a,b]\}<\varepsilon$.
            That is, any continuous function can be approximated
            arbitrarily well by a polynomial with rational
            coefficients. This is known as the
            Weierstrass Approximation Theorem. As mentioned
            before, $\mathbb{Q}$ is countable and is also
            a dense subset of $\mathbb{R}$. This means that
            every elements of $\mathbb{R}$ can be approximated
            arbitrarily well be an element of $\mathbb{Q}$. A
            space is called \textit{separable} if it contains
            a countable dense subset. The space of continuous
            functions on $[a,b]$, denoted $C[a,b]$ can be seen
            as separable, since the set of polynomials with
            rational coefficients is countable and dense in
            $C[a,b]$. The countability of this set comes from
            the fact that the set of polynomials with rational
            coefficients can be seen as the countably infinite
            union of countably infinite sets, which would itself
            be countable. Finally, a sequence of functions
            $f_{n}$ converges uniformly if the ``rate,'' of
            convergence is the same for every point. More precisely,
            $f_{n}:X\rightarrow\mathbb{R}$ converges to $f$
            uniformly if for all $\varepsilon>0$ there is an
            $N\in\mathbb{N}$ for all $x\in{X}$ such that
            $|f(x)-f_{n}(x)|<\varepsilon$.
        \subsubsection{Metric Spaces}
            Metric spaces are generalization of the notion
            of \textit{distance} that appears in $\mathbb{R}^{n}$.
            Metric spaces are sets $X$ with a
            \textit{distance function}
            $d:X\times{X}\rightarrow\mathbb{R}$ such that
            $d(x,y)=d(y,x)$, $d(x,y)\geq{0}$,
            $d(x,y)=0$ if and only if $x=y$, and finally the
            generalized triangle inequality holds:
            $d(x,z)\leq{d(x,y)+d(y,z)}$. Convergence in a metric
            space means that $d(x_{n},x)\rightarrow{0}$. There are
            many kinds of metric spaces with various metric. Popular
            ones are $d_{\infty}$, $p$ adic, the discrete metric,
            and induced metrics from \textit{normed spaces}.
            Other examples include $s,c,c_{0},B(A)$, and more.
            There are three important inequalities pertaining to
            metric spaces: The H\"{o}lder Inequality,
            the Cauchy-Schwartz Inequality, and the
            Minkowski Inequality. An open ball in a metric
            space of radius $r$ about a point $x$ is the set
            $B_{r}(x)=\{y\in{X}:d(x,y)<r\}$. That is, the
            set of all points that are closer that $r$ from $x$.
            In $\mathbb{R}^{2}$, with the usual metric, this
            is a circle. In $\mathbb{R}^{3}$ we get a sphere.
            This can look very strange in strange metric spaces,
            and can be very counter intuitive. An open subset
            $\mathcal{U}$ of a metric space $(X,d)$ is a set
            such that for all $x$ there is an $r>0$ such that
            $B_{r}(x)$ is contained entirely in $\mathcal{U}$.
            A closed set is a set whose \textit{complement} is
            open. These notions give rise to the more general
            theory of topology. Intervals $(a,b)$ are open,
            open balls are open, the entire space $X$ is open,
            and (Vacuously so) the empty set $\emptyset$ is open.
            A limit point of a subset $Y$ of a metric space $X$
            is a point $x\in{X}$ such that there is a sequence
            in $Y$ where $x_{n}\rightarrow{x}$. Closed sets
            contain all of their limit points.
            The closure of a set is the set together with all
            of its limit points. The closure of a set is closed.
            Cauchy sequence in a metric space are sequences such
            that, for all $\varepsilon>0$ there is an
            $N\in\mathbb{N}$ such that, for all $n,m>N$,
            $d(x_{n},x_{m})<\varepsilon$. The limit of
            convergent sequences is unique in a metric space.
            Convergent sequences are also bounded. If
            $x_{n}\rightarrow{x}$ and $y_{n}\rightarrow{y}$,
            then $d(x_{n},y_{n})\rightarrow{d(x,y)}$.
            A complete metric space is a space such that
            Cauchy sequences converge within the space.
            If $X$ is complete, and $Y$ is a closed subset of
            $X$, then $Y$ is complete.
        \subsubsection{Banach Fixed Point Theorem}
            A contraction is a function
            $T:X\rightarrow{X}$ such that there is an
            $\alpha\in[0,1)$ such that, for all
            $x,y\in{X}$, $d(Tx,Ty)\leq\alpha{d}(x,y)$. That is,
            a contraction is a mapping of $X$ onto itself that
            brings points closer together. The Banach Fixed Point
            Theorem says that if $X$ is complete, and $T$ is a
            contraction of $X$, then there is a unique fixed point
            $x\in{X}$. That is, a point $x$ such that $Tx=x$.
            Let $x_{0}$ be an arbitrary point in $X$, and define
            $x_{n+1}=Tx_{n}$. Then, as $T$ is a contraction,
            $x_{n}$ is Cauchy. But $X$ is complete and thus
            converges. Uniquness comes from the fact that
            if $Tx=x$ and $Ty=y$ then
            $d(Tx,Ty)=d(x,y)$, but $T$ is a contraction
            and thus $d(Tx,Ty)\leq\alpha{d}(x,y)$. Therefore
            $d(Tx,Ty)=d(x,y)=0$. Thus $x=y$. The Banach Fixed
            Point Theorem can be used to prove
            Picard's Theorem. This says if $x'(t)=f(x,t)$,
            $x(a)=x_{0}$, and if $f$ is
            \textit{Lipschitz Continuous}, then there is
            a unique solution $x(t)$ to this initial value
            problem. The Lipschitz requirement can not be
            relaxed without sacrificing uniqueness. The
            equation $x'(t)=\sqrt{x}$ with $x(0)=0$ has
            two solution, but $\sqrt{x}$ is not Lipschitz
            continuous at the origin. Peano's Theorem
            still guarantees existence of a solution, but
            cannot promise uniqueness.
        \subsubsection{Baire's Catagory Theorem}
            The interior of a set $X$ is the set of a points in $X$
            that can be enclosed by an open ball that is
            entirely contained in $X$. That is, the interior of
            $X$ is the ``largest,'' open subset of $X$. The interior
            of an open set is itself. A set is nowhere dense if
            its interior is empty. For example, the boundary of a circle
            in $\mathbb{R}^{2}$ is nowhere dense, with respect to
            the metric on $\mathbb{R}^{2}$. Any open ball about any point
            on the circle contains points not on the circle, and thus
            it has empty interior. A set is meager, or of first
            category, if it is the countable union of nowhere dense
            sets. A set is of second category, or non-meager, if
            it is not a meager set. Baire's Category Theorem says that
            a complete metric space is of second category. It also claims
            that given a countable collection of open and dense subsets
            of a complete metric space, the intersection of the collection
            is also dense (Though it may not be open). Incomplete
            metric spaces can be ``completed,'' by adding in enough
            points to make all Cauchy sequences converge. The
            completion of a metric space is unique up to
            \textit{isometry}. The Hilbert cube is an example of
            an infinite dimensional space that is compact.
            It is the set of all sequences
            $x_{n}:\mathbb{N}\rightarrow\mathbb{R}$ such that the
            $n^{th}$ entry, $x_{n}$ is less than $1/n$. That is,
            for all $n\in\mathbb{N}$, $x_{n}<1/n$.
        \subsubsection{Arzela-Ascoli Theorem}
            A metric space is totally bounded if,
            for all $\varepsilon>0$, there are
            finitely many points $x_{1},\hdots,x_{n}$ such that
            $X\subset\cup_{k=1}^{n}B_{\varepsilon}(x_{k})$. That is,
            $X$ can be contained in finitely many balls of any radius.
            A set is compact if and only if it is complete and
            totally bounded. Something about $\varepsilon$ nets.
            A sequence of functions $f_{n}$ are equicontinuous if
            for all $\varepsilon$ there is a $\delta>0$ such that,
            for all $n\in\mathbb{N}$, if $d(x,x_{0})<\delta$ then
            $d(f_{n}(x),f_{n}(x_{0})<\varepsilon$. In a way, the
            ``slopes,'' of the functions are tamed. This is not quite
            true since we could have a sequence of nowhere differentiable
            functions, in which case ``slope,'' has no meaning.
            The Arzela-Ascoli theorem says that if $f_{n}$ is a sequence
            of functions that is equicontinuous and uniformly bounded,
            then there is a subsequence $f_{k_{n}}$ that converges
            uniformly. The converse is also true. This theorem is used
            to prove the Peano theorem for differential equations that
            was discussed before.
        \subsubsection{Continuous Mappings}
            A continuous functions is a function $f:X\rightarrow{Y}$
            such that, for any open subset $\mathcal{U}\subset{Y}$,
            the \textit{pre-image} of $\mathcal{U}$ under $f$ is
            also open. That is, $f^{-1}(\mathcal{U})$ is an open subset
            of $X$. If $X$ is compact and $f:X\rightarrow{Y}$ is
            continuous, then $Y$ is compact. That is, continuous
            functions take compact sets to compact sets.
        \subsubsection{Inequalities}
            \begin{theorem}[Young]
                If $\frac{1}{p}+\frac{1}{q}=1$ and $x,y\geq{0}$, then
                $xy\leq\frac{1}{p}x^{p}+\frac{1}{q}y^{q}$.
            \end{theorem}
            \begin{theorem}[H\"{o}lder]
                If $a_{n},b_{n}\geq{0}$ and
                $\frac{1}{p}+\frac{1}{q}=1$, then
                $\sum{a_{n}b_{n}}\leq%
                 \big(\sum{a_{n}^{p}}\big)^{1/p}%
                 \big(\sum{b_{n}^{q}}\big)^{1/q}$
            \end{theorem}
            \begin{theorem}[Minkowski]
                If $a_{n},b_{n}\geq{0}$, $p>1$, then
                $\big(\sum(a_{n}+b_{n})^{p}\big)^{\frac{1}{p}}\leq%
                 \big(\sum{a_{n}}^{p}\big)^{\frac{1}{p}}+%
                 \big(\sum{b_{n}}^{p}\big)^{\frac{1}{p}}$
            \end{theorem}
        \subsubsection{Normed Spaces and Banach Spaces}
            A vector space $V$ over a field $K$ is a set that has
            a notion of \textit{vector addition} and
            \textit{scalar multiplication}, that behaves all of the
            usual rules one finds in a linear algebra course. There are
            many examples, such as $\mathbb{R}^{n}$ and $C[a,b]$.
            There are also the familiar notions of subspace,
            linear combination, indepence, spanning, dimension, and
            basis. There's also the notion of a Hamel basis. A norm on
            a vector space is a function $\norm{}:V\rightarrow\mathbb{R}$
            that obeys the triangle inequality, positive definiteness,
            and homogeneity. There's also the notion of
            \textit{convexity}. Open and closed balls are convex.
            The induced metric on a normed space is the metric
            $d(x,y)=\norm{x-y}$. A Banach Space is a normed space
            that is complete with respect to the induced metric.
            A subspace of a Banach space is complete if and only if
            it is closed. There are things like series and Schauder basis.
            A Schauder basis implies the space is separable. If
            $\{x_{1},\hdots,x_{n}\}$ is independent, then there exists
            a $c>0$ such that, for all $\boldsymbol{\alpha}$,
            $|\boldsymbol{\alpha}\cdot\mathbf{x}|%
             \geq{c}\norm{\boldsymbol{\alpha}}$.
            Finite dimensional subspaces are complete, as are closed
            subspaces. In finite dimensional normed spaces,
            a space is compact if and only if it is closed and bounded.
            Riesz's Lemma says that if $Z$ is a subspace of a normed
            space $X$, and if $Y$ is a proper closed subspace of
            $Z$, then there is a $z\in{Z}$ such that
            $\norm{z}=1$ and $D(z,Y)\geq{1/2}$. A corollary of this is
            that $B_{1}(0)$ is compact if and only if
            $X$ is finite dimensional.
        \subsubsection{Linear Operators}
            A linear operator is a function
            $T:X\rightarrow{Y}$ such that, for all
            $x,y\in{X}$, $\alpha,\beta\in\mathbb{R}$,
            $T(\alpha{x}+\beta{y})=\alpha{Tx}+\beta{Ty}$.
            Stuff about identity, zero, differentiation, and
            integration. 
            Domain of a linear operator, range of a linear operator,
            and the null space.
            Inverse of a linear operator is linear.
            $(ST)^{-1}=T^{-1}S^{-1}$.
            A bounded operator is a function $T:X\rightarrow{Y}$
            such that there is a $K\in\mathbb{R}$ such that, for all
            $x\in{X}$, $\norm{Tx}\leq{K}\norm{x}$. The norm of an operator
            is defined as
            $\norm{T}=\sup\{\norm{Tx}/\norm{x}:x\in{X},x\ne{0}\}$.
            This is equivalent to
            $\norm{T}=\sup\{\norm{Tx}:\norm{x}=1\}$. In finite dimension
            all linear operators are continuous. An operator is bounded
            if and only if it is continuous. If a linear operator is
            continuous at some point, then it is continuous everywhere.
            An operator is bounded if and only if its null space is closed.
            There is something called the extension of a bounded linear
            operator. $B(X,Y)$ is the set of bounder linear operators
            from $X$ to $Y$. This is complete if and only if
            $Y$ is complete. A functional is a mapping from a vector
            space $X$ into the real numbers $\mathbb{R}$. For continuous
            linear functional, continuity at $0$ implies continuity
            everywhere. There is something called the dual space
            $X'$, which is itself a Banach space. The dual
            of $\mathbb{R}$ is $\mathbb{R}$, and the dual of
            $\mathbb{R}^{n}$ is $\mathbb{R}^{n}$.
        \subsubsection{Inner Product and Hilbert Spaces}
            An inner product is a function
            $\langle\rangle:X\rightarrow\mathbb{R}$ the has
            positivity, symmetry, and linearity. The
            quintessential example is the dot product in
            $\mathbb{R}^{n}$, $\mathbf{a}\cdot\mathbf{b}$. An inner
            product induces a norm $\norm{x}=\langle{x,x}\rangle$.
            As norms induce metrics, an inner product also induces a
            metric. A Hilbert Space is an inner product space that
            is complete with respect to the induced metric.
            Orthogonal elements of an inner product space are elements
            $x$ and $y$ such that $\langle{x,y}\rangle=0$. The
            polarization identity says that
            $\langle{x,y}\rangle=\frac{1}{4}\norm{x+y}^{2}%
             -\frac{1}{4}\norm{x-y}^{2}$. The Apollonius identity says
            $\norm{x-z}^{2}+\norm{y-z}^{2}=%
             \frac{1}{2}\norm{x-y}^{2}+\norm{(x+y)^{2}-2z}^{2}$.
            If $x_{n}\rightarrow{x}$ and $y_{n}\rightarrow{y}$, then
            $\langle{x_{n},y_{n}}\rangle\rightarrow\langle{x,y}\rangle$.
            A subspace of a Hilbert space is complete if and only if
            it is closed. There's a notion of distance from a point $x$
            to a set $M$. If $X$ is an inner product space, and $M$ is a
            non-empty complete and convex subset, then for all
            $x\in{X}$ there is a $y\in{M}$ such that
            $\norm{x-y}=D(x,M)$. If $M$ is a subspace of $Y$, then
            $x-y\perp{Y}$. There's a notion of orthogonal sets,
            and orthonormality. If $(e_{n})$ is orthonormal basis, then
            $x=\sum\langle{x,e_{k}}\rangle{e_{k}}$ for all $x$.
            Bessel's inequality is a thing. So is the Gram-Schmidt
            procedure. $\sum\alpha_{k}e_{k}$ converges if and only if
            $\sum|\alpha_{k}|^{2}$ converges. A set $M$ is total in
            a Hilbert space $H$ is the span of the closure of $M$ is equal
            to $H$. If $M$ is complete, then it is 
            total if and only if $M^{\perp}=0$. Parseval's theorem.
            Legendre, Hermite, and Laguerre polynomials are things.
            Riesz's Representation Theorem.
            Hilbert Adjoint Operator. $T:H\rightarrow{H}$,
            adjoint $\langle{Tx,y}\rangle=\langle{x,T^{*}y}\rangle$.
            $\norm{T^{*}}=\norm{T}$, $T^{**}=T$.
            Self adjoint, unitary, and normal operators.
            $T^{*}=T$, $T^{*}=T^{-1}$, and $T^{*}T=TT^{*}$. If
            $X$ is a vector space over the complex numbers,
            and if $T$ is self adjoint, then
            $\langle{Tx,x}\rangle$ is a real number for all $x$.
        \subsubsection{Compact Linear Operators}
            A compact operator is a function
            $T:X\rightarrow{Y}$ such that, for all bounded subsets
            $M\subset{X}$, the closure of the image of $M$,
            that is $\overline{T(M)}$, is a compact subset of $Y$.
            If $T$ is compact and linear, then it is bounded and
            continuous. An operator is compact and linear if and only if
            for all bounded sequences $x_{n}$,
            $Tx_{n}$ has a convergent subsequence. Compact linear
            operators form a vector space. The rank of an operator is
            the dimension of its image. If $T$ is linear, bounded, and
            of finite rank, then it is compact.
            If $T_{n}$ is a sequence of compact linear operators, if $Y$ is
            complete, and if $\norm{T_{n}-T}\rightarrow{0}$, then
            $T$ is compact. A sequence $x_{n}$ converges weakly to
            $x$ if, for all $y$,
            $\langle{x_{n},y}\rangle\rightarrow\langle{x,y}\rangle$.
            If $x_{n}$ converges weakly to $x$, then
            and if $T$ is a compact linear operator, then
            $Tx_{n}\rightarrow{Tx}$. If $H$ is a Hilbert space,
            $T$ is a compact self-adjoint operator, and if
            $x_{n}$ converges weakly to $x$, then
            $\langle{Tx_{n},x_{n}}\rangle\rightarrow\langle{Tx,x}\rangle$.
            If $T:H\rightarrow{H}$ is compact and linear, then so
            is its adjoint. The Hilbert-Schmidt theorem says that
            compact self-adjoint operators on a Hilbert space $H$
            have an orthonormal basis of eigenvectors. All of this
            has applications to integral operators and
            Sturm-Liouville Theory.
        \subsubsection{Fundamental Theorems}
            Zorn's Lemma. Hahn-Banach Theorem. Sublinear functionals.
            If $X$ is a normed space, and $Z$ is a subspace, and if
            $f\in{Z'}$, then $f$ be extended to $X$ such that
            $\norm{f}_{X}=\norm{f}_{Z}$. This is immediately extended to
            Hilbert spaces by Riesz's theorem. If $X$ is a normed space
            and $x\ne{0}$, then there is an $f\in{X'}$ such that
            $\norm{f}=1$ and $f(x_{0})=\norm{x_{0}}$. For all $x$,
            $\norm{x}=\sup\{\norm{f(x)}/\norm{f}:f\in{X'},f\ne{0}\}$.
            There's a thing called bounded variation. If $x\in{X}$ and
            $g_{x}(f)=f(x)$ for $f\in{X'}$, then
            $g_{x}\in{X''}$ and $\norm{g_{x}}=\norm{x}$.
            The canonical map $g:X\rightarrow{X''}$,
            $C(x)=g_{x}$ is an isomorphism.
            A reflexive space is one such that
            $\mathscr{R}(X)=X''$.
            Reflexive implies complete. Finite and Hilbert implies
            reflexive.
            $X'$ separable implies $X$ is separable.
            $X$ separable and reflexive implies $X'$ is separable.
            There exist continuous functions whose Fourier series
            diverges at a point. $x_{n}\rightarrow{x}$ strongly if
            $\norm{x_{n}-x}\rightarrow{0}$. If $x_{n}\rightarrow{x}$
            strongly, then it converges weakly as well. The converse is
            not true. If $X$ is finite dimensional, then weak convergence
            implies strong convergence. Weak convergence implies
            $\norm{x_{n}}$ is bounded. If
            $x_{n}\rightarrow{x}$ weakly, and if
            $\norm{x_{n}}\rightarrow\norm{x}$, then
            $x_{n}\rightarrow{x}$ strongly. Open mapping theorem is
            a thing. As is the closed graph theorem. Differentiation
            is a closed operator on $C^{1}[a,b]\rightarrow{C[a,b]}$.
\end{document}